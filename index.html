<!DOCTYPE html>
<head><meta charset="utf-8" /><meta content="minimum-scale=1, initial-scale=1, width=device-width, shrink-to-fit=no" name="viewport" /><link href="static/css/style.css" rel="stylesheet" type="text/css" /><link href="static/css/custom.css" rel="stylesheet" type="text/css" /><link href="static/img/logo.png" rel="shortcut icon" type="image/png" /><link href="static/img/logo.png" rel="shortcut icon" sizes="192x192" /><link href="static/img/logo.png" rel="apple-touch-icon" /><meta name="apple-mobile-web-app-title" /><meta content="yes" name="apple-mobile-web-app-capable" /><meta content="yes" name="apple-touch-fullscreen" /><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style" /><meta content="yes" name="mobile-web-app-capable" /><meta property="og:title" /><meta content="site" property="og:type" /><meta content="static/img/logo.png" property="og:image" /><meta property="og:description" /><title></title><meta property="og:site_name" /><meta /></head><body><div id="root"></div><script>window.logseq_db="[&quot;~#datascript/DB&quot;,[&quot;^ &quot;,&quot;~:schema&quot;,[&quot;^ &quot;,&quot;~:ast/version&quot;,[&quot;^ &quot;],&quot;~:db/encryption-keys&quot;,[&quot;^ &quot;],&quot;~:file/content&quot;,[&quot;^ &quot;],&quot;~:git/status&quot;,[&quot;^ &quot;],&quot;~:repo/cloned?&quot;,[&quot;^ &quot;],&quot;~:block/alias&quot;,[&quot;^ &quot;,&quot;~:db/valueType&quot;,&quot;~:db.type/ref&quot;,&quot;~:db/cardinality&quot;,&quot;~:db.cardinality/many&quot;],&quot;~:git/error&quot;,[&quot;^ &quot;],&quot;~:block/pre-block?&quot;,[&quot;^ &quot;],&quot;~:git/last-pulled-at&quot;,[&quot;^ &quot;],&quot;~:block/uuid&quot;,[&quot;^ &quot;,&quot;~:db/unique&quot;,&quot;~:db.unique/identity&quot;],&quot;~:repo/url&quot;,[&quot;^ &quot;,&quot;^@&quot;,&quot;^A&quot;],&quot;~:block/priority&quot;,[&quot;^ &quot;],&quot;~:block/properties&quot;,[&quot;^ &quot;],&quot;~:block/journal?&quot;,[&quot;^ &quot;],&quot;~:block/namespace&quot;,[&quot;^ &quot;,&quot;^8&quot;,&quot;^9&quot;],&quot;~:block/updated-at&quot;,[&quot;^ &quot;],&quot;~:block/repeated?&quot;,[&quot;^ &quot;],&quot;~:db/type&quot;,[&quot;^ &quot;],&quot;~:file/handle&quot;,[&quot;^ &quot;],&quot;~:block/left&quot;,[&quot;^ &quot;,&quot;^8&quot;,&quot;^9&quot;],&quot;~:block/refs&quot;,[&quot;^ &quot;,&quot;^8&quot;,&quot;^9&quot;,&quot;^:&quot;,&quot;^;&quot;],&quot;~:block/scheduled&quot;,[&quot;^ &quot;],&quot;~:me/avatar&quot;,[&quot;^ &quot;],&quot;~:db/encrypted?&quot;,[&quot;^ &quot;],&quot;~:block/properties-order&quot;,[&quot;^ &quot;],&quot;~:block/created-at&quot;,[&quot;^ &quot;],&quot;~:block/deadline&quot;,[&quot;^ &quot;],&quot;~:block/body&quot;,[&quot;^ &quot;],&quot;~:me/name&quot;,[&quot;^ &quot;],&quot;~:block/meta&quot;,[&quot;^ &quot;],&quot;~:block/journal-day&quot;,[&quot;^ &quot;],&quot;~:block/format&quot;,[&quot;^ &quot;],&quot;~:block/level&quot;,[&quot;^ &quot;],&quot;~:block/tags&quot;,[&quot;^ &quot;,&quot;^8&quot;,&quot;^9&quot;,&quot;^:&quot;,&quot;^;&quot;],&quot;~:block/title&quot;,[&quot;^ &quot;],&quot;~:block/content&quot;,[&quot;^ &quot;],&quot;~:recent/pages&quot;,[&quot;^ &quot;],&quot;~:db/ident&quot;,[&quot;^ &quot;,&quot;^@&quot;,&quot;^A&quot;],&quot;~:block/path-refs&quot;,[&quot;^ &quot;,&quot;^8&quot;,&quot;^9&quot;,&quot;^:&quot;,&quot;^;&quot;],&quot;~:block/parent&quot;,[&quot;^ &quot;,&quot;^8&quot;,&quot;^9&quot;],&quot;~:block/heading-level&quot;,[&quot;^ &quot;],&quot;~:block/type&quot;,[&quot;^ &quot;],&quot;~:me/email&quot;,[&quot;^ &quot;],&quot;~:block/page&quot;,[&quot;^ &quot;,&quot;^8&quot;,&quot;^9&quot;,&quot;~:db/index&quot;,true],&quot;~:block/name&quot;,[&quot;^ &quot;,&quot;^@&quot;,&quot;^A&quot;],&quot;~:file/path&quot;,[&quot;^ &quot;,&quot;^@&quot;,&quot;^A&quot;],&quot;~:block/file&quot;,[&quot;^ &quot;,&quot;^8&quot;,&quot;^9&quot;],&quot;~:block/marker&quot;,[&quot;^ &quot;],&quot;~:block/original-name&quot;,[&quot;^ &quot;,&quot;^@&quot;,&quot;^A&quot;],&quot;~:schema/version&quot;,[&quot;^ &quot;]],&quot;~:datoms&quot;,[&quot;~#list&quot;,[[&quot;~#datascript/Datom&quot;,[1,&quot;^1&gt;&quot;,&quot;0.0.2&quot;,536870913]],[&quot;^1A&quot;,[3,&quot;^Q&quot;,1629343667322,536870918]],[&quot;^1A&quot;,[3,&quot;^E&quot;,false,536870915]],[&quot;^1A&quot;,[3,&quot;^19&quot;,&quot;todo&quot;,536870915]],[&quot;^1A&quot;,[3,&quot;^1=&quot;,&quot;TODO&quot;,536871606]],[&quot;^1A&quot;,[3,&quot;^G&quot;,1629343667322,536870918]],[&quot;^1A&quot;,[3,&quot;^?&quot;,&quot;~u6129d91c-9938-4a98-aa49-580872be3ad5&quot;,536871220]],[&quot;^1A&quot;,[4,&quot;^Q&quot;,1629343667322,536870918]],[&quot;^1A&quot;,[4,&quot;^E&quot;,false,536870915]],[&quot;^1A&quot;,[4,&quot;^19&quot;,&quot;now&quot;,536870915]],[&quot;^1A&quot;,[4,&quot;^1=&quot;,&quot;NOW&quot;,536870915]],[&quot;^1A&quot;,[4,&quot;^G&quot;,1629343667322,536870918]],[&quot;^1A&quot;,[4,&quot;^?&quot;,&quot;~udf68af73-942b-4dc5-a67d-35072062dbb0&quot;,536871208]],[&quot;^1A&quot;,[5,&quot;^Q&quot;,1629343667322,536870918]],[&quot;^1A&quot;,[5,&quot;^E&quot;,false,536870915]],[&quot;^1A&quot;,[5,&quot;^19&quot;,&quot;later&quot;,536870915]],[&quot;^1A&quot;,[5,&quot;^1=&quot;,&quot;LATER&quot;,536870915]],[&quot;^1A&quot;,[5,&quot;^G&quot;,1629343667322,536870918]],[&quot;^1A&quot;,[5,&quot;^?&quot;,&quot;~ua222c78e-572b-431e-acc9-305b36805788&quot;,536871208]],[&quot;^1A&quot;,[6,&quot;^Q&quot;,1629343667322,536870918]],[&quot;^1A&quot;,[6,&quot;^E&quot;,false,536870915]],[&quot;^1A&quot;,[6,&quot;^19&quot;,&quot;done&quot;,536870915]],[&quot;^1A&quot;,[6,&quot;^1=&quot;,&quot;DONE&quot;,536870915]],[&quot;^1A&quot;,[6,&quot;^G&quot;,1629343667322,536870918]],[&quot;^1A&quot;,[6,&quot;^?&quot;,&quot;~u1d33f631-3639-427f-b273-2738669acb9a&quot;,536871208]],[&quot;^1A&quot;,[7,&quot;^Q&quot;,1629343667322,536870918]],[&quot;^1A&quot;,[7,&quot;^E&quot;,false,536870915]],[&quot;^1A&quot;,[7,&quot;^19&quot;,&quot;doing&quot;,536870915]],[&quot;^1A&quot;,[7,&quot;^1=&quot;,&quot;DOING&quot;,536870915]],[&quot;^1A&quot;,[7,&quot;^G&quot;,1629343667322,536870918]],[&quot;^1A&quot;,[7,&quot;^?&quot;,&quot;~u8daf20c2-f811-4cc2-aec8-bb1867194def&quot;,536871208]],[&quot;^1A&quot;,[8,&quot;^Q&quot;,1629343667322,536870918]],[&quot;^1A&quot;,[8,&quot;^E&quot;,false,536870915]],[&quot;^1A&quot;,[8,&quot;^19&quot;,&quot;in-progress&quot;,536870915]],[&quot;^1A&quot;,[8,&quot;^1=&quot;,&quot;IN-PROGRESS&quot;,536870915]],[&quot;^1A&quot;,[8,&quot;^G&quot;,1629343667322,536870918]],[&quot;^1A&quot;,[8,&quot;^?&quot;,&quot;~u0cad6886-0a90-4fcf-b977-f0d391a3cb2f&quot;,536871208]],[&quot;^1A&quot;,[9,&quot;^Q&quot;,1629343667322,536870918]],[&quot;^1A&quot;,[9,&quot;^E&quot;,false,536870915]],[&quot;^1A&quot;,[9,&quot;^19&quot;,&quot;c&quot;,536870915]],[&quot;^1A&quot;,[9,&quot;^1=&quot;,&quot;C&quot;,536870915]],[&quot;^1A&quot;,[9,&quot;^G&quot;,1629343667322,536870918]],[&quot;^1A&quot;,[9,&quot;^?&quot;,&quot;~u3000190c-087b-491e-b9b4-efa32faf34c8&quot;,536871208]],[&quot;^1A&quot;,[10,&quot;^Q&quot;,1629343667322,536870918]],[&quot;^1A&quot;,[10,&quot;^E&quot;,false,536870915]],[&quot;^1A&quot;,[10,&quot;^19&quot;,&quot;b&quot;,536870915]],[&quot;^1A&quot;,[10,&quot;^1=&quot;,&quot;B&quot;,536870915]],[&quot;^1A&quot;,[10,&quot;^G&quot;,1629343667322,536870918]],[&quot;^1A&quot;,[10,&quot;^?&quot;,&quot;~ub7b4ffb3-9265-4abf-902c-bc9fc657328a&quot;,536871208]],[&quot;^1A&quot;,[11,&quot;^Q&quot;,1629343667322,536870918]],[&quot;^1A&quot;,[11,&quot;^E&quot;,false,536870915]],[&quot;^1A&quot;,[11,&quot;^19&quot;,&quot;waiting&quot;,536870915]],[&quot;^1A&quot;,[11,&quot;^1=&quot;,&quot;WAITING&quot;,536870915]],[&quot;^1A&quot;,[11,&quot;^G&quot;,1629343667322,536870918]],[&quot;^1A&quot;,[11,&quot;^?&quot;,&quot;~ud188b3be-1217-48d6-9eb3-552c5de5b440&quot;,536871208]],[&quot;^1A&quot;,[12,&quot;^Q&quot;,1629343667322,536870918]],[&quot;^1A&quot;,[12,&quot;^E&quot;,false,536870915]],[&quot;^1A&quot;,[12,&quot;^19&quot;,&quot;a&quot;,536870915]],[&quot;^1A&quot;,[12,&quot;^1=&quot;,&quot;A&quot;,536870915]],[&quot;^1A&quot;,[12,&quot;^G&quot;,1629343667322,536870918]],[&quot;^1A&quot;,[12,&quot;^?&quot;,&quot;~ucf656178-e4fe-4151-a9df-8fbb40c8d179&quot;,536871208]],[&quot;^1A&quot;,[13,&quot;^Q&quot;,1629343667322,536870918]],[&quot;^1A&quot;,[13,&quot;^E&quot;,false,536870915]],[&quot;^1A&quot;,[13,&quot;^19&quot;,&quot;wait&quot;,536870915]],[&quot;^1A&quot;,[13,&quot;^1=&quot;,&quot;WAIT&quot;,536870915]],[&quot;^1A&quot;,[13,&quot;^G&quot;,1629343667322,536870918]],[&quot;^1A&quot;,[13,&quot;^?&quot;,&quot;~u94b46caa-daf6-4658-ab02-3a946daf5382&quot;,536871208]],[&quot;^1A&quot;,[23,&quot;^Q&quot;,1629343667322,536870918]],[&quot;^1A&quot;,[23,&quot;^E&quot;,false,536870917]],[&quot;^1A&quot;,[23,&quot;^19&quot;,&quot;abstract&quot;,536870917]],[&quot;^1A&quot;,[23,&quot;^1=&quot;,&quot;Abstract&quot;,536870917]],[&quot;^1A&quot;,[23,&quot;^G&quot;,1629343667322,536870918]],[&quot;^1A&quot;,[23,&quot;^?&quot;,&quot;~u6120a3a8-aa56-4761-846e-06517d4fac5a&quot;,536870917]],[&quot;^1A&quot;,[24,&quot;^Q&quot;,1629343667322,536870918]],[&quot;^1A&quot;,[24,&quot;^E&quot;,false,536870917]],[&quot;^1A&quot;,[24,&quot;^19&quot;,&quot;journalarticle&quot;,536870917]],[&quot;^1A&quot;,[24,&quot;^1=&quot;,&quot;journalArticle&quot;,536870917]],[&quot;^1A&quot;,[24,&quot;^G&quot;,1629343667322,536870918]],[&quot;^1A&quot;,[24,&quot;^?&quot;,&quot;~u6129d874-ccb5-4689-9eba-308fdd401b74&quot;,536871175]],[&quot;^1A&quot;,[25,&quot;^Q&quot;,1629526968198,536870918]],[&quot;^1A&quot;,[25,&quot;^E&quot;,false,536870917]],[&quot;^1A&quot;,[25,&quot;^19&quot;,&quot;fuchun peng&quot;,536870917]],[&quot;^1A&quot;,[25,&quot;^1=&quot;,&quot;Fuchun Peng&quot;,536870917]],[&quot;^1A&quot;,[25,&quot;^G&quot;,1629526968198,536870918]],[&quot;^1A&quot;,[25,&quot;^?&quot;,&quot;~u6129d874-1256-45ab-a714-fb42a79ed259&quot;,536871175]],[&quot;^1A&quot;,[26,&quot;^Q&quot;,1629343667322,536870918]],[&quot;^1A&quot;,[26,&quot;^E&quot;,false,536870917]],[&quot;^1A&quot;,[26,&quot;^19&quot;,&quot;computer science - computation and language&quot;,536870917]],[&quot;^1A&quot;,[26,&quot;^1=&quot;,&quot;Computer Science - Computation and Language&quot;,536870917]],[&quot;^1A&quot;,[26,&quot;^G&quot;,1629343667322,536870918]],[&quot;^1A&quot;,[26,&quot;^?&quot;,&quot;~u6129d874-9ad0-4deb-b29f-5354250bd566&quot;,536871175]],[&quot;^1A&quot;,[27,&quot;^Q&quot;,1629346910603,536870918]],[&quot;^1A&quot;,[27,&quot;^E&quot;,false,536870917]],[&quot;^1A&quot;,[27,&quot;^19&quot;,&quot;computer science - sound&quot;,536870917]],[&quot;^1A&quot;,[27,&quot;^1=&quot;,&quot;Computer Science - Sound&quot;,536870917]],[&quot;^1A&quot;,[27,&quot;^G&quot;,1629346910603,536870918]],[&quot;^1A&quot;,[27,&quot;^?&quot;,&quot;~u6129d874-91dc-4f0a-8157-70f869ca80c4&quot;,536871175]],[&quot;^1A&quot;,[28,&quot;^Q&quot;,1629529000772,536870918]],[&quot;^1A&quot;,[28,&quot;^E&quot;,false,536870917]],[&quot;^1A&quot;,[28,&quot;^19&quot;,&quot;speech recognition&quot;,536870917]],[&quot;^1A&quot;,[28,&quot;^1=&quot;,&quot;Speech Recognition&quot;,536870917]],[&quot;^1A&quot;,[28,&quot;^G&quot;,1629529000772,536870918]],[&quot;^1A&quot;,[28,&quot;^?&quot;,&quot;~u6120a3a8-e6db-4726-8569-0ebbec6218f1&quot;,536870917]],[&quot;^1A&quot;,[29,&quot;^Q&quot;,1581638400000,536870918]],[&quot;^1A&quot;,[29,&quot;^V&quot;,20200214,536870917]],[&quot;^1A&quot;,[29,&quot;^E&quot;,true,536870917]],[&quot;^1A&quot;,[29,&quot;^19&quot;,&quot;feb 14th, 2020&quot;,536870917]],[&quot;^1A&quot;,[29,&quot;^1=&quot;,&quot;Feb 14th, 2020&quot;,536870917]],[&quot;^1A&quot;,[29,&quot;^G&quot;,1581638400000,536870918]],[&quot;^1A&quot;,[29,&quot;^?&quot;,&quot;~u6129d874-58c6-4ba0-b46b-c1753d12f797&quot;,536871175]],[&quot;^1A&quot;,[30,&quot;^Q&quot;,1629343667322,536870918]],[&quot;^1A&quot;,[30,&quot;^E&quot;,false,536870917]],[&quot;^1A&quot;,[30,&quot;^19&quot;,&quot;abdelrahman mohamed&quot;,536870917]],[&quot;^1A&quot;,[30,&quot;^1=&quot;,&quot;Abdelrahman Mohamed&quot;,536870917]],[&quot;^1A&quot;,[30,&quot;^G&quot;,1629343667322,536870918]],[&quot;^1A&quot;,[30,&quot;^?&quot;,&quot;~u6129d874-c247-4109-90af-60b95f10d303&quot;,536871175]],[&quot;^1A&quot;,[31,&quot;^Q&quot;,1603324800000,536870918]],[&quot;^1A&quot;,[31,&quot;^V&quot;,20201022,536870917]],[&quot;^1A&quot;,[31,&quot;^E&quot;,true,536870917]],[&quot;^1A&quot;,[31,&quot;^19&quot;,&quot;oct 22nd, 2020&quot;,536870917]],[&quot;^1A&quot;,[31,&quot;^1=&quot;,&quot;Oct 22nd, 2020&quot;,536870917]],[&quot;^1A&quot;,[31,&quot;^G&quot;,1603324800000,536870918]],[&quot;^1A&quot;,[31,&quot;^?&quot;,&quot;~u6120a3a8-6ff5-428f-b98c-82df259636c3&quot;,536870917]],[&quot;^1A&quot;,[32,&quot;^Q&quot;,1629526968198,536870918]],[&quot;^1A&quot;,[32,&quot;^E&quot;,false,536870917]],[&quot;^1A&quot;,[32,&quot;^19&quot;,&quot;ross girshick&quot;,536870917]],[&quot;^1A&quot;,[32,&quot;^1=&quot;,&quot;Ross Girshick&quot;,536870917]],[&quot;^1A&quot;,[32,&quot;^G&quot;,1629526968198,536870918]],[&quot;^1A&quot;,[32,&quot;^?&quot;,&quot;~u6129d874-8c50-4a2a-b826-649f98251569&quot;,536871175]],[&quot;^1A&quot;,[33,&quot;^Q&quot;,1629526968198,536870918]],[&quot;^1A&quot;,[33,&quot;^E&quot;,false,536870917]],[&quot;^1A&quot;,[33,&quot;^19&quot;,&quot;yatharth saraf&quot;,536870917]],[&quot;^1A&quot;,[33,&quot;^1=&quot;,&quot;Yatharth Saraf&quot;,536870917]],[&quot;^1A&quot;,[33,&quot;^G&quot;,1629526968198,536870918]],[&quot;^1A&quot;,[33,&quot;^?&quot;,&quot;~u6129d874-3c37-4305-ad30-f9fa294179ae&quot;,536871175]],[&quot;^1A&quot;,[34,&quot;^Q&quot;,1629526968198,536870918]],[&quot;^1A&quot;,[34,&quot;^E&quot;,false,536870917]],[&quot;^1A&quot;,[34,&quot;^19&quot;,&quot;geoffrey zweig&quot;,536870917]],[&quot;^1A&quot;,[34,&quot;^1=&quot;,&quot;Geoffrey Zweig&quot;,536870917]],[&quot;^1A&quot;,[34,&quot;^G&quot;,1629526968198,536870918]],[&quot;^1A&quot;,[34,&quot;^?&quot;,&quot;~u6129d874-be96-4c7c-b2fa-2dc7379409fd&quot;,536871175]],[&quot;^1A&quot;,[35,&quot;^Q&quot;,1629526968198,536870918]],[&quot;^1A&quot;,[35,&quot;^E&quot;,false,536870917]],[&quot;^1A&quot;,[35,&quot;^19&quot;,&quot;yongqiang wang&quot;,536870917]],[&quot;^1A&quot;,[35,&quot;^1=&quot;,&quot;Yongqiang Wang&quot;,536870917]],[&quot;^1A&quot;,[35,&quot;^G&quot;,1629526968198,536870918]],[&quot;^1A&quot;,[35,&quot;^?&quot;,&quot;~u6129d874-56ff-460a-aab7-8ad31b99fd4b&quot;,536871175]],[&quot;^1A&quot;,[37,&quot;^Q&quot;,1629346910602,536870918]],[&quot;^1A&quot;,[37,&quot;^E&quot;,false,536870917]],[&quot;^1A&quot;,[37,&quot;^19&quot;,&quot;michael auli&quot;,536870917]],[&quot;^1A&quot;,[37,&quot;^1=&quot;,&quot;Michael Auli&quot;,536870917]],[&quot;^1A&quot;,[37,&quot;^G&quot;,1629346910602,536870918]],[&quot;^1A&quot;,[37,&quot;^?&quot;,&quot;~u6120a3a8-ce3a-4dad-9230-1e5ede16456f&quot;,536870917]],[&quot;^1A&quot;,[38,&quot;^Q&quot;,1629526968198,536870918]],[&quot;^1A&quot;,[38,&quot;^E&quot;,false,536870917]],[&quot;^1A&quot;,[38,&quot;^19&quot;,&quot;frank zhang&quot;,536870917]],[&quot;^1A&quot;,[38,&quot;^1=&quot;,&quot;Frank Zhang&quot;,536870917]],[&quot;^1A&quot;,[38,&quot;^G&quot;,1629526968198,536870918]],[&quot;^1A&quot;,[38,&quot;^?&quot;,&quot;~u6129d874-5039-4d91-aef2-03637c213981&quot;,536871175]],[&quot;^1A&quot;,[40,&quot;^Q&quot;,1629343667322,536871096]],[&quot;^1A&quot;,[40,&quot;^E&quot;,false,536870917]],[&quot;^1A&quot;,[40,&quot;^19&quot;,&quot;contents&quot;,536870917]],[&quot;^1A&quot;,[40,&quot;^1=&quot;,&quot;Contents&quot;,536870917]],[&quot;^1A&quot;,[40,&quot;~:block/unordered&quot;,true,536871074]],[&quot;^1A&quot;,[40,&quot;^G&quot;,1630142384552,536873562]],[&quot;^1A&quot;,[40,&quot;^?&quot;,&quot;~u6129d91c-1a9a-4715-a162-6fd3f7567a8a&quot;,536871220]],[&quot;^1A&quot;,[41,&quot;^Q&quot;,1629526968199,536870918]],[&quot;^1A&quot;,[41,&quot;^E&quot;,false,536870917]],[&quot;^1A&quot;,[41,&quot;^19&quot;,&quot;dmytro okhonko&quot;,536870917]],[&quot;^1A&quot;,[41,&quot;^1=&quot;,&quot;Dmytro Okhonko&quot;,536870917]],[&quot;^1A&quot;,[41,&quot;^G&quot;,1629526968199,536870918]],[&quot;^1A&quot;,[41,&quot;^?&quot;,&quot;~u6129d874-70f9-42be-8c4b-7f8f1b56b52c&quot;,536871175]],[&quot;^1A&quot;,[42,&quot;^Q&quot;,1629346910603,536870918]],[&quot;^1A&quot;,[42,&quot;^E&quot;,false,536870917]],[&quot;^1A&quot;,[42,&quot;^19&quot;,&quot;henry zhou&quot;,536870917]],[&quot;^1A&quot;,[42,&quot;^1=&quot;,&quot;Henry Zhou&quot;,536870917]],[&quot;^1A&quot;,[42,&quot;^G&quot;,1629346910603,536870918]],[&quot;^1A&quot;,[42,&quot;^?&quot;,&quot;~u6120a3a8-f392-4d6b-84b4-c6bb4411123f&quot;,536870917]],[&quot;^1A&quot;,[43,&quot;^Q&quot;,1629526968198,536870918]],[&quot;^1A&quot;,[43,&quot;^E&quot;,false,536870917]],[&quot;^1A&quot;,[43,&quot;^19&quot;,&quot;sergey edunov&quot;,536870917]],[&quot;^1A&quot;,[43,&quot;^1=&quot;,&quot;Sergey Edunov&quot;,536870917]],[&quot;^1A&quot;,[43,&quot;^G&quot;,1629526968198,536870918]],[&quot;^1A&quot;,[43,&quot;^?&quot;,&quot;~u6129d874-cfdc-40d2-bace-a11a32e53a3a&quot;,536871175]],[&quot;^1A&quot;,[44,&quot;^Q&quot;,1629526968199,536870918]],[&quot;^1A&quot;,[44,&quot;^E&quot;,false,536870917]],[&quot;^1A&quot;,[44,&quot;^19&quot;,&quot;kritika singh&quot;,536870917]],[&quot;^1A&quot;,[44,&quot;^1=&quot;,&quot;Kritika Singh&quot;,536870917]],[&quot;^1A&quot;,[44,&quot;^G&quot;,1629526968199,536870918]],[&quot;^1A&quot;,[44,&quot;^?&quot;,&quot;~u6129d874-856c-4d05-bf92-0b65b869dd83&quot;,536871175]],[&quot;^1A&quot;,[45,&quot;^Q&quot;,1629346910602,536870918]],[&quot;^1A&quot;,[45,&quot;^E&quot;,false,536870917]],[&quot;^1A&quot;,[45,&quot;^19&quot;,&quot;alexei baevski&quot;,536870917]],[&quot;^1A&quot;,[45,&quot;^1=&quot;,&quot;Alexei Baevski&quot;,536870917]],[&quot;^1A&quot;,[45,&quot;^G&quot;,1629346910602,536870918]],[&quot;^1A&quot;,[45,&quot;^?&quot;,&quot;~u6120a3a8-2c56-4b87-bd5f-969608b4863f&quot;,536870917]],[&quot;^1A&quot;,[46,&quot;^Q&quot;,1629343667322,536870918]],[&quot;^1A&quot;,[46,&quot;^E&quot;,false,536870917]],[&quot;^1A&quot;,[46,&quot;^19&quot;,&quot;computer science - machine learning&quot;,536870917]],[&quot;^1A&quot;,[46,&quot;^1=&quot;,&quot;Computer Science - Machine Learning&quot;,536870917]],[&quot;^1A&quot;,[46,&quot;^G&quot;,1629343667322,536870918]],[&quot;^1A&quot;,[46,&quot;^?&quot;,&quot;~u6129d874-9fbc-45c7-8817-81a9f3d0f6ae&quot;,536871175]],[&quot;^1A&quot;,[47,&quot;^Q&quot;,1629356502566,536870918]],[&quot;^1A&quot;,[47,&quot;^E&quot;,false,536870917]],[&quot;^1A&quot;,[47,&quot;^19&quot;,&quot;eess]&quot;,536870917]],[&quot;^1A&quot;,[47,&quot;^1=&quot;,&quot;eess]&quot;,536870917]],[&quot;^1A&quot;,[47,&quot;^G&quot;,1629356502566,536870918]],[&quot;^1A&quot;,[47,&quot;^?&quot;,&quot;~u6129d874-ca9a-4881-bb2d-80265dd9a3a1&quot;,536871175]],[&quot;^1A&quot;,[49,&quot;^Q&quot;,1629343667322,536870918]],[&quot;^1A&quot;,[49,&quot;^E&quot;,false,536870917]],[&quot;^1A&quot;,[49,&quot;^19&quot;,&quot;attachments&quot;,536870917]],[&quot;^1A&quot;,[49,&quot;^1=&quot;,&quot;Attachments&quot;,536870917]],[&quot;^1A&quot;,[49,&quot;^G&quot;,1629343667322,536870918]],[&quot;^1A&quot;,[49,&quot;^?&quot;,&quot;~u6120a3a8-b440-401b-af16-a567916d6df2&quot;,536870917]],[&quot;^1A&quot;,[51,&quot;^Q&quot;,1629526968199,536870918]],[&quot;^1A&quot;,[51,&quot;^E&quot;,false,536870917]],[&quot;^1A&quot;,[51,&quot;^19&quot;,&quot;arxiv:1910.12367 [cs&quot;,536870917]],[&quot;^1A&quot;,[51,&quot;^1=&quot;,&quot;arXiv:1910.12367 [cs&quot;,536870917]],[&quot;^1A&quot;,[51,&quot;^G&quot;,1629526968199,536870918]],[&quot;^1A&quot;,[51,&quot;^?&quot;,&quot;~u6129d874-6370-4f34-a4bf-ef0847940073&quot;,536871175]],[&quot;^1A&quot;,[52,&quot;^Q&quot;,1629343667322,536870918]],[&quot;^1A&quot;,[52,&quot;^E&quot;,false,536870917]],[&quot;^1A&quot;,[52,&quot;^19&quot;,&quot;electrical engineering and systems science - audio and speech processing&quot;,536870917]],[&quot;^1A&quot;,[52,&quot;^1=&quot;,&quot;Electrical Engineering and Systems Science - Audio and Speech Processing&quot;,536870917]],[&quot;^1A&quot;,[52,&quot;^G&quot;,1629343667322,536870918]],[&quot;^1A&quot;,[52,&quot;^?&quot;,&quot;~u6129d874-ad74-4897-a4d0-ccff5284ded1&quot;,536871175]],[&quot;^1A&quot;,[53,&quot;^Q&quot;,1629526968198,536870918]],[&quot;^1A&quot;,[53,&quot;^E&quot;,false,536870917]],[&quot;^1A&quot;,[53,&quot;^19&quot;,&quot;jun liu&quot;,536870917]],[&quot;^1A&quot;,[53,&quot;^1=&quot;,&quot;Jun Liu&quot;,536870917]],[&quot;^1A&quot;,[53,&quot;^G&quot;,1629526968198,536870918]],[&quot;^1A&quot;,[53,&quot;^?&quot;,&quot;~u6129d874-a105-4de1-9097-ddab0377a0d5&quot;,536871175]],[&quot;^1A&quot;,[63,&quot;~:block/anchor&quot;,&quot;http-3a--2f--2f-www-2e-cs-2e-toronto-2e-edu-2f--7e-asamir-2f-&quot;,536870917]],[&quot;^1A&quot;,[63,&quot;^S&quot;,[],536870917]],[&quot;^1A&quot;,[63,&quot;~:block/children&quot;,[&quot;~#set&quot;,[]],536870917]],[&quot;^1A&quot;,[63,&quot;^[&quot;,&quot;[http://www.cs.toronto.edu/~asamir/](http://www.cs.toronto.edu/~asamir/)&quot;,536870917]],[&quot;^1A&quot;,[63,&quot;^W&quot;,&quot;~:markdown&quot;,536870917]],[&quot;^1A&quot;,[63,&quot;^K&quot;,30,536870917]],[&quot;^1A&quot;,[63,&quot;^X&quot;,1,536870917]],[&quot;^1A&quot;,[63,&quot;^U&quot;,[&quot;^ &quot;,&quot;~:timestamps&quot;,[],&quot;~:properties&quot;,[],&quot;~:start-pos&quot;,0,&quot;~:end-pos&quot;,74],536870917]],[&quot;^1A&quot;,[63,&quot;^17&quot;,30,536870917]],[&quot;^1A&quot;,[63,&quot;^13&quot;,30,536870917]],[&quot;^1A&quot;,[63,&quot;^Z&quot;,[[&quot;Link&quot;,[&quot;^ &quot;,&quot;~:url&quot;,[&quot;Complex&quot;,[&quot;^ &quot;,&quot;~:protocol&quot;,&quot;http&quot;,&quot;~:link&quot;,&quot;www.cs.toronto.edu/~asamir/&quot;]],&quot;~:label&quot;,[[&quot;Plain&quot;,&quot;http://www.cs.toronto.edu/~asamir/&quot;]],&quot;~:full_text&quot;,&quot;[http://www.cs.toronto.edu/~asamir/](http://www.cs.toronto.edu/~asamir/)&quot;,&quot;~:metadata&quot;,&quot;&quot;]]],536870917]],[&quot;^1A&quot;,[63,&quot;^1B&quot;,true,536870917]],[&quot;^1A&quot;,[63,&quot;^?&quot;,&quot;~u6120a3a8-3306-4362-806f-71f059031903&quot;,536870917]],[&quot;^1A&quot;,[99,&quot;^11&quot;,&quot;^10&quot;,536870919]],[&quot;^1A&quot;,[100,&quot;^2&quot;,&quot;0.0.1&quot;,536870920]],[&quot;^1A&quot;,[100,&quot;^11&quot;,&quot;^2&quot;,536870920]],[&quot;^1A&quot;,[101,&quot;^[&quot;,&quot;title:: attachments:wav2vec%202.0%20A%20Framework%20for%20Self-Supervised%20Learning%20of%20Speech%20Representation.pdf&quot;,536870927]],[&quot;^1A&quot;,[101,&quot;^W&quot;,&quot;^1F&quot;,536870927]],[&quot;^1A&quot;,[101,&quot;^=&quot;,true,536870927]],[&quot;^1A&quot;,[101,&quot;^D&quot;,[&quot;^ &quot;,&quot;~:title&quot;,&quot;attachments:wav2vec%202.0%20A%20Framework%20for%20Self-Supervised%20Learning%20of%20Speech%20Representation.pdf&quot;],536870927]],[&quot;^1A&quot;,[101,&quot;^P&quot;,[&quot;^1@&quot;,[&quot;^1Q&quot;]],536870927]],[&quot;^1A&quot;,[101,&quot;^1B&quot;,true,536870927]],[&quot;^1A&quot;,[101,&quot;^?&quot;,&quot;~u6120a3c3-295e-4651-9af5-c974c3c8af18&quot;,536870927]],[&quot;^1A&quot;,[102,&quot;^[&quot;,&quot;&quot;,536870927]],[&quot;^1A&quot;,[102,&quot;^W&quot;,&quot;^1F&quot;,536870927]],[&quot;^1A&quot;,[102,&quot;^K&quot;,101,536870927]],[&quot;^1A&quot;,[102,&quot;^P&quot;,[&quot;^1@&quot;,[&quot;^1Q&quot;]],536870927]],[&quot;^1A&quot;,[102,&quot;^1B&quot;,true,536870927]],[&quot;^1A&quot;,[102,&quot;^?&quot;,&quot;~u6120a3c3-709b-49fb-8ee1-2d2dfb0bfd09&quot;,536870927]],[&quot;^1A&quot;,[106,&quot;^Q&quot;,1623196800000,536871176]],[&quot;^1A&quot;,[106,&quot;^V&quot;,20210609,536870959]],[&quot;^1A&quot;,[106,&quot;^E&quot;,true,536870959]],[&quot;^1A&quot;,[106,&quot;^19&quot;,&quot;jun 9th, 2021&quot;,536870959]],[&quot;^1A&quot;,[106,&quot;^1=&quot;,&quot;Jun 9th, 2021&quot;,536870959]],[&quot;^1A&quot;,[106,&quot;^G&quot;,1623196800000,536871176]],[&quot;^1A&quot;,[106,&quot;^?&quot;,&quot;~u6120a475-5004-4880-b116-d93e8d34d27b&quot;,536870959]],[&quot;^1A&quot;,[107,&quot;^Q&quot;,1629530915217,536871176]],[&quot;^1A&quot;,[107,&quot;^E&quot;,false,536870959]],[&quot;^1A&quot;,[107,&quot;^19&quot;,&quot;peter vieting&quot;,536870959]],[&quot;^1A&quot;,[107,&quot;^1=&quot;,&quot;Peter Vieting&quot;,536870959]],[&quot;^1A&quot;,[107,&quot;^G&quot;,1629530915217,536871176]],[&quot;^1A&quot;,[107,&quot;^?&quot;,&quot;~u6120a475-a524-4dbf-b313-16e5c1e9403c&quot;,536870959]],[&quot;^1A&quot;,[108,&quot;^Q&quot;,1629530915215,536871176]],[&quot;^1A&quot;,[108,&quot;^E&quot;,false,536870959]],[&quot;^1A&quot;,[108,&quot;^19&quot;,&quot;christoph lüscher&quot;,536870959]],[&quot;^1A&quot;,[108,&quot;^1=&quot;,&quot;Christoph Lüscher&quot;,536870959]],[&quot;^1A&quot;,[108,&quot;^G&quot;,1629530915215,536871176]],[&quot;^1A&quot;,[108,&quot;^?&quot;,&quot;~u6120a475-193d-4a77-bbe2-577a4499905a&quot;,536870959]],[&quot;^1A&quot;,[109,&quot;^Q&quot;,1629530915215,536871176]],[&quot;^1A&quot;,[109,&quot;^E&quot;,false,536870959]],[&quot;^1A&quot;,[109,&quot;^19&quot;,&quot;wilfried michel&quot;,536870959]],[&quot;^1A&quot;,[109,&quot;^1=&quot;,&quot;Wilfried Michel&quot;,536870959]],[&quot;^1A&quot;,[109,&quot;^G&quot;,1629530915215,536871176]],[&quot;^1A&quot;,[109,&quot;^?&quot;,&quot;~u6120a475-0f66-4b2e-9cd5-26be4d049446&quot;,536870959]],[&quot;^1A&quot;,[110,&quot;^Q&quot;,1629530915215,536871176]],[&quot;^1A&quot;,[110,&quot;^E&quot;,false,536870959]],[&quot;^1A&quot;,[110,&quot;^19&quot;,&quot;ralf schlüter&quot;,536870959]],[&quot;^1A&quot;,[110,&quot;^1=&quot;,&quot;Ralf Schlüter&quot;,536870959]],[&quot;^1A&quot;,[110,&quot;^G&quot;,1629530915215,536871176]],[&quot;^1A&quot;,[110,&quot;^?&quot;,&quot;~u6120a475-778d-40f7-a49d-5b2b9d6acc88&quot;,536870959]],[&quot;^1A&quot;,[111,&quot;^Q&quot;,1629530915215,536871176]],[&quot;^1A&quot;,[111,&quot;^E&quot;,false,536870959]],[&quot;^1A&quot;,[111,&quot;^19&quot;,&quot;hermann ney&quot;,536870959]],[&quot;^1A&quot;,[111,&quot;^1=&quot;,&quot;Hermann Ney&quot;,536870959]],[&quot;^1A&quot;,[111,&quot;^G&quot;,1629530915215,536871176]],[&quot;^1A&quot;,[111,&quot;^?&quot;,&quot;~u6120a475-895a-43d1-89f5-2576514de9de&quot;,536870959]],[&quot;^1A&quot;,[115,&quot;^Q&quot;,1629530915215,536871176]],[&quot;^1A&quot;,[115,&quot;^E&quot;,false,536870981]],[&quot;^1A&quot;,[115,&quot;^19&quot;,&quot;feature replacement and combination for hybrid asr systems&quot;,536870981]],[&quot;^1A&quot;,[115,&quot;^1=&quot;,&quot;Feature Replacement and Combination for Hybrid ASR Systems&quot;,536870981]],[&quot;^1A&quot;,[115,&quot;^D&quot;,[&quot;^ &quot;,&quot;~:tags&quot;,[&quot;^1@&quot;,[&quot;Computer Science - Computation and Language&quot;,&quot;Computer Science - Machine Learning&quot;,&quot;Computer Science - Sound&quot;,&quot;Electrical Engineering and Systems Science - Audio and Speech Processing&quot;]],&quot;~:date&quot;,[&quot;^1E&quot;,[&quot;Jun 9th, 2021&quot;]],&quot;~:extra&quot;,&quot;arXiv: 2104.04298&quot;,&quot;^1Q&quot;,&quot;Feature Replacement and Combination for Hybrid ASR Systems&quot;,&quot;~:item-type&quot;,[&quot;^1E&quot;,[&quot;journalArticle&quot;]],&quot;~:access-date&quot;,&quot;2021-07-07T05:39:04Z&quot;,&quot;~:original-title&quot;,&quot;Feature Replacement and Combination for Hybrid ASR Systems&quot;,&quot;^1K&quot;,&quot;http://arxiv.org/abs/2104.04298&quot;,&quot;~:publication-title&quot;,[&quot;^1E&quot;,[&quot;arXiv:2104.04298 [cs&quot;,&quot;eess]&quot;]],&quot;~:authors&quot;,[&quot;^1E&quot;,[&quot;Peter Vieting&quot;,&quot;Christoph Lüscher&quot;,&quot;Wilfried Michel&quot;,&quot;Ralf Schlüter&quot;,&quot;Hermann Ney&quot;]],&quot;~:library-catalog&quot;,&quot;arXiv.org&quot;,&quot;~:links&quot;,&quot;[Local library](zotero://select/library/items/5JFDDHFZ), [Web library](https://www.zotero.org/users/7048753/items/5JFDDHFZ)&quot;],536870981]],[&quot;^1A&quot;,[115,&quot;^Y&quot;,26,536870981]],[&quot;^1A&quot;,[115,&quot;^Y&quot;,27,536870981]],[&quot;^1A&quot;,[115,&quot;^Y&quot;,46,536870981]],[&quot;^1A&quot;,[115,&quot;^Y&quot;,52,536870981]],[&quot;^1A&quot;,[115,&quot;^G&quot;,1629530915215,536871176]],[&quot;^1A&quot;,[115,&quot;^?&quot;,&quot;~u6129d91c-c33f-47ee-907f-e8af782734ce&quot;,536871220]],[&quot;^1A&quot;,[116,&quot;^S&quot;,[&quot;^1@&quot;,[[&quot;Paragraph&quot;,[[&quot;Break_Line&quot;]]]]],536870981]],[&quot;^1A&quot;,[116,&quot;^[&quot;,&quot;tags:: [[Computer Science - Computation and Language]], [[Computer Science - Machine Learning]], [[Computer Science - Sound]], [[Electrical Engineering and Systems Science - Audio and Speech Processing]]\\ndate:: [[Jun 9th, 2021]]\\nextra:: arXiv: 2104.04298\\ntitle:: Feature Replacement and Combination for Hybrid ASR Systems\\nitem-type:: [[journalArticle]]\\naccess-date:: 2021-07-07T05:39:04Z\\noriginal-title:: Feature Replacement and Combination for Hybrid ASR Systems\\nurl:: http://arxiv.org/abs/2104.04298\\npublication-title:: \\&quot;arXiv:2104.04298 [cs, eess]\\&quot;\\nauthors:: [[Peter Vieting]], [[Christoph Lüscher]], [[Wilfried Michel]], [[Ralf Schlüter]], [[Hermann Ney]]\\nlibrary-catalog:: arXiv.org\\nlinks:: [Local library](zotero://select/library/items/5JFDDHFZ), [Web library](https://www.zotero.org/users/7048753/items/5JFDDHFZ)\\n\\n&quot;,536870981]],[&quot;^1A&quot;,[116,&quot;^W&quot;,&quot;^1F&quot;,536870981]],[&quot;^1A&quot;,[116,&quot;^K&quot;,115,536870981]],[&quot;^1A&quot;,[116,&quot;^X&quot;,1,536870981]],[&quot;^1A&quot;,[116,&quot;^U&quot;,[&quot;^ &quot;,&quot;^1I&quot;,0,&quot;^1J&quot;,823],536870981]],[&quot;^1A&quot;,[116,&quot;^17&quot;,115,536870981]],[&quot;^1A&quot;,[116,&quot;^13&quot;,115,536870981]],[&quot;^1A&quot;,[116,&quot;^12&quot;,24,536870981]],[&quot;^1A&quot;,[116,&quot;^12&quot;,26,536870981]],[&quot;^1A&quot;,[116,&quot;^12&quot;,27,536870981]],[&quot;^1A&quot;,[116,&quot;^12&quot;,46,536870981]],[&quot;^1A&quot;,[116,&quot;^12&quot;,47,536870981]],[&quot;^1A&quot;,[116,&quot;^12&quot;,52,536870981]],[&quot;^1A&quot;,[116,&quot;^12&quot;,106,536870981]],[&quot;^1A&quot;,[116,&quot;^12&quot;,107,536870981]],[&quot;^1A&quot;,[116,&quot;^12&quot;,108,536870981]],[&quot;^1A&quot;,[116,&quot;^12&quot;,109,536870981]],[&quot;^1A&quot;,[116,&quot;^12&quot;,110,536870981]],[&quot;^1A&quot;,[116,&quot;^12&quot;,111,536870981]],[&quot;^1A&quot;,[116,&quot;^12&quot;,115,536870981]],[&quot;^1A&quot;,[116,&quot;^12&quot;,119,536870981]],[&quot;^1A&quot;,[116,&quot;^=&quot;,true,536870981]],[&quot;^1A&quot;,[116,&quot;^D&quot;,[&quot;^ &quot;,&quot;^1R&quot;,[&quot;^1E&quot;,[&quot;Computer Science - Computation and Language&quot;,&quot;Computer Science - Machine Learning&quot;,&quot;Computer Science - Sound&quot;,&quot;Electrical Engineering and Systems Science - Audio and Speech Processing&quot;]],&quot;^1S&quot;,[&quot;^1E&quot;,[&quot;Jun 9th, 2021&quot;]],&quot;^1T&quot;,&quot;arXiv: 2104.04298&quot;,&quot;^1Q&quot;,&quot;Feature Replacement and Combination for Hybrid ASR Systems&quot;,&quot;^1U&quot;,[&quot;^1E&quot;,[&quot;journalArticle&quot;]],&quot;^1V&quot;,&quot;2021-07-07T05:39:04Z&quot;,&quot;^1W&quot;,&quot;Feature Replacement and Combination for Hybrid ASR Systems&quot;,&quot;^1K&quot;,&quot;http://arxiv.org/abs/2104.04298&quot;,&quot;^1X&quot;,[&quot;^1E&quot;,[&quot;arXiv:2104.04298 [cs&quot;,&quot;eess]&quot;]],&quot;^1Y&quot;,[&quot;^1E&quot;,[&quot;Peter Vieting&quot;,&quot;Christoph Lüscher&quot;,&quot;Wilfried Michel&quot;,&quot;Ralf Schlüter&quot;,&quot;Hermann Ney&quot;]],&quot;^1Z&quot;,&quot;arXiv.org&quot;,&quot;^1[&quot;,&quot;[Local library](zotero://select/library/items/5JFDDHFZ), [Web library](https://www.zotero.org/users/7048753/items/5JFDDHFZ)&quot;],536870981]],[&quot;^1A&quot;,[116,&quot;^P&quot;,[&quot;^1@&quot;,[&quot;^1R&quot;,&quot;^1S&quot;,&quot;^1T&quot;,&quot;^1Q&quot;,&quot;^1U&quot;,&quot;^1V&quot;,&quot;^1W&quot;,&quot;^1K&quot;,&quot;^1X&quot;,&quot;^1Y&quot;,&quot;^1Z&quot;,&quot;^1[&quot;]],536870981]],[&quot;^1A&quot;,[116,&quot;^1B&quot;,true,536870981]],[&quot;^1A&quot;,[116,&quot;^?&quot;,&quot;~u6120a4ab-48a8-4b9e-b5ab-4e26a0400b60&quot;,536870981]],[&quot;^1A&quot;,[117,&quot;^1C&quot;,&quot;Abstract&quot;,536870981]],[&quot;^1A&quot;,[117,&quot;^S&quot;,[],536870981]],[&quot;^1A&quot;,[117,&quot;^1D&quot;,[&quot;^1E&quot;,[]],536870981]],[&quot;^1A&quot;,[117,&quot;^[&quot;,&quot;## Abstract&quot;,536870981]],[&quot;^1A&quot;,[117,&quot;^W&quot;,&quot;^1F&quot;,536870981]],[&quot;^1A&quot;,[117,&quot;^14&quot;,2,536870981]],[&quot;^1A&quot;,[117,&quot;^K&quot;,116,536870981]],[&quot;^1A&quot;,[117,&quot;^X&quot;,1,536870981]],[&quot;^1A&quot;,[117,&quot;^U&quot;,[&quot;^ &quot;,&quot;^1G&quot;,[],&quot;^1H&quot;,[],&quot;^1I&quot;,823,&quot;^1J&quot;,835],536870981]],[&quot;^1A&quot;,[117,&quot;^17&quot;,115,536870981]],[&quot;^1A&quot;,[117,&quot;^13&quot;,115,536870981]],[&quot;^1A&quot;,[117,&quot;^12&quot;,115,536870981]],[&quot;^1A&quot;,[117,&quot;~:block/size&quot;,2,536870981]],[&quot;^1A&quot;,[117,&quot;^Z&quot;,[[&quot;Plain&quot;,&quot;Abstract&quot;]],536870981]],[&quot;^1A&quot;,[117,&quot;^15&quot;,&quot;~:heading&quot;,536870981]],[&quot;^1A&quot;,[117,&quot;^1B&quot;,false,536870981]],[&quot;^1A&quot;,[117,&quot;^?&quot;,&quot;~u6120a4ab-769a-42f8-8a00-cab9e6e5fd55&quot;,536870981]],[&quot;^1A&quot;,[118,&quot;^1C&quot;,&quot;Acoustic_modeling_of_raw_waveform_and_learning_feature_extractors_as_part_of_the_neural_network_classifier_has_been_the_goal_of_many_studies_in_the_area_of_automatic_speech_recognition_(ASR)-2e-_Recently-2c-_one_line_of_research_has_focused_on_frameworks_that_can_be_pre_trained_on_audio_only_data_in_an_unsupervised_fashion_and_aim_at_improving_downstream_ASR_tasks-2e-_In_this_work-2c-_we_investigate_the_usefulness_of_one_of_these_front_end_frameworks-2c-_namely_wav2vec-2c-_for_hybrid_ASR_systems-2e-_In_addition_to_deploying_a_pre_trained_feature_extractor-2c-_we_explore_how_to_make_use_of_an_existing_acoustic_model_(AM)_trained_on_the_same_task_with_different_features_as_well-2e-_Another_neural_front_end_which_is_only_trained_together_with_the_supervised_ASR_loss_as_well_as_traditional_Gammatone_features_are_applied_for_comparison-2e-_Moreover-2c-_it_is_shown_that_the_AM_can_be_retrofitted_with_i_vectors_for_speaker_adaptation-2e-_Finally-2c-_the_described_features_are_combined_in_order_to_further_advance_the_performance-2e-_With_the_final_best_system-2c-_we_obtain_a_relative_improvement_of_4-25-_and_6-25-_over_our_previous_best_model_on_the_LibriSpeech_test_clean_and_test_other_sets-2e-&quot;,536870981]],[&quot;^1A&quot;,[118,&quot;^S&quot;,[],536870981]],[&quot;^1A&quot;,[118,&quot;^1D&quot;,[&quot;^1E&quot;,[]],536870981]],[&quot;^1A&quot;,[118,&quot;^[&quot;,&quot;Acoustic modeling of raw waveform and learning feature extractors as part of the neural network classifier has been the goal of many studies in the area of automatic speech recognition (ASR). Recently, one line of research has focused on frameworks that can be pre-trained on audio-only data in an unsupervised fashion and aim at improving downstream ASR tasks. In this work, we investigate the usefulness of one of these front-end frameworks, namely wav2vec, for hybrid ASR systems. In addition to deploying a pre-trained feature extractor, we explore how to make use of an existing acoustic model (AM) trained on the same task with different features as well. Another neural front-end which is only trained together with the supervised ASR loss as well as traditional Gammatone features are applied for comparison. Moreover, it is shown that the AM can be retrofitted with i-vectors for speaker adaptation. Finally, the described features are combined in order to further advance the performance. With the final best system, we obtain a relative improvement of 4% and 6% over our previous best model on the LibriSpeech test-clean and test-other sets.&quot;,536870981]],[&quot;^1A&quot;,[118,&quot;^W&quot;,&quot;^1F&quot;,536870981]],[&quot;^1A&quot;,[118,&quot;^K&quot;,117,536870981]],[&quot;^1A&quot;,[118,&quot;^X&quot;,1,536870981]],[&quot;^1A&quot;,[118,&quot;^U&quot;,[&quot;^ &quot;,&quot;^1G&quot;,[],&quot;^1H&quot;,[],&quot;^1I&quot;,835,&quot;^1J&quot;,1989],536870981]],[&quot;^1A&quot;,[118,&quot;^17&quot;,115,536870981]],[&quot;^1A&quot;,[118,&quot;^13&quot;,115,536870981]],[&quot;^1A&quot;,[118,&quot;^12&quot;,115,536870981]],[&quot;^1A&quot;,[118,&quot;^Z&quot;,[[&quot;Plain&quot;,&quot;Acoustic modeling of raw waveform and learning feature extractors as part of the neural network classifier has been the goal of many studies in the area of automatic speech recognition (ASR). Recently, one line of research has focused on frameworks that can be pre-trained on audio-only data in an unsupervised fashion and aim at improving downstream ASR tasks. In this work, we investigate the usefulness of one of these front-end frameworks, namely wav2vec, for hybrid ASR systems. In addition to deploying a pre-trained feature extractor, we explore how to make use of an existing acoustic model (AM) trained on the same task with different features as well. Another neural front-end which is only trained together with the supervised ASR loss as well as traditional Gammatone features are applied for comparison. Moreover, it is shown that the AM can be retrofitted with i-vectors for speaker adaptation. Finally, the described features are combined in order to further advance the performance. With the final best system, we obtain a relative improvement of 4% and 6% over our previous best model on the LibriSpeech test-clean and test-other sets.&quot;]],536870981]],[&quot;^1A&quot;,[118,&quot;^1B&quot;,true,536870981]],[&quot;^1A&quot;,[118,&quot;^?&quot;,&quot;~u6120a4ab-6a90-49fc-96a0-d230bd9e1b93&quot;,536870981]],[&quot;^1A&quot;,[119,&quot;^Q&quot;,1629530915215,536871176]],[&quot;^1A&quot;,[119,&quot;^19&quot;,&quot;arxiv:2104.04298 [cs&quot;,536870981]],[&quot;^1A&quot;,[119,&quot;^G&quot;,1629530915215,536871176]],[&quot;^1A&quot;,[209,&quot;^Q&quot;,1629529702656,536871043]],[&quot;^1A&quot;,[209,&quot;^E&quot;,false,536871036]],[&quot;^1A&quot;,[209,&quot;^19&quot;,&quot;training asr models by generation of contextual information&quot;,536871036]],[&quot;^1A&quot;,[209,&quot;^1=&quot;,&quot;Training ASR models by Generation of Contextual Information&quot;,536871036]],[&quot;^1A&quot;,[209,&quot;^D&quot;,[&quot;^ &quot;,&quot;^1R&quot;,[&quot;^1@&quot;,[&quot;Computer Science - Computation and Language&quot;,&quot;Computer Science - Machine Learning&quot;,&quot;Computer Science - Sound&quot;,&quot;Electrical Engineering and Systems Science - Audio and Speech Processing&quot;]],&quot;^1S&quot;,[&quot;^1E&quot;,[&quot;Feb 14th, 2020&quot;]],&quot;^1T&quot;,&quot;arXiv: 1910.12367&quot;,&quot;^1Q&quot;,&quot;Training ASR models by Generation of Contextual Information&quot;,&quot;^1U&quot;,[&quot;^1E&quot;,[&quot;journalArticle&quot;]],&quot;^1V&quot;,&quot;2021-08-21T03:18:11Z&quot;,&quot;^1W&quot;,&quot;Training ASR models by Generation of Contextual Information&quot;,&quot;^1K&quot;,&quot;http://arxiv.org/abs/1910.12367&quot;,&quot;^1X&quot;,[&quot;^1E&quot;,[&quot;arXiv:1910.12367 [cs&quot;,&quot;eess]&quot;]],&quot;^1Y&quot;,[&quot;^1E&quot;,[&quot;Yatharth Saraf&quot;,&quot;Jun Liu&quot;,&quot;Geoffrey Zweig&quot;,&quot;Ross Girshick&quot;,&quot;Yongqiang Wang&quot;,&quot;Frank Zhang&quot;,&quot;Abdelrahman Mohamed&quot;,&quot;Fuchun Peng&quot;,&quot;Kritika Singh&quot;,&quot;Dmytro Okhonko&quot;,&quot;Sergey Edunov&quot;]],&quot;^1Z&quot;,&quot;arXiv.org&quot;,&quot;^1[&quot;,&quot;[Local library](zotero://select/library/items/UUNX2N8G), [Web library](https://www.zotero.org/users/7048753/items/UUNX2N8G)&quot;],536871036]],[&quot;^1A&quot;,[209,&quot;^Y&quot;,26,536871036]],[&quot;^1A&quot;,[209,&quot;^Y&quot;,27,536871036]],[&quot;^1A&quot;,[209,&quot;^Y&quot;,46,536871036]],[&quot;^1A&quot;,[209,&quot;^Y&quot;,52,536871036]],[&quot;^1A&quot;,[209,&quot;^G&quot;,1629529793368,536871069]],[&quot;^1A&quot;,[209,&quot;^?&quot;,&quot;~u6129d91c-9b92-44a8-a084-28dbc2b4acdf&quot;,536871220]],[&quot;^1A&quot;,[244,&quot;^1C&quot;,&quot;&quot;,536871165]],[&quot;^1A&quot;,[244,&quot;^S&quot;,[],536871165]],[&quot;^1A&quot;,[244,&quot;^[&quot;,&quot;&quot;,536871165]],[&quot;^1A&quot;,[244,&quot;^W&quot;,&quot;^1F&quot;,536871165]],[&quot;^1A&quot;,[244,&quot;^E&quot;,false,536871165]],[&quot;^1A&quot;,[244,&quot;^K&quot;,3,536871165]],[&quot;^1A&quot;,[244,&quot;^X&quot;,1,536871165]],[&quot;^1A&quot;,[244,&quot;^17&quot;,3,536871165]],[&quot;^1A&quot;,[244,&quot;^13&quot;,3,536871165]],[&quot;^1A&quot;,[244,&quot;^D&quot;,[&quot;^ &quot;],536871165]],[&quot;^1A&quot;,[244,&quot;^Z&quot;,[],536871165]],[&quot;^1A&quot;,[244,&quot;^1B&quot;,true,536871165]],[&quot;^1A&quot;,[244,&quot;^?&quot;,&quot;~u6120a762-d389-47ed-bfd9-98aa2b775403&quot;,536871165]],[&quot;^1A&quot;,[246,&quot;^S&quot;,[&quot;^1@&quot;,[[&quot;Paragraph&quot;,[[&quot;Break_Line&quot;]]]]],536871175]],[&quot;^1A&quot;,[246,&quot;^[&quot;,&quot;tags:: [[Computer Science - Computation and Language]], [[Computer Science - Machine Learning]], [[Computer Science - Sound]], [[Electrical Engineering and Systems Science - Audio and Speech Processing]]\\ndate:: [[Feb 14th, 2020]]\\nextra:: arXiv: 1910.12367\\ntitle:: Training ASR models by Generation of Contextual Information\\nitem-type:: [[journalArticle]]\\naccess-date:: 2021-08-21T03:18:11Z\\noriginal-title:: Training ASR models by Generation of Contextual Information\\nurl:: http://arxiv.org/abs/1910.12367\\npublication-title:: \\&quot;arXiv:1910.12367 [cs, eess]\\&quot;\\nauthors:: [[Kritika Singh]], [[Dmytro Okhonko]], [[Jun Liu]], [[Yongqiang Wang]], [[Frank Zhang]], [[Ross Girshick]], [[Sergey Edunov]], [[Fuchun Peng]], [[Yatharth Saraf]], [[Geoffrey Zweig]], [[Abdelrahman Mohamed]]\\nlibrary-catalog:: arXiv.org\\nlinks:: [Local library](zotero://select/library/items/UUNX2N8G), [Web library](https://www.zotero.org/users/7048753/items/UUNX2N8G)\\n\\n&quot;,536871175]],[&quot;^1A&quot;,[246,&quot;^W&quot;,&quot;^1F&quot;,536871175]],[&quot;^1A&quot;,[246,&quot;^K&quot;,209,536871175]],[&quot;^1A&quot;,[246,&quot;^X&quot;,1,536871175]],[&quot;^1A&quot;,[246,&quot;^U&quot;,[&quot;^ &quot;,&quot;^1I&quot;,0,&quot;^1J&quot;,934],536871175]],[&quot;^1A&quot;,[246,&quot;^17&quot;,209,536871175]],[&quot;^1A&quot;,[246,&quot;^13&quot;,209,536871175]],[&quot;^1A&quot;,[246,&quot;^12&quot;,24,536871175]],[&quot;^1A&quot;,[246,&quot;^12&quot;,25,536871175]],[&quot;^1A&quot;,[246,&quot;^12&quot;,26,536871175]],[&quot;^1A&quot;,[246,&quot;^12&quot;,27,536871175]],[&quot;^1A&quot;,[246,&quot;^12&quot;,29,536871175]],[&quot;^1A&quot;,[246,&quot;^12&quot;,30,536871175]],[&quot;^1A&quot;,[246,&quot;^12&quot;,32,536871175]],[&quot;^1A&quot;,[246,&quot;^12&quot;,33,536871175]],[&quot;^1A&quot;,[246,&quot;^12&quot;,34,536871175]],[&quot;^1A&quot;,[246,&quot;^12&quot;,35,536871175]],[&quot;^1A&quot;,[246,&quot;^12&quot;,38,536871175]],[&quot;^1A&quot;,[246,&quot;^12&quot;,41,536871175]],[&quot;^1A&quot;,[246,&quot;^12&quot;,43,536871175]],[&quot;^1A&quot;,[246,&quot;^12&quot;,44,536871175]],[&quot;^1A&quot;,[246,&quot;^12&quot;,46,536871175]],[&quot;^1A&quot;,[246,&quot;^12&quot;,47,536871175]],[&quot;^1A&quot;,[246,&quot;^12&quot;,51,536871175]],[&quot;^1A&quot;,[246,&quot;^12&quot;,52,536871175]],[&quot;^1A&quot;,[246,&quot;^12&quot;,53,536871175]],[&quot;^1A&quot;,[246,&quot;^12&quot;,209,536871175]],[&quot;^1A&quot;,[246,&quot;^=&quot;,true,536871175]],[&quot;^1A&quot;,[246,&quot;^D&quot;,[&quot;^ &quot;,&quot;^1R&quot;,[&quot;^1E&quot;,[&quot;Computer Science - Computation and Language&quot;,&quot;Computer Science - Machine Learning&quot;,&quot;Computer Science - Sound&quot;,&quot;Electrical Engineering and Systems Science - Audio and Speech Processing&quot;]],&quot;^1S&quot;,[&quot;^1E&quot;,[&quot;Feb 14th, 2020&quot;]],&quot;^1T&quot;,&quot;arXiv: 1910.12367&quot;,&quot;^1Q&quot;,&quot;Training ASR models by Generation of Contextual Information&quot;,&quot;^1U&quot;,[&quot;^1E&quot;,[&quot;journalArticle&quot;]],&quot;^1V&quot;,&quot;2021-08-21T03:18:11Z&quot;,&quot;^1W&quot;,&quot;Training ASR models by Generation of Contextual Information&quot;,&quot;^1K&quot;,&quot;http://arxiv.org/abs/1910.12367&quot;,&quot;^1X&quot;,[&quot;^1E&quot;,[&quot;arXiv:1910.12367 [cs&quot;,&quot;eess]&quot;]],&quot;^1Y&quot;,[&quot;^1E&quot;,[&quot;Yatharth Saraf&quot;,&quot;Jun Liu&quot;,&quot;Geoffrey Zweig&quot;,&quot;Ross Girshick&quot;,&quot;Yongqiang Wang&quot;,&quot;Frank Zhang&quot;,&quot;Abdelrahman Mohamed&quot;,&quot;Fuchun Peng&quot;,&quot;Kritika Singh&quot;,&quot;Dmytro Okhonko&quot;,&quot;Sergey Edunov&quot;]],&quot;^1Z&quot;,&quot;arXiv.org&quot;,&quot;^1[&quot;,&quot;[Local library](zotero://select/library/items/UUNX2N8G), [Web library](https://www.zotero.org/users/7048753/items/UUNX2N8G)&quot;],536871175]],[&quot;^1A&quot;,[246,&quot;^P&quot;,[&quot;^1@&quot;,[&quot;^1R&quot;,&quot;^1S&quot;,&quot;^1T&quot;,&quot;^1Q&quot;,&quot;^1U&quot;,&quot;^1V&quot;,&quot;^1W&quot;,&quot;^1K&quot;,&quot;^1X&quot;,&quot;^1Y&quot;,&quot;^1Z&quot;,&quot;^1[&quot;]],536871175]],[&quot;^1A&quot;,[246,&quot;^L&quot;,24,536871175]],[&quot;^1A&quot;,[246,&quot;^L&quot;,25,536871175]],[&quot;^1A&quot;,[246,&quot;^L&quot;,26,536871175]],[&quot;^1A&quot;,[246,&quot;^L&quot;,27,536871175]],[&quot;^1A&quot;,[246,&quot;^L&quot;,29,536871175]],[&quot;^1A&quot;,[246,&quot;^L&quot;,30,536871175]],[&quot;^1A&quot;,[246,&quot;^L&quot;,32,536871175]],[&quot;^1A&quot;,[246,&quot;^L&quot;,33,536871175]],[&quot;^1A&quot;,[246,&quot;^L&quot;,34,536871175]],[&quot;^1A&quot;,[246,&quot;^L&quot;,35,536871175]],[&quot;^1A&quot;,[246,&quot;^L&quot;,38,536871175]],[&quot;^1A&quot;,[246,&quot;^L&quot;,41,536871175]],[&quot;^1A&quot;,[246,&quot;^L&quot;,43,536871175]],[&quot;^1A&quot;,[246,&quot;^L&quot;,44,536871175]],[&quot;^1A&quot;,[246,&quot;^L&quot;,46,536871175]],[&quot;^1A&quot;,[246,&quot;^L&quot;,47,536871175]],[&quot;^1A&quot;,[246,&quot;^L&quot;,51,536871175]],[&quot;^1A&quot;,[246,&quot;^L&quot;,52,536871175]],[&quot;^1A&quot;,[246,&quot;^L&quot;,53,536871175]],[&quot;^1A&quot;,[246,&quot;^1B&quot;,true,536871175]],[&quot;^1A&quot;,[246,&quot;^?&quot;,&quot;~u6129d874-40f0-459c-816d-018efa6843a9&quot;,536871175]],[&quot;^1A&quot;,[247,&quot;^1C&quot;,&quot;TLDR&quot;,536871175]],[&quot;^1A&quot;,[247,&quot;^S&quot;,[],536871175]],[&quot;^1A&quot;,[247,&quot;^1D&quot;,[&quot;^1E&quot;,[]],536871175]],[&quot;^1A&quot;,[247,&quot;^[&quot;,&quot;## TLDR&quot;,536871175]],[&quot;^1A&quot;,[247,&quot;^W&quot;,&quot;^1F&quot;,536871175]],[&quot;^1A&quot;,[247,&quot;^14&quot;,2,536871175]],[&quot;^1A&quot;,[247,&quot;^K&quot;,246,536871175]],[&quot;^1A&quot;,[247,&quot;^X&quot;,1,536871175]],[&quot;^1A&quot;,[247,&quot;^U&quot;,[&quot;^ &quot;,&quot;^1G&quot;,[],&quot;^1H&quot;,[],&quot;^1I&quot;,934,&quot;^1J&quot;,942],536871175]],[&quot;^1A&quot;,[247,&quot;^17&quot;,209,536871175]],[&quot;^1A&quot;,[247,&quot;^13&quot;,209,536871175]],[&quot;^1A&quot;,[247,&quot;^12&quot;,209,536871175]],[&quot;^1A&quot;,[247,&quot;^20&quot;,2,536871175]],[&quot;^1A&quot;,[247,&quot;^Z&quot;,[[&quot;Plain&quot;,&quot;TLDR&quot;]],536871175]],[&quot;^1A&quot;,[247,&quot;^15&quot;,&quot;^21&quot;,536871175]],[&quot;^1A&quot;,[247,&quot;^1B&quot;,false,536871175]],[&quot;^1A&quot;,[247,&quot;^?&quot;,&quot;~u6129d874-cefe-496c-b50c-c4677990eb95&quot;,536871175]],[&quot;^1A&quot;,[248,&quot;^1C&quot;,&quot;Use_weak_supervision_from_social_media_posts_and_augment_it_with_supervised_training_for_surpassing_supervised_only_training_results-2e-_3_main_scenarios___clean-2c-_noisy_and_extreme___are_used_to_show_results-2e-&quot;,536871175]],[&quot;^1A&quot;,[248,&quot;^S&quot;,[],536871175]],[&quot;^1A&quot;,[248,&quot;^1D&quot;,[&quot;^1E&quot;,[]],536871175]],[&quot;^1A&quot;,[248,&quot;^[&quot;,&quot;Use weak supervision from social media posts and augment it with supervised training for surpassing supervised only training results. 3 main scenarios - clean, noisy and _extreme_ - are used to show results.&quot;,536871175]],[&quot;^1A&quot;,[248,&quot;^W&quot;,&quot;^1F&quot;,536871175]],[&quot;^1A&quot;,[248,&quot;^K&quot;,247,536871175]],[&quot;^1A&quot;,[248,&quot;^X&quot;,1,536871175]],[&quot;^1A&quot;,[248,&quot;^U&quot;,[&quot;^ &quot;,&quot;^1G&quot;,[],&quot;^1H&quot;,[],&quot;^1I&quot;,942,&quot;^1J&quot;,1152],536871175]],[&quot;^1A&quot;,[248,&quot;^17&quot;,209,536871175]],[&quot;^1A&quot;,[248,&quot;^13&quot;,209,536871175]],[&quot;^1A&quot;,[248,&quot;^12&quot;,209,536871175]],[&quot;^1A&quot;,[248,&quot;^Z&quot;,[[&quot;Plain&quot;,&quot;Use weak supervision from social media posts and augment it with supervised training for surpassing supervised only training results. 3 main scenarios - clean, noisy and &quot;],[&quot;Emphasis&quot;,[[&quot;Italic&quot;],[[&quot;Plain&quot;,&quot;extreme&quot;]]]],[&quot;Plain&quot;,&quot; - are used to show results.&quot;]],536871175]],[&quot;^1A&quot;,[248,&quot;^1B&quot;,true,536871175]],[&quot;^1A&quot;,[248,&quot;^?&quot;,&quot;~u6129d874-9a12-42aa-ae0c-ab55b458b1ae&quot;,536871175]],[&quot;^1A&quot;,[249,&quot;^1C&quot;,&quot;Unique&quot;,536871175]],[&quot;^1A&quot;,[249,&quot;^S&quot;,[],536871175]],[&quot;^1A&quot;,[249,&quot;^1D&quot;,[&quot;^1E&quot;,[]],536871175]],[&quot;^1A&quot;,[249,&quot;^[&quot;,&quot;## Unique&quot;,536871175]],[&quot;^1A&quot;,[249,&quot;^W&quot;,&quot;^1F&quot;,536871175]],[&quot;^1A&quot;,[249,&quot;^14&quot;,2,536871175]],[&quot;^1A&quot;,[249,&quot;^K&quot;,248,536871175]],[&quot;^1A&quot;,[249,&quot;^X&quot;,1,536871175]],[&quot;^1A&quot;,[249,&quot;^U&quot;,[&quot;^ &quot;,&quot;^1G&quot;,[],&quot;^1H&quot;,[],&quot;^1I&quot;,1152,&quot;^1J&quot;,1162],536871175]],[&quot;^1A&quot;,[249,&quot;^17&quot;,209,536871175]],[&quot;^1A&quot;,[249,&quot;^13&quot;,209,536871175]],[&quot;^1A&quot;,[249,&quot;^12&quot;,209,536871175]],[&quot;^1A&quot;,[249,&quot;^20&quot;,2,536871175]],[&quot;^1A&quot;,[249,&quot;^Z&quot;,[[&quot;Plain&quot;,&quot;Unique&quot;]],536871175]],[&quot;^1A&quot;,[249,&quot;^15&quot;,&quot;^21&quot;,536871175]],[&quot;^1A&quot;,[249,&quot;^1B&quot;,false,536871175]],[&quot;^1A&quot;,[249,&quot;^?&quot;,&quot;~u6129d874-0611-44fa-8138-3f7c9f168354&quot;,536871175]],[&quot;^1A&quot;,[250,&quot;^1C&quot;,&quot;Use_of_a_starting__stage_in_training_with_supervised_data_to_properly_initialise_weights-2e-_The__phase_uses_a_mix_of_both_supervised_and_weak_supervised_loss_functions-2e-_A_final_supervised_only__phase_to_polish_-22-decoder_cross_attention_input_audio_sequence_to_be_more_monotonic-22--2e-&quot;,536871175]],[&quot;^1A&quot;,[250,&quot;^S&quot;,[],536871175]],[&quot;^1A&quot;,[250,&quot;^1D&quot;,[&quot;^1E&quot;,[]],536871175]],[&quot;^1A&quot;,[250,&quot;^[&quot;,&quot;Use of a starting `burn-in` stage in training with supervised data to properly initialise weights. The `train-main` phase uses a mix of both supervised and weak supervised loss functions. A final supervised-only `fine-tune` phase to polish \\&quot;decoder cross-attention input audio sequence to be more monotonic\\&quot;.\\nid:: 61208c0d-a528-401a-a53d-6e2a88568b1f&quot;,536871175]],[&quot;^1A&quot;,[250,&quot;^W&quot;,&quot;^1F&quot;,536871175]],[&quot;^1A&quot;,[250,&quot;^K&quot;,249,536871175]],[&quot;^1A&quot;,[250,&quot;^X&quot;,1,536871175]],[&quot;^1A&quot;,[250,&quot;^U&quot;,[&quot;^ &quot;,&quot;^1G&quot;,[],&quot;^1H&quot;,[],&quot;^1I&quot;,1162,&quot;^1J&quot;,1517],536871175]],[&quot;^1A&quot;,[250,&quot;^17&quot;,209,536871175]],[&quot;^1A&quot;,[250,&quot;^13&quot;,209,536871175]],[&quot;^1A&quot;,[250,&quot;^12&quot;,209,536871175]],[&quot;^1A&quot;,[250,&quot;^D&quot;,[&quot;^ &quot;,&quot;~:id&quot;,&quot;61208c0d-a528-401a-a53d-6e2a88568b1f&quot;],536871175]],[&quot;^1A&quot;,[250,&quot;^P&quot;,[&quot;^1@&quot;,[&quot;^22&quot;]],536871175]],[&quot;^1A&quot;,[250,&quot;^Z&quot;,[[&quot;Plain&quot;,&quot;Use of a starting &quot;],[&quot;Code&quot;,&quot;burn-in&quot;],[&quot;Plain&quot;,&quot; stage in training with supervised data to properly initialise weights. The &quot;],[&quot;Code&quot;,&quot;train-main&quot;],[&quot;Plain&quot;,&quot; phase uses a mix of both supervised and weak supervised loss functions. A final supervised-only &quot;],[&quot;Code&quot;,&quot;fine-tune&quot;],[&quot;Plain&quot;,&quot; phase to polish \\&quot;decoder cross-attention input audio sequence to be more monotonic\\&quot;.&quot;]],536871175]],[&quot;^1A&quot;,[250,&quot;^1B&quot;,true,536871175]],[&quot;^1A&quot;,[250,&quot;^?&quot;,&quot;~u61208c0d-a528-401a-a53d-6e2a88568b1f&quot;,536871175]],[&quot;^1A&quot;,[251,&quot;^1C&quot;,&quot;Main_Points&quot;,536871175]],[&quot;^1A&quot;,[251,&quot;^S&quot;,[],536871175]],[&quot;^1A&quot;,[251,&quot;^1D&quot;,[&quot;^1E&quot;,[]],536871175]],[&quot;^1A&quot;,[251,&quot;^[&quot;,&quot;## Main Points&quot;,536871175]],[&quot;^1A&quot;,[251,&quot;^W&quot;,&quot;^1F&quot;,536871175]],[&quot;^1A&quot;,[251,&quot;^14&quot;,2,536871175]],[&quot;^1A&quot;,[251,&quot;^K&quot;,250,536871175]],[&quot;^1A&quot;,[251,&quot;^X&quot;,1,536871175]],[&quot;^1A&quot;,[251,&quot;^U&quot;,[&quot;^ &quot;,&quot;^1G&quot;,[],&quot;^1H&quot;,[],&quot;^1I&quot;,1517,&quot;^1J&quot;,1532],536871175]],[&quot;^1A&quot;,[251,&quot;^17&quot;,209,536871175]],[&quot;^1A&quot;,[251,&quot;^13&quot;,209,536871175]],[&quot;^1A&quot;,[251,&quot;^12&quot;,209,536871175]],[&quot;^1A&quot;,[251,&quot;^20&quot;,2,536871175]],[&quot;^1A&quot;,[251,&quot;^Z&quot;,[[&quot;Plain&quot;,&quot;Main Points&quot;]],536871175]],[&quot;^1A&quot;,[251,&quot;^15&quot;,&quot;^21&quot;,536871175]],[&quot;^1A&quot;,[251,&quot;^1B&quot;,false,536871175]],[&quot;^1A&quot;,[251,&quot;^?&quot;,&quot;~u6129d874-e4fd-468e-89ff-753927d8cdba&quot;,536871175]],[&quot;^1A&quot;,[252,&quot;^1C&quot;,&quot;Two_main_assumptions_regarding_unlabelled_data_(D_w)_and_supervised_data_(D_s)_are_assumed-2e-_Y_w_denotes_the_generated_text_sequence-2c-_Y_s_denotes_actual_audio_content-2c-_X_denotes_input_audio_features-2e-&quot;,536871175]],[&quot;^1A&quot;,[252,&quot;^S&quot;,[],536871175]],[&quot;^1A&quot;,[252,&quot;^1D&quot;,[&quot;^1E&quot;,[[&quot;^?&quot;,&quot;~u6129d874-4aad-42c6-8844-eb3a6cd5712d&quot;],[&quot;^?&quot;,&quot;~u6129d874-fde0-46a4-8c1f-6d7a6d660581&quot;]]],536871175]],[&quot;^1A&quot;,[252,&quot;^[&quot;,&quot;Two main assumptions regarding unlabelled data (D_w) and supervised data (D_s) are assumed. Y_w denotes the generated text sequence, Y_s denotes actual audio content, X denotes input audio features.\\nid:: 61208e0f-900e-4e11-9fb7-fa0311ed09ce&quot;,536871175]],[&quot;^1A&quot;,[252,&quot;^W&quot;,&quot;^1F&quot;,536871175]],[&quot;^1A&quot;,[252,&quot;^K&quot;,251,536871175]],[&quot;^1A&quot;,[252,&quot;^X&quot;,1,536871175]],[&quot;^1A&quot;,[252,&quot;^U&quot;,[&quot;^ &quot;,&quot;^1G&quot;,[],&quot;^1H&quot;,[],&quot;^1I&quot;,1532,&quot;^1J&quot;,1777],536871175]],[&quot;^1A&quot;,[252,&quot;^17&quot;,209,536871175]],[&quot;^1A&quot;,[252,&quot;^13&quot;,209,536871175]],[&quot;^1A&quot;,[252,&quot;^12&quot;,209,536871175]],[&quot;^1A&quot;,[252,&quot;^D&quot;,[&quot;^ &quot;,&quot;^22&quot;,&quot;61208e0f-900e-4e11-9fb7-fa0311ed09ce&quot;],536871175]],[&quot;^1A&quot;,[252,&quot;^P&quot;,[&quot;^1@&quot;,[&quot;^22&quot;]],536871175]],[&quot;^1A&quot;,[252,&quot;^Z&quot;,[[&quot;Plain&quot;,&quot;Two main assumptions regarding unlabelled data (D_w) and supervised data (D_s) are assumed. Y_w denotes the generated text sequence, Y_s denotes actual audio content, X denotes input audio features.&quot;]],536871175]],[&quot;^1A&quot;,[252,&quot;^1B&quot;,true,536871175]],[&quot;^1A&quot;,[252,&quot;^?&quot;,&quot;~u61208e0f-900e-4e11-9fb7-fa0311ed09ce&quot;,536871175]],[&quot;^1A&quot;,[253,&quot;^1C&quot;,&quot;(i)_amount_of_D_w_much_higher_than_D_s-2c-_i-2e-e-2e-_-7c-D_w-7c-_-3e--3e-_-7c-D_s-7c--2e-_Also_D_w_is_more_acoustically_diverse_with_many_more_speakers_than_D_s-2e-&quot;,536871175]],[&quot;^1A&quot;,[253,&quot;^S&quot;,[],536871175]],[&quot;^1A&quot;,[253,&quot;^1D&quot;,[&quot;^1E&quot;,[]],536871175]],[&quot;^1A&quot;,[253,&quot;^[&quot;,&quot;(i) amount of D_w much higher than D_s, i.e. |D_w| &gt;&gt; |D_s|. Also D_w is more acoustically diverse with many more speakers than D_s.&quot;,536871175]],[&quot;^1A&quot;,[253,&quot;^W&quot;,&quot;^1F&quot;,536871175]],[&quot;^1A&quot;,[253,&quot;^K&quot;,252,536871175]],[&quot;^1A&quot;,[253,&quot;^X&quot;,2,536871175]],[&quot;^1A&quot;,[253,&quot;^U&quot;,[&quot;^ &quot;,&quot;^1G&quot;,[],&quot;^1H&quot;,[],&quot;^1I&quot;,1777,&quot;^1J&quot;,1913],536871175]],[&quot;^1A&quot;,[253,&quot;^17&quot;,209,536871175]],[&quot;^1A&quot;,[253,&quot;^13&quot;,252,536871175]],[&quot;^1A&quot;,[253,&quot;^12&quot;,209,536871175]],[&quot;^1A&quot;,[253,&quot;^Z&quot;,[[&quot;Plain&quot;,&quot;(i) amount of D_w much higher than D_s, i.e. |D_w| &gt;&gt; |D_s|. Also D_w is more acoustically diverse with many more speakers than D_s.&quot;]],536871175]],[&quot;^1A&quot;,[253,&quot;^1B&quot;,true,536871175]],[&quot;^1A&quot;,[253,&quot;^?&quot;,&quot;~u6129d874-fde0-46a4-8c1f-6d7a6d660581&quot;,536871175]],[&quot;^1A&quot;,[254,&quot;^1C&quot;,&quot;(ii)_maximising_p(Y_w-7c-X-3b--5c-theta)_is_a_good_enough_proxy_to_maximise_p(Y_s-7c-X-3b--5c-theta)-2e-_Several_training_configurations_are_used_to_validate_this_assumption-2e-&quot;,536871175]],[&quot;^1A&quot;,[254,&quot;^S&quot;,[],536871175]],[&quot;^1A&quot;,[254,&quot;^1D&quot;,[&quot;^1E&quot;,[[&quot;^?&quot;,&quot;~u6129d874-d631-4b39-891e-1897ce30c3f0&quot;],[&quot;^?&quot;,&quot;~u6129d874-ee3c-419a-b5cb-fd3ca8c4dbbb&quot;],[&quot;^?&quot;,&quot;~u6129d874-e748-437e-b40d-3a62354d2197&quot;]]],536871175]],[&quot;^1A&quot;,[254,&quot;^[&quot;,&quot;(ii) maximising p(Y_w|X;$\\\\theta$) is a good enough proxy to maximise p(Y_s|X;$\\\\theta$). Several training configurations are used to validate this assumption.&quot;,536871175]],[&quot;^1A&quot;,[254,&quot;^W&quot;,&quot;^1F&quot;,536871175]],[&quot;^1A&quot;,[254,&quot;^K&quot;,253,536871175]],[&quot;^1A&quot;,[254,&quot;^X&quot;,2,536871175]],[&quot;^1A&quot;,[254,&quot;^U&quot;,[&quot;^ &quot;,&quot;^1G&quot;,[],&quot;^1H&quot;,[],&quot;^1I&quot;,1913,&quot;^1J&quot;,2074],536871175]],[&quot;^1A&quot;,[254,&quot;^17&quot;,209,536871175]],[&quot;^1A&quot;,[254,&quot;^13&quot;,252,536871175]],[&quot;^1A&quot;,[254,&quot;^12&quot;,209,536871175]],[&quot;^1A&quot;,[254,&quot;^Z&quot;,[[&quot;Plain&quot;,&quot;(ii) maximising p(Y_w|X;&quot;],[&quot;Latex_Fragment&quot;,[&quot;Inline&quot;,&quot;\\\\theta&quot;]],[&quot;Plain&quot;,&quot;) is a good enough proxy to maximise p(Y_s|X;&quot;],[&quot;Latex_Fragment&quot;,[&quot;Inline&quot;,&quot;\\\\theta&quot;]],[&quot;Plain&quot;,&quot;). Several training configurations are used to validate this assumption.&quot;]],536871175]],[&quot;^1A&quot;,[254,&quot;^1B&quot;,true,536871175]],[&quot;^1A&quot;,[254,&quot;^?&quot;,&quot;~u6129d874-4aad-42c6-8844-eb3a6cd5712d&quot;,536871175]],[&quot;^1A&quot;,[255,&quot;^1C&quot;,&quot;How_do_we_estimate_similarity_between_Y_s_and_Y_w-3f-_Here_Y_s_is_generated_using_a_baseline_ASR_system-2e-_A_set_intersection_of_words_between_Y_s_and_Y_w_acts_as_a_measure_of_relatedness_between_audio_content_and_weak_labels-2e-&quot;,536871175]],[&quot;^1A&quot;,[255,&quot;^S&quot;,[],536871175]],[&quot;^1A&quot;,[255,&quot;^1D&quot;,[&quot;^1E&quot;,[]],536871175]],[&quot;^1A&quot;,[255,&quot;^[&quot;,&quot;**How do we estimate similarity between Y_s and Y_w?** Here Y_s is generated using a baseline ASR system. _A set intersection of words between Y_s and Y_w acts as a measure of relatedness between audio content and weak labels._&quot;,536871175]],[&quot;^1A&quot;,[255,&quot;^W&quot;,&quot;^1F&quot;,536871175]],[&quot;^1A&quot;,[255,&quot;^K&quot;,254,536871175]],[&quot;^1A&quot;,[255,&quot;^X&quot;,3,536871175]],[&quot;^1A&quot;,[255,&quot;^U&quot;,[&quot;^ &quot;,&quot;^1G&quot;,[],&quot;^1H&quot;,[],&quot;^1I&quot;,2074,&quot;^1J&quot;,2306],536871175]],[&quot;^1A&quot;,[255,&quot;^17&quot;,209,536871175]],[&quot;^1A&quot;,[255,&quot;^13&quot;,254,536871175]],[&quot;^1A&quot;,[255,&quot;^12&quot;,209,536871175]],[&quot;^1A&quot;,[255,&quot;^Z&quot;,[[&quot;Emphasis&quot;,[[&quot;Bold&quot;],[[&quot;Plain&quot;,&quot;How do we estimate similarity between Y_s and Y_w?&quot;]]]],[&quot;Plain&quot;,&quot; Here Y_s is generated using a baseline ASR system. &quot;],[&quot;Emphasis&quot;,[[&quot;Italic&quot;],[[&quot;Plain&quot;,&quot;A set intersection of words between Y_s and Y_w acts as a measure of relatedness between audio content and weak labels.&quot;]]]]],536871175]],[&quot;^1A&quot;,[255,&quot;^1B&quot;,true,536871175]],[&quot;^1A&quot;,[255,&quot;^?&quot;,&quot;~u6129d874-e748-437e-b40d-3a62354d2197&quot;,536871175]],[&quot;^1A&quot;,[256,&quot;^1C&quot;,&quot;maximising_p(Y_w-7c-X-3b-)_improves_p(Y_s-7c-X-3b-)_during_all_phases_of_training-3f-_Authors_study_the_effect_and_conduct_model_training_in_3_different_stages-2c-_as_mentioned_above-2e-&quot;,536871175]],[&quot;^1A&quot;,[256,&quot;^S&quot;,[],536871175]],[&quot;^1A&quot;,[256,&quot;^1D&quot;,[&quot;^1E&quot;,[]],536871175]],[&quot;^1A&quot;,[256,&quot;^[&quot;,&quot;maximising p(Y_w|X;$$\\\\theta$$) improves p(Y_s|X;$$\\\\theta$$) during all phases of training? Authors study the effect and conduct model training in 3 different stages, as mentioned above.&quot;,536871175]],[&quot;^1A&quot;,[256,&quot;^W&quot;,&quot;^1F&quot;,536871175]],[&quot;^1A&quot;,[256,&quot;^K&quot;,255,536871175]],[&quot;^1A&quot;,[256,&quot;^X&quot;,3,536871175]],[&quot;^1A&quot;,[256,&quot;^U&quot;,[&quot;^ &quot;,&quot;^1G&quot;,[],&quot;^1H&quot;,[],&quot;^1I&quot;,2306,&quot;^1J&quot;,2496],536871175]],[&quot;^1A&quot;,[256,&quot;^17&quot;,209,536871175]],[&quot;^1A&quot;,[256,&quot;^13&quot;,254,536871175]],[&quot;^1A&quot;,[256,&quot;^12&quot;,209,536871175]],[&quot;^1A&quot;,[256,&quot;^Z&quot;,[[&quot;Plain&quot;,&quot;maximising p(Y_w|X;&quot;],[&quot;Latex_Fragment&quot;,[&quot;Displayed&quot;,&quot;\\\\theta&quot;]],[&quot;Plain&quot;,&quot;) improves p(Y_s|X;&quot;],[&quot;Latex_Fragment&quot;,[&quot;Displayed&quot;,&quot;\\\\theta&quot;]],[&quot;Plain&quot;,&quot;) during all phases of training? Authors study the effect and conduct model training in 3 different stages, as mentioned above.&quot;]],536871175]],[&quot;^1A&quot;,[256,&quot;^1B&quot;,true,536871175]],[&quot;^1A&quot;,[256,&quot;^?&quot;,&quot;~u6129d874-ee3c-419a-b5cb-fd3ca8c4dbbb&quot;,536871175]],[&quot;^1A&quot;,[257,&quot;^1C&quot;,&quot;Will_such_training_benefit_AM_-2f-_LM_components_separately_or_just_E2E_model-3f-_Authors_show_results_where_just__is_used_for__with_a_CTC_loss_which_also_shows_improvements-2e-&quot;,536871175]],[&quot;^1A&quot;,[257,&quot;^S&quot;,[],536871175]],[&quot;^1A&quot;,[257,&quot;^1D&quot;,[&quot;^1E&quot;,[]],536871175]],[&quot;^1A&quot;,[257,&quot;^[&quot;,&quot;**Will such training benefit AM / LM components separately or just E2E model?** Authors show results where just $$\\\\theta _{enc}$$ is used for `fine-tune` with a CTC loss which also shows improvements.&quot;,536871175]],[&quot;^1A&quot;,[257,&quot;^W&quot;,&quot;^1F&quot;,536871175]],[&quot;^1A&quot;,[257,&quot;^K&quot;,256,536871175]],[&quot;^1A&quot;,[257,&quot;^X&quot;,3,536871175]],[&quot;^1A&quot;,[257,&quot;^U&quot;,[&quot;^ &quot;,&quot;^1G&quot;,[],&quot;^1H&quot;,[],&quot;^1I&quot;,2496,&quot;^1J&quot;,2701],536871175]],[&quot;^1A&quot;,[257,&quot;^17&quot;,209,536871175]],[&quot;^1A&quot;,[257,&quot;^13&quot;,254,536871175]],[&quot;^1A&quot;,[257,&quot;^12&quot;,209,536871175]],[&quot;^1A&quot;,[257,&quot;^Z&quot;,[[&quot;Emphasis&quot;,[[&quot;Bold&quot;],[[&quot;Plain&quot;,&quot;Will such training benefit AM / LM components separately or just E2E model?&quot;]]]],[&quot;Plain&quot;,&quot; Authors show results where just &quot;],[&quot;Latex_Fragment&quot;,[&quot;Displayed&quot;,&quot;\\\\theta _{enc}&quot;]],[&quot;Plain&quot;,&quot; is used for &quot;],[&quot;Code&quot;,&quot;fine-tune&quot;],[&quot;Plain&quot;,&quot; with a CTC loss which also shows improvements.&quot;]],536871175]],[&quot;^1A&quot;,[257,&quot;^1B&quot;,true,536871175]],[&quot;^1A&quot;,[257,&quot;^?&quot;,&quot;~u6129d874-d631-4b39-891e-1897ce30c3f0&quot;,536871175]],[&quot;^1A&quot;,[258,&quot;^1C&quot;,&quot;Training&quot;,536871175]],[&quot;^1A&quot;,[258,&quot;^S&quot;,[],536871175]],[&quot;^1A&quot;,[258,&quot;^1D&quot;,[&quot;^1E&quot;,[]],536871175]],[&quot;^1A&quot;,[258,&quot;^[&quot;,&quot;## Training&quot;,536871175]],[&quot;^1A&quot;,[258,&quot;^W&quot;,&quot;^1F&quot;,536871175]],[&quot;^1A&quot;,[258,&quot;^14&quot;,2,536871175]],[&quot;^1A&quot;,[258,&quot;^K&quot;,252,536871175]],[&quot;^1A&quot;,[258,&quot;^X&quot;,1,536871175]],[&quot;^1A&quot;,[258,&quot;^U&quot;,[&quot;^ &quot;,&quot;^1G&quot;,[],&quot;^1H&quot;,[],&quot;^1I&quot;,2701,&quot;^1J&quot;,2713],536871175]],[&quot;^1A&quot;,[258,&quot;^17&quot;,209,536871175]],[&quot;^1A&quot;,[258,&quot;^13&quot;,209,536871175]],[&quot;^1A&quot;,[258,&quot;^12&quot;,209,536871175]],[&quot;^1A&quot;,[258,&quot;^20&quot;,2,536871175]],[&quot;^1A&quot;,[258,&quot;^Z&quot;,[[&quot;Plain&quot;,&quot;Training&quot;]],536871175]],[&quot;^1A&quot;,[258,&quot;^15&quot;,&quot;^21&quot;,536871175]],[&quot;^1A&quot;,[258,&quot;^1B&quot;,false,536871175]],[&quot;^1A&quot;,[258,&quot;^?&quot;,&quot;~u6129d874-58dd-4d3e-a8c7-94cd2d20d4f4&quot;,536871175]],[&quot;^1A&quot;,[259,&quot;^1C&quot;,&quot;During__phase-2c-_mini_batches_alternated_between_D_w_and_D_s-2e-&quot;,536871175]],[&quot;^1A&quot;,[259,&quot;^S&quot;,[],536871175]],[&quot;^1A&quot;,[259,&quot;^1D&quot;,[&quot;^1E&quot;,[]],536871175]],[&quot;^1A&quot;,[259,&quot;^[&quot;,&quot;During `train-main` phase, mini-batches alternated between D_w and D_s.&quot;,536871175]],[&quot;^1A&quot;,[259,&quot;^W&quot;,&quot;^1F&quot;,536871175]],[&quot;^1A&quot;,[259,&quot;^K&quot;,258,536871175]],[&quot;^1A&quot;,[259,&quot;^X&quot;,1,536871175]],[&quot;^1A&quot;,[259,&quot;^U&quot;,[&quot;^ &quot;,&quot;^1G&quot;,[],&quot;^1H&quot;,[],&quot;^1I&quot;,2713,&quot;^1J&quot;,2787],536871175]],[&quot;^1A&quot;,[259,&quot;^17&quot;,209,536871175]],[&quot;^1A&quot;,[259,&quot;^13&quot;,209,536871175]],[&quot;^1A&quot;,[259,&quot;^12&quot;,209,536871175]],[&quot;^1A&quot;,[259,&quot;^Z&quot;,[[&quot;Plain&quot;,&quot;During &quot;],[&quot;Code&quot;,&quot;train-main&quot;],[&quot;Plain&quot;,&quot; phase, mini-batches alternated between D_w and D_s.&quot;]],536871175]],[&quot;^1A&quot;,[259,&quot;^1B&quot;,true,536871175]],[&quot;^1A&quot;,[259,&quot;^?&quot;,&quot;~u6129d874-fe11-4687-9782-5a796988f699&quot;,536871175]],[&quot;^1A&quot;,[260,&quot;^1C&quot;,&quot;Input_features_are_regular_80_dimensions_mel_scale_log_filter_bank_features___computed_over_16ms_with_10ms_shift-2e-&quot;,536871175]],[&quot;^1A&quot;,[260,&quot;^S&quot;,[],536871175]],[&quot;^1A&quot;,[260,&quot;^1D&quot;,[&quot;^1E&quot;,[]],536871175]],[&quot;^1A&quot;,[260,&quot;^[&quot;,&quot;Input features are regular 80 dimensions mel-scale log filter bank features - computed over 16ms with 10ms shift.&quot;,536871175]],[&quot;^1A&quot;,[260,&quot;^W&quot;,&quot;^1F&quot;,536871175]],[&quot;^1A&quot;,[260,&quot;^K&quot;,259,536871175]],[&quot;^1A&quot;,[260,&quot;^X&quot;,1,536871175]],[&quot;^1A&quot;,[260,&quot;^U&quot;,[&quot;^ &quot;,&quot;^1G&quot;,[],&quot;^1H&quot;,[],&quot;^1I&quot;,2787,&quot;^1J&quot;,2903],536871175]],[&quot;^1A&quot;,[260,&quot;^17&quot;,209,536871175]],[&quot;^1A&quot;,[260,&quot;^13&quot;,209,536871175]],[&quot;^1A&quot;,[260,&quot;^12&quot;,209,536871175]],[&quot;^1A&quot;,[260,&quot;^Z&quot;,[[&quot;Plain&quot;,&quot;Input features are regular 80 dimensions mel-scale log filter bank features - computed over 16ms with 10ms shift.&quot;]],536871175]],[&quot;^1A&quot;,[260,&quot;^1B&quot;,true,536871175]],[&quot;^1A&quot;,[260,&quot;^?&quot;,&quot;~u6129d874-2689-4460-a738-8c5c3a7c2f22&quot;,536871175]],[&quot;^1A&quot;,[261,&quot;^1C&quot;,&quot;Use_AdaDelta_for_training_with__and_gradient_clipping_at_10-2e-0_where_total_gradients_are_scaled_by_the_number_of_utterances_in_each_minibatch-2e-&quot;,536871175]],[&quot;^1A&quot;,[261,&quot;^S&quot;,[],536871175]],[&quot;^1A&quot;,[261,&quot;^1D&quot;,[&quot;^1E&quot;,[]],536871175]],[&quot;^1A&quot;,[261,&quot;^[&quot;,&quot;Use AdaDelta for training with `fixed lr=1.0` and gradient clipping at 10.0 where total gradients are scaled by the number of utterances in each minibatch.&quot;,536871175]],[&quot;^1A&quot;,[261,&quot;^W&quot;,&quot;^1F&quot;,536871175]],[&quot;^1A&quot;,[261,&quot;^K&quot;,260,536871175]],[&quot;^1A&quot;,[261,&quot;^X&quot;,1,536871175]],[&quot;^1A&quot;,[261,&quot;^U&quot;,[&quot;^ &quot;,&quot;^1G&quot;,[],&quot;^1H&quot;,[],&quot;^1I&quot;,2903,&quot;^1J&quot;,3061],536871175]],[&quot;^1A&quot;,[261,&quot;^17&quot;,209,536871175]],[&quot;^1A&quot;,[261,&quot;^13&quot;,209,536871175]],[&quot;^1A&quot;,[261,&quot;^12&quot;,209,536871175]],[&quot;^1A&quot;,[261,&quot;^Z&quot;,[[&quot;Plain&quot;,&quot;Use AdaDelta for training with &quot;],[&quot;Code&quot;,&quot;fixed lr=1.0&quot;],[&quot;Plain&quot;,&quot; and gradient clipping at 10.0 where total gradients are scaled by the number of utterances in each minibatch.&quot;]],536871175]],[&quot;^1A&quot;,[261,&quot;^1B&quot;,true,536871175]],[&quot;^1A&quot;,[261,&quot;^?&quot;,&quot;~u6129d874-df25-4cd0-b49d-ce9dd6b60233&quot;,536871175]],[&quot;^1A&quot;,[262,&quot;^1C&quot;,&quot;Explanation_for_using_a__phase_in_training&quot;,536871175]],[&quot;^1A&quot;,[262,&quot;^S&quot;,[],536871175]],[&quot;^1A&quot;,[262,&quot;^1D&quot;,[&quot;^1E&quot;,[]],536871175]],[&quot;^1A&quot;,[262,&quot;^[&quot;,&quot;## Explanation for using a `burn-in` phase in training&quot;,536871175]],[&quot;^1A&quot;,[262,&quot;^W&quot;,&quot;^1F&quot;,536871175]],[&quot;^1A&quot;,[262,&quot;^14&quot;,2,536871175]],[&quot;^1A&quot;,[262,&quot;^K&quot;,261,536871175]],[&quot;^1A&quot;,[262,&quot;^X&quot;,1,536871175]],[&quot;^1A&quot;,[262,&quot;^U&quot;,[&quot;^ &quot;,&quot;^1G&quot;,[],&quot;^1H&quot;,[],&quot;^1I&quot;,3061,&quot;^1J&quot;,3116],536871175]],[&quot;^1A&quot;,[262,&quot;^17&quot;,209,536871175]],[&quot;^1A&quot;,[262,&quot;^13&quot;,209,536871175]],[&quot;^1A&quot;,[262,&quot;^12&quot;,209,536871175]],[&quot;^1A&quot;,[262,&quot;^20&quot;,2,536871175]],[&quot;^1A&quot;,[262,&quot;^Z&quot;,[[&quot;Plain&quot;,&quot;Explanation for using a &quot;],[&quot;Code&quot;,&quot;burn-in&quot;],[&quot;Plain&quot;,&quot; phase in training&quot;]],536871175]],[&quot;^1A&quot;,[262,&quot;^15&quot;,&quot;^21&quot;,536871175]],[&quot;^1A&quot;,[262,&quot;^1B&quot;,false,536871175]],[&quot;^1A&quot;,[262,&quot;^?&quot;,&quot;~u6129d874-7af8-4383-9b3e-72c48eabbd80&quot;,536871175]],[&quot;^1A&quot;,[263,&quot;^1C&quot;,&quot;image-2e-png&quot;,536871175]],[&quot;^1A&quot;,[263,&quot;^S&quot;,[],536871175]],[&quot;^1A&quot;,[263,&quot;^1D&quot;,[&quot;^1E&quot;,[[&quot;^?&quot;,&quot;~u6129d874-4c03-4de6-9929-6229e23961b4&quot;],[&quot;^?&quot;,&quot;~u6129d874-4cd7-4bd5-98e0-ca5911867e9a&quot;]]],536871175]],[&quot;^1A&quot;,[263,&quot;^[&quot;,&quot;![image.png](../assets/image_1629525676888_0.png)&quot;,536871175]],[&quot;^1A&quot;,[263,&quot;^W&quot;,&quot;^1F&quot;,536871175]],[&quot;^1A&quot;,[263,&quot;^K&quot;,262,536871175]],[&quot;^1A&quot;,[263,&quot;^X&quot;,1,536871175]],[&quot;^1A&quot;,[263,&quot;^U&quot;,[&quot;^ &quot;,&quot;^1G&quot;,[],&quot;^1H&quot;,[],&quot;^1I&quot;,3116,&quot;^1J&quot;,3168],536871175]],[&quot;^1A&quot;,[263,&quot;^17&quot;,209,536871175]],[&quot;^1A&quot;,[263,&quot;^13&quot;,209,536871175]],[&quot;^1A&quot;,[263,&quot;^12&quot;,209,536871175]],[&quot;^1A&quot;,[263,&quot;^Z&quot;,[[&quot;Link&quot;,[&quot;^ &quot;,&quot;^1K&quot;,[&quot;Search&quot;,&quot;../assets/image_1629525676888_0.png&quot;],&quot;^1N&quot;,[[&quot;Plain&quot;,&quot;image.png&quot;]],&quot;^1O&quot;,&quot;![image.png](../assets/image_1629525676888_0.png)&quot;,&quot;^1P&quot;,&quot;&quot;]]],536871175]],[&quot;^1A&quot;,[263,&quot;^1B&quot;,true,536871175]],[&quot;^1A&quot;,[263,&quot;^?&quot;,&quot;~u6129d874-7038-4d4f-9dd7-1771a1b6ce52&quot;,536871175]],[&quot;^1A&quot;,[264,&quot;^1C&quot;,&quot;Issue_with_weak_supervision_in_encoder_decoder_setting_is_that_decoder_is_not_able_to_refine_encoder_representations_easily-2c-_since_the_weak_labels_are_not_aligned_with_input_sequence-2e-&quot;,536871175]],[&quot;^1A&quot;,[264,&quot;^S&quot;,[],536871175]],[&quot;^1A&quot;,[264,&quot;^1D&quot;,[&quot;^1E&quot;,[]],536871175]],[&quot;^1A&quot;,[264,&quot;^[&quot;,&quot;Issue with weak supervision in encoder-decoder setting is that decoder is not able to refine encoder representations easily, since the weak labels are not aligned with input sequence.&quot;,536871175]],[&quot;^1A&quot;,[264,&quot;^W&quot;,&quot;^1F&quot;,536871175]],[&quot;^1A&quot;,[264,&quot;^K&quot;,263,536871175]],[&quot;^1A&quot;,[264,&quot;^X&quot;,2,536871175]],[&quot;^1A&quot;,[264,&quot;^U&quot;,[&quot;^ &quot;,&quot;^1G&quot;,[],&quot;^1H&quot;,[],&quot;^1I&quot;,3168,&quot;^1J&quot;,3355],536871175]],[&quot;^1A&quot;,[264,&quot;^17&quot;,209,536871175]],[&quot;^1A&quot;,[264,&quot;^13&quot;,263,536871175]],[&quot;^1A&quot;,[264,&quot;^12&quot;,209,536871175]],[&quot;^1A&quot;,[264,&quot;^Z&quot;,[[&quot;Plain&quot;,&quot;Issue with weak supervision in encoder-decoder setting is that decoder is not able to refine encoder representations easily, since the weak labels are not aligned with input sequence.&quot;]],536871175]],[&quot;^1A&quot;,[264,&quot;^1B&quot;,true,536871175]],[&quot;^1A&quot;,[264,&quot;^?&quot;,&quot;~u6129d874-4cd7-4bd5-98e0-ca5911867e9a&quot;,536871175]],[&quot;^1A&quot;,[265,&quot;^1C&quot;,&quot;To_circumvent_this-2c-_authors_have_used_the__phase_where_they_initially_train_the_model_with_supervised_data_(all_1000_hrs_which_are_also_used_for__phase)-2e-&quot;,536871175]],[&quot;^1A&quot;,[265,&quot;^S&quot;,[],536871175]],[&quot;^1A&quot;,[265,&quot;^1D&quot;,[&quot;^1E&quot;,[]],536871175]],[&quot;^1A&quot;,[265,&quot;^[&quot;,&quot;To circumvent this, authors have used the `burn-in` phase where they initially train the model with supervised data (all 1000 hrs which are also used for `fine-tune` phase).&quot;,536871175]],[&quot;^1A&quot;,[265,&quot;^W&quot;,&quot;^1F&quot;,536871175]],[&quot;^1A&quot;,[265,&quot;^K&quot;,264,536871175]],[&quot;^1A&quot;,[265,&quot;^X&quot;,2,536871175]],[&quot;^1A&quot;,[265,&quot;^U&quot;,[&quot;^ &quot;,&quot;^1G&quot;,[],&quot;^1H&quot;,[],&quot;^1I&quot;,3355,&quot;^1J&quot;,3532],536871175]],[&quot;^1A&quot;,[265,&quot;^17&quot;,209,536871175]],[&quot;^1A&quot;,[265,&quot;^13&quot;,263,536871175]],[&quot;^1A&quot;,[265,&quot;^12&quot;,209,536871175]],[&quot;^1A&quot;,[265,&quot;^Z&quot;,[[&quot;Plain&quot;,&quot;To circumvent this, authors have used the &quot;],[&quot;Code&quot;,&quot;burn-in&quot;],[&quot;Plain&quot;,&quot; phase where they initially train the model with supervised data (all 1000 hrs which are also used for &quot;],[&quot;Code&quot;,&quot;fine-tune&quot;],[&quot;Plain&quot;,&quot; phase).&quot;]],536871175]],[&quot;^1A&quot;,[265,&quot;^1B&quot;,true,536871175]],[&quot;^1A&quot;,[265,&quot;^?&quot;,&quot;~u6129d874-4c03-4de6-9929-6229e23961b4&quot;,536871175]],[&quot;^1A&quot;,[266,&quot;^1C&quot;,&quot;Results&quot;,536871175]],[&quot;^1A&quot;,[266,&quot;^S&quot;,[],536871175]],[&quot;^1A&quot;,[266,&quot;^1D&quot;,[&quot;^1E&quot;,[]],536871175]],[&quot;^1A&quot;,[266,&quot;^[&quot;,&quot;## Results&quot;,536871175]],[&quot;^1A&quot;,[266,&quot;^W&quot;,&quot;^1F&quot;,536871175]],[&quot;^1A&quot;,[266,&quot;^14&quot;,2,536871175]],[&quot;^1A&quot;,[266,&quot;^K&quot;,263,536871175]],[&quot;^1A&quot;,[266,&quot;^X&quot;,1,536871175]],[&quot;^1A&quot;,[266,&quot;^U&quot;,[&quot;^ &quot;,&quot;^1G&quot;,[],&quot;^1H&quot;,[],&quot;^1I&quot;,3532,&quot;^1J&quot;,3543],536871175]],[&quot;^1A&quot;,[266,&quot;^17&quot;,209,536871175]],[&quot;^1A&quot;,[266,&quot;^13&quot;,209,536871175]],[&quot;^1A&quot;,[266,&quot;^12&quot;,209,536871175]],[&quot;^1A&quot;,[266,&quot;^20&quot;,2,536871175]],[&quot;^1A&quot;,[266,&quot;^Z&quot;,[[&quot;Plain&quot;,&quot;Results&quot;]],536871175]],[&quot;^1A&quot;,[266,&quot;^15&quot;,&quot;^21&quot;,536871175]],[&quot;^1A&quot;,[266,&quot;^1B&quot;,false,536871175]],[&quot;^1A&quot;,[266,&quot;^?&quot;,&quot;~u6129d874-0794-42b1-9375-2aa668c44605&quot;,536871175]],[&quot;^1A&quot;,[267,&quot;^1C&quot;,&quot;image-2e-png&quot;,536871175]],[&quot;^1A&quot;,[267,&quot;^S&quot;,[],536871175]],[&quot;^1A&quot;,[267,&quot;^1D&quot;,[&quot;^1E&quot;,[]],536871175]],[&quot;^1A&quot;,[267,&quot;^[&quot;,&quot;![image.png](../assets/image_1629524983473_0.png)&quot;,536871175]],[&quot;^1A&quot;,[267,&quot;^W&quot;,&quot;^1F&quot;,536871175]],[&quot;^1A&quot;,[267,&quot;^K&quot;,266,536871175]],[&quot;^1A&quot;,[267,&quot;^X&quot;,1,536871175]],[&quot;^1A&quot;,[267,&quot;^U&quot;,[&quot;^ &quot;,&quot;^1G&quot;,[],&quot;^1H&quot;,[],&quot;^1I&quot;,3543,&quot;^1J&quot;,3595],536871175]],[&quot;^1A&quot;,[267,&quot;^17&quot;,209,536871175]],[&quot;^1A&quot;,[267,&quot;^13&quot;,209,536871175]],[&quot;^1A&quot;,[267,&quot;^12&quot;,209,536871175]],[&quot;^1A&quot;,[267,&quot;^Z&quot;,[[&quot;Link&quot;,[&quot;^ &quot;,&quot;^1K&quot;,[&quot;Search&quot;,&quot;../assets/image_1629524983473_0.png&quot;],&quot;^1N&quot;,[[&quot;Plain&quot;,&quot;image.png&quot;]],&quot;^1O&quot;,&quot;![image.png](../assets/image_1629524983473_0.png)&quot;,&quot;^1P&quot;,&quot;&quot;]]],536871175]],[&quot;^1A&quot;,[267,&quot;^1B&quot;,true,536871175]],[&quot;^1A&quot;,[267,&quot;^?&quot;,&quot;~u6129d874-adef-4496-9b9d-beed172f11f0&quot;,536871175]],[&quot;^1A&quot;,[268,&quot;^1C&quot;,&quot;__have_both_encoder_and_decoder_trained_in_E2E_manner-2e-____use__only_and__with_CTC_loss-2e-&quot;,536871175]],[&quot;^1A&quot;,[268,&quot;^S&quot;,[],536871175]],[&quot;^1A&quot;,[268,&quot;^1D&quot;,[&quot;^1E&quot;,[]],536871175]],[&quot;^1A&quot;,[268,&quot;^[&quot;,&quot;~`Encoder-Decoder` - have both encoder and decoder trained in E2E manner. `CTC` - use $$\\\\theta_{enc}$$ only and `fine-tune` with CTC loss.&quot;,536871175]],[&quot;^1A&quot;,[268,&quot;^W&quot;,&quot;^1F&quot;,536871175]],[&quot;^1A&quot;,[268,&quot;^K&quot;,267,536871175]],[&quot;^1A&quot;,[268,&quot;^X&quot;,1,536871175]],[&quot;^1A&quot;,[268,&quot;^U&quot;,[&quot;^ &quot;,&quot;^1G&quot;,[],&quot;^1H&quot;,[],&quot;^1I&quot;,3595,&quot;^1J&quot;,3735],536871175]],[&quot;^1A&quot;,[268,&quot;^17&quot;,209,536871175]],[&quot;^1A&quot;,[268,&quot;^13&quot;,209,536871175]],[&quot;^1A&quot;,[268,&quot;^12&quot;,209,536871175]],[&quot;^1A&quot;,[268,&quot;^Z&quot;,[[&quot;Code&quot;,&quot;Encoder-Decoder&quot;],[&quot;Plain&quot;,&quot; - have both encoder and decoder trained in E2E manner. &quot;],[&quot;Code&quot;,&quot;CTC&quot;],[&quot;Plain&quot;,&quot; - use &quot;],[&quot;Latex_Fragment&quot;,[&quot;Displayed&quot;,&quot;\\\\theta_{enc}&quot;]],[&quot;Plain&quot;,&quot; only and &quot;],[&quot;Code&quot;,&quot;fine-tune&quot;],[&quot;Plain&quot;,&quot; with CTC loss.&quot;]],536871175]],[&quot;^1A&quot;,[268,&quot;^1B&quot;,true,536871175]],[&quot;^1A&quot;,[268,&quot;^?&quot;,&quot;~u6129d874-6a4d-4f6c-ba9f-c79dad57e1b2&quot;,536871175]],[&quot;^1A&quot;,[269,&quot;^1C&quot;,&quot;Even_when_using_additional_2000_hrs_of_supervised_data-2c-_best_weakly_supervised_models_are_consistently_better-2e-_It_might_be_due_to_assumption_(i)-2c-_i-2e-e-2e-_more_diversity_of_acoustic_features_and_speakers_present_in_D_w_than_in_additional_D_s-2e-&quot;,536871175]],[&quot;^1A&quot;,[269,&quot;^S&quot;,[],536871175]],[&quot;^1A&quot;,[269,&quot;^1D&quot;,[&quot;^1E&quot;,[]],536871175]],[&quot;^1A&quot;,[269,&quot;^[&quot;,&quot;Even when using additional 2000 hrs of supervised data, best weakly supervised models are consistently better. It might be due to assumption (i), i.e. more diversity of acoustic features and speakers present in D_w than in additional D_s.&quot;,536871175]],[&quot;^1A&quot;,[269,&quot;^W&quot;,&quot;^1F&quot;,536871175]],[&quot;^1A&quot;,[269,&quot;^K&quot;,268,536871175]],[&quot;^1A&quot;,[269,&quot;^X&quot;,1,536871175]],[&quot;^1A&quot;,[269,&quot;^U&quot;,[&quot;^ &quot;,&quot;^1G&quot;,[],&quot;^1H&quot;,[],&quot;^1I&quot;,3735,&quot;^1J&quot;,3976],536871175]],[&quot;^1A&quot;,[269,&quot;^17&quot;,209,536871175]],[&quot;^1A&quot;,[269,&quot;^13&quot;,209,536871175]],[&quot;^1A&quot;,[269,&quot;^12&quot;,209,536871175]],[&quot;^1A&quot;,[269,&quot;^Z&quot;,[[&quot;Plain&quot;,&quot;Even when using additional 2000 hrs of supervised data, best weakly supervised models are consistently better. It might be due to assumption (i), i.e. more diversity of acoustic features and speakers present in D_w than in additional D_s.&quot;]],536871175]],[&quot;^1A&quot;,[269,&quot;^1B&quot;,true,536871175]],[&quot;^1A&quot;,[269,&quot;^?&quot;,&quot;~u6129d874-db81-4f1e-b403-027278a1106b&quot;,536871175]],[&quot;^1A&quot;,[270,&quot;^1C&quot;,&quot;&quot;,536871175]],[&quot;^1A&quot;,[270,&quot;^S&quot;,[[&quot;Custom&quot;,&quot;note&quot;,null,[[&quot;Paragraph&quot;,[[&quot;Plain&quot;,&quot;A consistent observation with unsupervised training has been the importance of data processing on audio to ensure diversity of acoustic features and speakers. The paper highlights the importance of data filtering with weak supervision as well.&quot;],[&quot;Break_Line&quot;]]]],&quot;A consistent observation with unsupervised training has been the importance of data processing on audio to ensure diversity of acoustic features and speakers. The paper highlights the importance of data filtering with weak supervision as well.\\n&quot;]],536871175]],[&quot;^1A&quot;,[270,&quot;^1D&quot;,[&quot;^1E&quot;,[]],536871175]],[&quot;^1A&quot;,[270,&quot;^[&quot;,&quot;  #+BEGIN_NOTE\\nA consistent observation with unsupervised training has been the importance of data processing on audio to ensure diversity of acoustic features and speakers. The paper highlights the importance of data filtering with weak supervision as well.\\n#+END_NOTE&quot;,536871175]],[&quot;^1A&quot;,[270,&quot;^W&quot;,&quot;^1F&quot;,536871175]],[&quot;^1A&quot;,[270,&quot;^K&quot;,269,536871175]],[&quot;^1A&quot;,[270,&quot;^X&quot;,1,536871175]],[&quot;^1A&quot;,[270,&quot;^U&quot;,[&quot;^ &quot;,&quot;^1G&quot;,[],&quot;^1H&quot;,[],&quot;^1I&quot;,3976,&quot;^1J&quot;,4252],536871175]],[&quot;^1A&quot;,[270,&quot;^17&quot;,209,536871175]],[&quot;^1A&quot;,[270,&quot;^13&quot;,209,536871175]],[&quot;^1A&quot;,[270,&quot;^12&quot;,209,536871175]],[&quot;^1A&quot;,[270,&quot;^Z&quot;,[],536871175]],[&quot;^1A&quot;,[270,&quot;^1B&quot;,true,536871175]],[&quot;^1A&quot;,[270,&quot;^?&quot;,&quot;~u6129d874-adf7-4f9c-bfdc-7b0c64a138ec&quot;,536871175]],[&quot;^1A&quot;,[271,&quot;^1C&quot;,&quot;image-2e-png&quot;,536871175]],[&quot;^1A&quot;,[271,&quot;^S&quot;,[],536871175]],[&quot;^1A&quot;,[271,&quot;^1D&quot;,[&quot;^1E&quot;,[]],536871175]],[&quot;^1A&quot;,[271,&quot;^[&quot;,&quot;![image.png](../assets/image_1629526367648_0.png)&quot;,536871175]],[&quot;^1A&quot;,[271,&quot;^W&quot;,&quot;^1F&quot;,536871175]],[&quot;^1A&quot;,[271,&quot;^K&quot;,270,536871175]],[&quot;^1A&quot;,[271,&quot;^X&quot;,1,536871175]],[&quot;^1A&quot;,[271,&quot;^U&quot;,[&quot;^ &quot;,&quot;^1G&quot;,[],&quot;^1H&quot;,[],&quot;^1I&quot;,4252,&quot;^1J&quot;,4304],536871175]],[&quot;^1A&quot;,[271,&quot;^17&quot;,209,536871175]],[&quot;^1A&quot;,[271,&quot;^13&quot;,209,536871175]],[&quot;^1A&quot;,[271,&quot;^12&quot;,209,536871175]],[&quot;^1A&quot;,[271,&quot;^Z&quot;,[[&quot;Link&quot;,[&quot;^ &quot;,&quot;^1K&quot;,[&quot;Search&quot;,&quot;../assets/image_1629526367648_0.png&quot;],&quot;^1N&quot;,[[&quot;Plain&quot;,&quot;image.png&quot;]],&quot;^1O&quot;,&quot;![image.png](../assets/image_1629526367648_0.png)&quot;,&quot;^1P&quot;,&quot;&quot;]]],536871175]],[&quot;^1A&quot;,[271,&quot;^1B&quot;,true,536871175]],[&quot;^1A&quot;,[271,&quot;^?&quot;,&quot;~u6129d874-a960-400e-a10b-6e97f0247b64&quot;,536871175]],[&quot;^1A&quot;,[272,&quot;^1C&quot;,&quot;Abstract&quot;,536871175]],[&quot;^1A&quot;,[272,&quot;^S&quot;,[],536871175]],[&quot;^1A&quot;,[272,&quot;^1D&quot;,[&quot;^1E&quot;,[]],536871175]],[&quot;^1A&quot;,[272,&quot;^[&quot;,&quot;## Abstract&quot;,536871175]],[&quot;^1A&quot;,[272,&quot;^W&quot;,&quot;^1F&quot;,536871175]],[&quot;^1A&quot;,[272,&quot;^14&quot;,2,536871175]],[&quot;^1A&quot;,[272,&quot;^K&quot;,271,536871175]],[&quot;^1A&quot;,[272,&quot;^X&quot;,1,536871175]],[&quot;^1A&quot;,[272,&quot;^U&quot;,[&quot;^ &quot;,&quot;^1G&quot;,[],&quot;^1H&quot;,[],&quot;^1I&quot;,4304,&quot;^1J&quot;,4316],536871175]],[&quot;^1A&quot;,[272,&quot;^17&quot;,209,536871175]],[&quot;^1A&quot;,[272,&quot;^13&quot;,209,536871175]],[&quot;^1A&quot;,[272,&quot;^12&quot;,209,536871175]],[&quot;^1A&quot;,[272,&quot;^20&quot;,2,536871175]],[&quot;^1A&quot;,[272,&quot;^Z&quot;,[[&quot;Plain&quot;,&quot;Abstract&quot;]],536871175]],[&quot;^1A&quot;,[272,&quot;^15&quot;,&quot;^21&quot;,536871175]],[&quot;^1A&quot;,[272,&quot;^1B&quot;,false,536871175]],[&quot;^1A&quot;,[272,&quot;^?&quot;,&quot;~u6129d874-3f2c-4649-9fe6-88ab37a09da0&quot;,536871175]],[&quot;^1A&quot;,[273,&quot;^1C&quot;,&quot;Supervised_ASR_models_have_reached_unprecedented_levels_of_accuracy-2c-_thanks_in_part_to_ever_increasing_amounts_of_labelled_training_data-2e-_However-2c-_in_many_applications_and_locales-2c-_only_moderate_amounts_of_data_are_available-2c-_which_has_led_to_a_surge_in_semi__and_weakly_supervised_learning_research-2e-_In_this_paper-2c-_we_conduct_a_large_scale_study_evaluating_the_effectiveness_of_weakly_supervised_learning_for_speech_recognition_by_using_loosely_related_contextual_information_as_a_surrogate_for_ground_truth_labels-2e-_For_weakly_supervised_training-2c-_we_use_50k_hours_of_public_English_social_media_videos_along_with_their_respective_titles_and_post_text_to_train_an_encoder_decoder_transformer_model-2e-_Our_best_encoder_decoder_models_achieve_an_average_of_20-2e-8-25-_WER_reduction_over_a_1000_hours_supervised_baseline-2c-_and_an_average_of_13-2e-4-25-_WER_reduction_when_using_only_the_weakly_supervised_encoder_for_CTC_fine_tuning-2e-_Our_results_show_that_our_setup_for_weak_supervision_improved_both_the_encoder_acoustic_representations_as_well_as_the_decoder_language_generation_abilities-2e-&quot;,536871175]],[&quot;^1A&quot;,[273,&quot;^S&quot;,[],536871175]],[&quot;^1A&quot;,[273,&quot;^1D&quot;,[&quot;^1E&quot;,[]],536871175]],[&quot;^1A&quot;,[273,&quot;^[&quot;,&quot;Supervised ASR models have reached unprecedented levels of accuracy, thanks in part to ever-increasing amounts of labelled training data. However, in many applications and locales, only moderate amounts of data are available, which has led to a surge in semi- and weakly-supervised learning research. In this paper, we conduct a large-scale study evaluating the effectiveness of weakly-supervised learning for speech recognition by using loosely related contextual information as a surrogate for ground-truth labels. For weakly supervised training, we use 50k hours of public English social media videos along with their respective titles and post text to train an encoder-decoder transformer model. Our best encoder-decoder models achieve an average of 20.8% WER reduction over a 1000 hours supervised baseline, and an average of 13.4% WER reduction when using only the weakly supervised encoder for CTC fine-tuning. Our results show that our setup for weak supervision improved both the encoder acoustic representations as well as the decoder language generation abilities.&quot;,536871175]],[&quot;^1A&quot;,[273,&quot;^W&quot;,&quot;^1F&quot;,536871175]],[&quot;^1A&quot;,[273,&quot;^K&quot;,272,536871175]],[&quot;^1A&quot;,[273,&quot;^X&quot;,1,536871175]],[&quot;^1A&quot;,[273,&quot;^U&quot;,[&quot;^ &quot;,&quot;^1G&quot;,[],&quot;^1H&quot;,[],&quot;^1I&quot;,4316,&quot;^1J&quot;,5393],536871175]],[&quot;^1A&quot;,[273,&quot;^17&quot;,209,536871175]],[&quot;^1A&quot;,[273,&quot;^13&quot;,209,536871175]],[&quot;^1A&quot;,[273,&quot;^12&quot;,209,536871175]],[&quot;^1A&quot;,[273,&quot;^Z&quot;,[[&quot;Plain&quot;,&quot;Supervised ASR models have reached unprecedented levels of accuracy, thanks in part to ever-increasing amounts of labelled training data. However, in many applications and locales, only moderate amounts of data are available, which has led to a surge in semi- and weakly-supervised learning research. In this paper, we conduct a large-scale study evaluating the effectiveness of weakly-supervised learning for speech recognition by using loosely related contextual information as a surrogate for ground-truth labels. For weakly supervised training, we use 50k hours of public English social media videos along with their respective titles and post text to train an encoder-decoder transformer model. Our best encoder-decoder models achieve an average of 20.8% WER reduction over a 1000 hours supervised baseline, and an average of 13.4% WER reduction when using only the weakly supervised encoder for CTC fine-tuning. Our results show that our setup for weak supervision improved both the encoder acoustic representations as well as the decoder language generation abilities.&quot;]],536871175]],[&quot;^1A&quot;,[273,&quot;^1B&quot;,true,536871175]],[&quot;^1A&quot;,[273,&quot;^?&quot;,&quot;~u6129d874-5897-4b5a-9d70-a95fae4bee74&quot;,536871175]],[&quot;^1A&quot;,[280,&quot;^7&quot;,319,536871675]],[&quot;^1A&quot;,[280,&quot;^Q&quot;,1630132585448,536871241]],[&quot;^1A&quot;,[280,&quot;^W&quot;,&quot;^1F&quot;,536871210]],[&quot;^1A&quot;,[280,&quot;^E&quot;,false,536871210]],[&quot;^1A&quot;,[280,&quot;^19&quot;,&quot;semi-supervised learning of visual features by non-parametrically predicting view assignments with support samples&quot;,536871210]],[&quot;^1A&quot;,[280,&quot;^1=&quot;,&quot;Semi-Supervised Learning of Visual Features by Non-Parametrically Predicting View Assignments with Support Samples&quot;,536871210]],[&quot;^1A&quot;,[280,&quot;^D&quot;,[&quot;^ &quot;,&quot;^1R&quot;,[&quot;^1E&quot;,[&quot;Computer Science - Artificial Intelligence&quot;,&quot;Computer Science - Computer Vision and Pattern Recognition&quot;,&quot;Computer Science - Machine Learning&quot;,&quot;Electrical Engineering and Systems Science - Image and Video Processing&quot;]],&quot;^1S&quot;,[&quot;^1E&quot;,[&quot;Jul 30th, 2021&quot;]],&quot;^1T&quot;,&quot;arXiv: 2104.13963&quot;,&quot;^1Q&quot;,&quot;Semi-Supervised Learning of Visual Features by Non-Parametrically Predicting View Assignments with Support Samples&quot;,&quot;^1U&quot;,[&quot;^1E&quot;,[&quot;journalArticle&quot;]],&quot;^1V&quot;,&quot;2021-08-28T06:27:12Z&quot;,&quot;~:alias&quot;,[&quot;^1E&quot;,[&quot;PAWS&quot;]],&quot;^1W&quot;,&quot;Semi-Supervised Learning of Visual Features by Non-Parametrically Predicting View Assignments with Support Samples&quot;,&quot;^1K&quot;,&quot;http://arxiv.org/abs/2104.13963&quot;,&quot;^1X&quot;,[&quot;^1E&quot;,[&quot;arXiv:2104.13963 [cs&quot;,&quot;eess]&quot;]],&quot;^1Y&quot;,[&quot;^1E&quot;,[&quot;Mahmoud Assran&quot;,&quot;Mathilde Caron&quot;,&quot;Ishan Misra&quot;,&quot;Piotr Bojanowski&quot;,&quot;Armand Joulin&quot;,&quot;Nicolas Ballas&quot;,&quot;Michael Rabbat&quot;]],&quot;^1Z&quot;,&quot;arXiv.org&quot;,&quot;^1[&quot;,&quot;[Local library](zotero://select/library/items/WJZMQAFX), [Web library](https://www.zotero.org/users/7048753/items/WJZMQAFX)&quot;],536871675]],[&quot;^1A&quot;,[280,&quot;^Y&quot;,46,536871675]],[&quot;^1A&quot;,[280,&quot;^Y&quot;,282,536871675]],[&quot;^1A&quot;,[280,&quot;^Y&quot;,283,536871675]],[&quot;^1A&quot;,[280,&quot;^Y&quot;,284,536871675]],[&quot;^1A&quot;,[280,&quot;^G&quot;,1630142348249,536873557]],[&quot;^1A&quot;,[280,&quot;^?&quot;,&quot;~u6129d90a-c596-453b-a9ac-e0a56466564a&quot;,536871210]],[&quot;^1A&quot;,[281,&quot;^[&quot;,&quot;tags:: [[Computer Science - Artificial Intelligence]], [[Computer Science - Computer Vision and Pattern Recognition]], [[Computer Science - Machine Learning]], [[Electrical Engineering and Systems Science - Image and Video Processing]]\\ndate:: [[Jul 30th, 2021]]\\nextra:: arXiv: 2104.13963\\ntitle:: Semi-Supervised Learning of Visual Features by Non-Parametrically Predicting View Assignments with Support Samples\\nitem-type:: [[journalArticle]]\\naccess-date:: 2021-08-28T06:27:12Z\\noriginal-title:: Semi-Supervised Learning of Visual Features by Non-Parametrically Predicting View Assignments with Support Samples\\nurl:: http://arxiv.org/abs/2104.13963\\npublication-title:: \\&quot;arXiv:2104.13963 [cs, eess]\\&quot;\\nauthors:: [[Mahmoud Assran]], [[Mathilde Caron]], [[Ishan Misra]], [[Piotr Bojanowski]], [[Armand Joulin]], [[Nicolas Ballas]], [[Michael Rabbat]]\\nlibrary-catalog:: arXiv.org\\nlinks:: [Local library](zotero://select/library/items/WJZMQAFX), [Web library](https://www.zotero.org/users/7048753/items/WJZMQAFX)\\nalias:: PAWS&quot;,536871675]],[&quot;^1A&quot;,[281,&quot;^W&quot;,&quot;^1F&quot;,536871210]],[&quot;^1A&quot;,[281,&quot;^K&quot;,280,536871210]],[&quot;^1A&quot;,[281,&quot;^X&quot;,1,536871675]],[&quot;^1A&quot;,[281,&quot;^17&quot;,280,536871210]],[&quot;^1A&quot;,[281,&quot;^13&quot;,280,536871210]],[&quot;^1A&quot;,[281,&quot;^12&quot;,24,536871675]],[&quot;^1A&quot;,[281,&quot;^12&quot;,46,536871675]],[&quot;^1A&quot;,[281,&quot;^12&quot;,47,536871675]],[&quot;^1A&quot;,[281,&quot;^12&quot;,280,536871675]],[&quot;^1A&quot;,[281,&quot;^12&quot;,282,536871675]],[&quot;^1A&quot;,[281,&quot;^12&quot;,283,536871675]],[&quot;^1A&quot;,[281,&quot;^12&quot;,284,536871675]],[&quot;^1A&quot;,[281,&quot;^12&quot;,285,536871675]],[&quot;^1A&quot;,[281,&quot;^12&quot;,286,536871675]],[&quot;^1A&quot;,[281,&quot;^12&quot;,287,536871675]],[&quot;^1A&quot;,[281,&quot;^12&quot;,288,536871675]],[&quot;^1A&quot;,[281,&quot;^12&quot;,289,536871675]],[&quot;^1A&quot;,[281,&quot;^12&quot;,290,536871675]],[&quot;^1A&quot;,[281,&quot;^12&quot;,291,536871675]],[&quot;^1A&quot;,[281,&quot;^12&quot;,292,536871675]],[&quot;^1A&quot;,[281,&quot;^12&quot;,317,536871675]],[&quot;^1A&quot;,[281,&quot;^12&quot;,319,536871675]],[&quot;^1A&quot;,[281,&quot;^=&quot;,true,536871675]],[&quot;^1A&quot;,[281,&quot;^D&quot;,[&quot;^ &quot;,&quot;^1R&quot;,[&quot;^1E&quot;,[&quot;Computer Science - Artificial Intelligence&quot;,&quot;Computer Science - Computer Vision and Pattern Recognition&quot;,&quot;Computer Science - Machine Learning&quot;,&quot;Electrical Engineering and Systems Science - Image and Video Processing&quot;]],&quot;^1S&quot;,[&quot;^1E&quot;,[&quot;Jul 30th, 2021&quot;]],&quot;^1T&quot;,&quot;arXiv: 2104.13963&quot;,&quot;^1Q&quot;,&quot;Semi-Supervised Learning of Visual Features by Non-Parametrically Predicting View Assignments with Support Samples&quot;,&quot;^1U&quot;,[&quot;^1E&quot;,[&quot;journalArticle&quot;]],&quot;^1V&quot;,&quot;2021-08-28T06:27:12Z&quot;,&quot;^23&quot;,[&quot;^1E&quot;,[&quot;PAWS&quot;]],&quot;^1W&quot;,&quot;Semi-Supervised Learning of Visual Features by Non-Parametrically Predicting View Assignments with Support Samples&quot;,&quot;^1K&quot;,&quot;http://arxiv.org/abs/2104.13963&quot;,&quot;^1X&quot;,[&quot;^1E&quot;,[&quot;arXiv:2104.13963 [cs&quot;,&quot;eess]&quot;]],&quot;^1Y&quot;,[&quot;^1E&quot;,[&quot;Mahmoud Assran&quot;,&quot;Mathilde Caron&quot;,&quot;Ishan Misra&quot;,&quot;Piotr Bojanowski&quot;,&quot;Armand Joulin&quot;,&quot;Nicolas Ballas&quot;,&quot;Michael Rabbat&quot;]],&quot;^1Z&quot;,&quot;arXiv.org&quot;,&quot;^1[&quot;,&quot;[Local library](zotero://select/library/items/WJZMQAFX), [Web library](https://www.zotero.org/users/7048753/items/WJZMQAFX)&quot;],536871675]],[&quot;^1A&quot;,[281,&quot;^P&quot;,[&quot;^1@&quot;,[&quot;^1R&quot;,&quot;^1S&quot;,&quot;^1T&quot;,&quot;^1Q&quot;,&quot;^1U&quot;,&quot;^1V&quot;,&quot;^23&quot;,&quot;^1W&quot;,&quot;^1K&quot;,&quot;^1X&quot;,&quot;^1Y&quot;,&quot;^1Z&quot;,&quot;^1[&quot;]],536871675]],[&quot;^1A&quot;,[281,&quot;^L&quot;,24,536871675]],[&quot;^1A&quot;,[281,&quot;^L&quot;,46,536871675]],[&quot;^1A&quot;,[281,&quot;^L&quot;,47,536871675]],[&quot;^1A&quot;,[281,&quot;^L&quot;,282,536871675]],[&quot;^1A&quot;,[281,&quot;^L&quot;,283,536871675]],[&quot;^1A&quot;,[281,&quot;^L&quot;,284,536871675]],[&quot;^1A&quot;,[281,&quot;^L&quot;,285,536871675]],[&quot;^1A&quot;,[281,&quot;^L&quot;,286,536871675]],[&quot;^1A&quot;,[281,&quot;^L&quot;,287,536871675]],[&quot;^1A&quot;,[281,&quot;^L&quot;,288,536871675]],[&quot;^1A&quot;,[281,&quot;^L&quot;,289,536871675]],[&quot;^1A&quot;,[281,&quot;^L&quot;,290,536871675]],[&quot;^1A&quot;,[281,&quot;^L&quot;,291,536871675]],[&quot;^1A&quot;,[281,&quot;^L&quot;,292,536871675]],[&quot;^1A&quot;,[281,&quot;^L&quot;,317,536871675]],[&quot;^1A&quot;,[281,&quot;^L&quot;,319,536871675]],[&quot;^1A&quot;,[281,&quot;^1B&quot;,true,536871210]],[&quot;^1A&quot;,[281,&quot;^?&quot;,&quot;~u6129d90a-74e3-448f-a114-26427705f2cb&quot;,536871210]],[&quot;^1A&quot;,[282,&quot;^E&quot;,false,536871210]],[&quot;^1A&quot;,[282,&quot;^19&quot;,&quot;computer science - artificial intelligence&quot;,536871210]],[&quot;^1A&quot;,[282,&quot;^1=&quot;,&quot;Computer Science - Artificial Intelligence&quot;,536871210]],[&quot;^1A&quot;,[282,&quot;^?&quot;,&quot;~u6129d90a-a81f-4b53-ab16-1708404a3fec&quot;,536871210]],[&quot;^1A&quot;,[283,&quot;^E&quot;,false,536871210]],[&quot;^1A&quot;,[283,&quot;^19&quot;,&quot;computer science - computer vision and pattern recognition&quot;,536871210]],[&quot;^1A&quot;,[283,&quot;^1=&quot;,&quot;Computer Science - Computer Vision and Pattern Recognition&quot;,536871210]],[&quot;^1A&quot;,[283,&quot;^?&quot;,&quot;~u6129d90a-1b36-40ed-9067-deed12fccd5b&quot;,536871210]],[&quot;^1A&quot;,[284,&quot;^E&quot;,false,536871210]],[&quot;^1A&quot;,[284,&quot;^19&quot;,&quot;electrical engineering and systems science - image and video processing&quot;,536871210]],[&quot;^1A&quot;,[284,&quot;^1=&quot;,&quot;Electrical Engineering and Systems Science - Image and Video Processing&quot;,536871210]],[&quot;^1A&quot;,[284,&quot;^?&quot;,&quot;~u6129d90a-5068-4756-bb07-047136eefb70&quot;,536871210]],[&quot;^1A&quot;,[285,&quot;^V&quot;,20210730,536871210]],[&quot;^1A&quot;,[285,&quot;^E&quot;,true,536871210]],[&quot;^1A&quot;,[285,&quot;^19&quot;,&quot;jul 30th, 2021&quot;,536871210]],[&quot;^1A&quot;,[285,&quot;^1=&quot;,&quot;Jul 30th, 2021&quot;,536871210]],[&quot;^1A&quot;,[285,&quot;^?&quot;,&quot;~u6129d90a-b005-4737-9d82-8e0238f8a2aa&quot;,536871210]],[&quot;^1A&quot;,[286,&quot;^E&quot;,false,536871210]],[&quot;^1A&quot;,[286,&quot;^19&quot;,&quot;mahmoud assran&quot;,536871210]],[&quot;^1A&quot;,[286,&quot;^1=&quot;,&quot;Mahmoud Assran&quot;,536871210]],[&quot;^1A&quot;,[286,&quot;^?&quot;,&quot;~u6129d90a-8cf2-4558-b24f-ad32618c3ca9&quot;,536871210]],[&quot;^1A&quot;,[287,&quot;^E&quot;,false,536871210]],[&quot;^1A&quot;,[287,&quot;^19&quot;,&quot;mathilde caron&quot;,536871210]],[&quot;^1A&quot;,[287,&quot;^1=&quot;,&quot;Mathilde Caron&quot;,536871210]],[&quot;^1A&quot;,[287,&quot;^?&quot;,&quot;~u6129d90a-2cd4-47fd-a4d5-6efb293c8f75&quot;,536871210]],[&quot;^1A&quot;,[288,&quot;^E&quot;,false,536871210]],[&quot;^1A&quot;,[288,&quot;^19&quot;,&quot;ishan misra&quot;,536871210]],[&quot;^1A&quot;,[288,&quot;^1=&quot;,&quot;Ishan Misra&quot;,536871210]],[&quot;^1A&quot;,[288,&quot;^?&quot;,&quot;~u6129d90a-e64d-4042-a467-de608c53de9e&quot;,536871210]],[&quot;^1A&quot;,[289,&quot;^E&quot;,false,536871210]],[&quot;^1A&quot;,[289,&quot;^19&quot;,&quot;piotr bojanowski&quot;,536871210]],[&quot;^1A&quot;,[289,&quot;^1=&quot;,&quot;Piotr Bojanowski&quot;,536871210]],[&quot;^1A&quot;,[289,&quot;^?&quot;,&quot;~u6129d90a-d274-45a5-a4e5-858a7b62cb88&quot;,536871210]],[&quot;^1A&quot;,[290,&quot;^E&quot;,false,536871210]],[&quot;^1A&quot;,[290,&quot;^19&quot;,&quot;armand joulin&quot;,536871210]],[&quot;^1A&quot;,[290,&quot;^1=&quot;,&quot;Armand Joulin&quot;,536871210]],[&quot;^1A&quot;,[290,&quot;^?&quot;,&quot;~u6129d90a-7c7f-4bb4-820d-8aa2e18eb299&quot;,536871210]],[&quot;^1A&quot;,[291,&quot;^E&quot;,false,536871210]],[&quot;^1A&quot;,[291,&quot;^19&quot;,&quot;nicolas ballas&quot;,536871210]],[&quot;^1A&quot;,[291,&quot;^1=&quot;,&quot;Nicolas Ballas&quot;,536871210]],[&quot;^1A&quot;,[291,&quot;^?&quot;,&quot;~u6129d90a-bd5f-4afe-9b19-f31e5f8615b4&quot;,536871210]],[&quot;^1A&quot;,[292,&quot;^E&quot;,false,536871210]],[&quot;^1A&quot;,[292,&quot;^19&quot;,&quot;michael rabbat&quot;,536871210]],[&quot;^1A&quot;,[292,&quot;^1=&quot;,&quot;Michael Rabbat&quot;,536871210]],[&quot;^1A&quot;,[292,&quot;^?&quot;,&quot;~u6129d90a-c442-4fa3-8cc6-7e5a9fa94a1f&quot;,536871210]],[&quot;^1A&quot;,[293,&quot;^1C&quot;,&quot;&quot;,536871211]],[&quot;^1A&quot;,[293,&quot;^S&quot;,[],536871951]],[&quot;^1A&quot;,[293,&quot;^[&quot;,&quot;[[Abstract]]&quot;,536871211]],[&quot;^1A&quot;,[293,&quot;^W&quot;,&quot;^1F&quot;,536871211]],[&quot;^1A&quot;,[293,&quot;^E&quot;,false,536871211]],[&quot;^1A&quot;,[293,&quot;^K&quot;,324,536871951]],[&quot;^1A&quot;,[293,&quot;^X&quot;,1,536871951]],[&quot;^1A&quot;,[293,&quot;^17&quot;,280,536871211]],[&quot;^1A&quot;,[293,&quot;^13&quot;,280,536871211]],[&quot;^1A&quot;,[293,&quot;^12&quot;,23,536871951]],[&quot;^1A&quot;,[293,&quot;^12&quot;,280,536871951]],[&quot;^1A&quot;,[293,&quot;^D&quot;,[&quot;^ &quot;],536871951]],[&quot;^1A&quot;,[293,&quot;^L&quot;,23,536871951]],[&quot;^1A&quot;,[293,&quot;^Z&quot;,[[&quot;Link&quot;,[&quot;^ &quot;,&quot;^1K&quot;,[&quot;Page_ref&quot;,&quot;Abstract&quot;],&quot;^1N&quot;,[[&quot;Plain&quot;,&quot;&quot;]],&quot;^1O&quot;,&quot;[[Abstract]]&quot;,&quot;^1P&quot;,&quot;&quot;]]],536871951]],[&quot;^1A&quot;,[293,&quot;^1B&quot;,true,536871211]],[&quot;^1A&quot;,[293,&quot;^?&quot;,&quot;~u6129d90a-dead-408c-825d-2ef5af4458e0&quot;,536871211]],[&quot;^1A&quot;,[294,&quot;^1C&quot;,&quot;This_paper_proposes_a_novel_method_of_learning_by_predicting_view_assignments_with_support_samples_(PAWS)-2e-_The_method_trains_a_model_to_minimize_a_consistency_loss-2c-_which_ensures_that_different_views_of_the_same_unlabeled_instance_are_assigned_similar_pseudo_labels-2e-_The_pseudo_labels_are_generated_non_parametrically-2c-_by_comparing_the_representations_of_the_image_views_to_those_of_a_set_of_randomly_sampled_labeled_images-2e-_The_distance_between_the_view_representations_and_labeled_representations_is_used_to_provide_a_weighting_over_class_labels-2c-_which_we_interpret_as_a_soft_pseudo_label-2e-_By_non_parametrically_incorporating_labeled_samples_in_this_way-2c-_PAWS_extends_the_distance_metric_loss_used_in_self_supervised_methods_such_as_BYOL_and_SwAV_to_the_semi_supervised_setting-2e-_Despite_the_simplicity_of_the_approach-2c-_PAWS_outperforms_other_semi_supervised_methods_across_architectures-2c-_setting_a_new_state_of_the_art_for_a_ResNet_50_on_ImageNet_trained_with_either_10-25-_or_1-25-_of_the_labels-2c-_reaching_75-2e-5-25-_and_66-2e-5-25-_top_1_respectively-2e-_PAWS_requires_4x_to_12x_less_training_than_the_previous_best_methods-2e-&quot;,536871212]],[&quot;^1A&quot;,[294,&quot;^S&quot;,[],536871212]],[&quot;^1A&quot;,[294,&quot;^[&quot;,&quot;This paper proposes a novel method of learning by predicting view assignments with support samples (PAWS). The method trains a model to minimize a consistency loss, which ensures that different views of the same unlabeled instance are assigned similar pseudo-labels. The pseudo-labels are generated non-parametrically, by comparing the representations of the image views to those of a set of randomly sampled labeled images. The distance between the view representations and labeled representations is used to provide a weighting over class labels, which we interpret as a soft pseudo-label. By non-parametrically incorporating labeled samples in this way, PAWS extends the distance-metric loss used in self-supervised methods such as BYOL and SwAV to the semi-supervised setting. Despite the simplicity of the approach, PAWS outperforms other semi-supervised methods across architectures, setting a new state-of-the-art for a ResNet-50 on ImageNet trained with either 10% or 1% of the labels, reaching 75.5% and 66.5% top-1 respectively. PAWS requires 4x to 12x less training than the previous best methods.&quot;,536871212]],[&quot;^1A&quot;,[294,&quot;^W&quot;,&quot;^1F&quot;,536871212]],[&quot;^1A&quot;,[294,&quot;^E&quot;,false,536871212]],[&quot;^1A&quot;,[294,&quot;^K&quot;,293,536871212]],[&quot;^1A&quot;,[294,&quot;^X&quot;,1,536871212]],[&quot;^1A&quot;,[294,&quot;^17&quot;,280,536871212]],[&quot;^1A&quot;,[294,&quot;^13&quot;,293,536871212]],[&quot;^1A&quot;,[294,&quot;^D&quot;,[&quot;^ &quot;],536871212]],[&quot;^1A&quot;,[294,&quot;^Z&quot;,[[&quot;Plain&quot;,&quot;This paper proposes a novel method of learning by predicting view assignments with support samples (PAWS). The method trains a model to minimize a consistency loss, which ensures that different views of the same unlabeled instance are assigned similar pseudo-labels. The pseudo-labels are generated non-parametrically, by comparing the representations of the image views to those of a set of randomly sampled labeled images. The distance between the view representations and labeled representations is used to provide a weighting over class labels, which we interpret as a soft pseudo-label. By non-parametrically incorporating labeled samples in this way, PAWS extends the distance-metric loss used in self-supervised methods such as BYOL and SwAV to the semi-supervised setting. Despite the simplicity of the approach, PAWS outperforms other semi-supervised methods across architectures, setting a new state-of-the-art for a ResNet-50 on ImageNet trained with either 10% or 1% of the labels, reaching 75.5% and 66.5% top-1 respectively. PAWS requires 4x to 12x less training than the previous best methods.&quot;]],536871212]],[&quot;^1A&quot;,[294,&quot;^1B&quot;,true,536871212]],[&quot;^1A&quot;,[294,&quot;^?&quot;,&quot;~u6129d90a-1109-457c-b85b-8a4d5cb5d1a2&quot;,536871212]],[&quot;^1A&quot;,[296,&quot;^1C&quot;,&quot;Unsupervised_training_in_Speech_Recognition&quot;,536871220]],[&quot;^1A&quot;,[296,&quot;^S&quot;,[],536871220]],[&quot;^1A&quot;,[296,&quot;^1D&quot;,[&quot;^1E&quot;,[[&quot;^?&quot;,&quot;~u6129d91c-d458-4983-8f0f-0976dd0938ae&quot;],[&quot;^?&quot;,&quot;~u6129d91c-e9c6-4b5f-9c22-99aeb626ac6f&quot;]]],536871220]],[&quot;^1A&quot;,[296,&quot;^[&quot;,&quot;Unsupervised training in Speech Recognition&quot;,536871220]],[&quot;^1A&quot;,[296,&quot;^W&quot;,&quot;^1F&quot;,536871220]],[&quot;^1A&quot;,[296,&quot;^K&quot;,40,536871220]],[&quot;^1A&quot;,[296,&quot;^X&quot;,1,536871220]],[&quot;^1A&quot;,[296,&quot;^U&quot;,[&quot;^ &quot;,&quot;^1G&quot;,[],&quot;^1H&quot;,[],&quot;^1I&quot;,0,&quot;^1J&quot;,46],536871220]],[&quot;^1A&quot;,[296,&quot;^17&quot;,40,536871220]],[&quot;^1A&quot;,[296,&quot;^13&quot;,40,536871220]],[&quot;^1A&quot;,[296,&quot;^12&quot;,40,536871220]],[&quot;^1A&quot;,[296,&quot;^Z&quot;,[[&quot;Plain&quot;,&quot;Unsupervised training in Speech Recognition&quot;]],536871220]],[&quot;^1A&quot;,[296,&quot;^1B&quot;,true,536871220]],[&quot;^1A&quot;,[296,&quot;^?&quot;,&quot;~u6129d91c-0355-497b-bec7-e469a7101bea&quot;,536871220]],[&quot;^1A&quot;,[297,&quot;^1C&quot;,&quot;&quot;,536871220]],[&quot;^1A&quot;,[297,&quot;^S&quot;,[],536871220]],[&quot;^1A&quot;,[297,&quot;^1D&quot;,[&quot;^1E&quot;,[]],536871220]],[&quot;^1A&quot;,[297,&quot;^[&quot;,&quot;[[Training ASR models by Generation of Contextual Information]]&quot;,536871220]],[&quot;^1A&quot;,[297,&quot;^W&quot;,&quot;^1F&quot;,536871220]],[&quot;^1A&quot;,[297,&quot;^K&quot;,296,536871220]],[&quot;^1A&quot;,[297,&quot;^X&quot;,2,536871220]],[&quot;^1A&quot;,[297,&quot;^U&quot;,[&quot;^ &quot;,&quot;^1G&quot;,[],&quot;^1H&quot;,[],&quot;^1I&quot;,46,&quot;^1J&quot;,113],536871220]],[&quot;^1A&quot;,[297,&quot;^17&quot;,40,536871220]],[&quot;^1A&quot;,[297,&quot;^13&quot;,296,536871220]],[&quot;^1A&quot;,[297,&quot;^12&quot;,40,536871220]],[&quot;^1A&quot;,[297,&quot;^12&quot;,209,536871220]],[&quot;^1A&quot;,[297,&quot;^L&quot;,209,536871220]],[&quot;^1A&quot;,[297,&quot;^Z&quot;,[[&quot;Link&quot;,[&quot;^ &quot;,&quot;^1K&quot;,[&quot;Page_ref&quot;,&quot;Training ASR models by Generation of Contextual Information&quot;],&quot;^1N&quot;,[[&quot;Plain&quot;,&quot;&quot;]],&quot;^1O&quot;,&quot;[[Training ASR models by Generation of Contextual Information]]&quot;,&quot;^1P&quot;,&quot;&quot;]]],536871220]],[&quot;^1A&quot;,[297,&quot;^1B&quot;,true,536871220]],[&quot;^1A&quot;,[297,&quot;^?&quot;,&quot;~u6129d91c-e9c6-4b5f-9c22-99aeb626ac6f&quot;,536871220]],[&quot;^1A&quot;,[298,&quot;^1C&quot;,&quot;_&quot;,536871220]],[&quot;^1A&quot;,[298,&quot;^S&quot;,[],536871220]],[&quot;^1A&quot;,[298,&quot;^1D&quot;,[&quot;^1E&quot;,[]],536871220]],[&quot;^1A&quot;,[298,&quot;^[&quot;,&quot;[[Feature Replacement and Combination for Hybrid ASR Systems]] - #todo&quot;,536871220]],[&quot;^1A&quot;,[298,&quot;^W&quot;,&quot;^1F&quot;,536871220]],[&quot;^1A&quot;,[298,&quot;^K&quot;,297,536871220]],[&quot;^1A&quot;,[298,&quot;^X&quot;,2,536871220]],[&quot;^1A&quot;,[298,&quot;^U&quot;,[&quot;^ &quot;,&quot;^1G&quot;,[],&quot;^1H&quot;,[],&quot;^1I&quot;,113,&quot;^1J&quot;,187],536871220]],[&quot;^1A&quot;,[298,&quot;^17&quot;,40,536871220]],[&quot;^1A&quot;,[298,&quot;^13&quot;,296,536871220]],[&quot;^1A&quot;,[298,&quot;^12&quot;,3,536871220]],[&quot;^1A&quot;,[298,&quot;^12&quot;,40,536871220]],[&quot;^1A&quot;,[298,&quot;^12&quot;,115,536871220]],[&quot;^1A&quot;,[298,&quot;^L&quot;,3,536871220]],[&quot;^1A&quot;,[298,&quot;^L&quot;,115,536871220]],[&quot;^1A&quot;,[298,&quot;^Z&quot;,[[&quot;Link&quot;,[&quot;^ &quot;,&quot;^1K&quot;,[&quot;Page_ref&quot;,&quot;Feature Replacement and Combination for Hybrid ASR Systems&quot;],&quot;^1N&quot;,[[&quot;Plain&quot;,&quot;&quot;]],&quot;^1O&quot;,&quot;[[Feature Replacement and Combination for Hybrid ASR Systems]]&quot;,&quot;^1P&quot;,&quot;&quot;]],[&quot;Plain&quot;,&quot; - &quot;],[&quot;Tag&quot;,[[&quot;Plain&quot;,&quot;todo&quot;]]]],536871220]],[&quot;^1A&quot;,[298,&quot;^1B&quot;,true,536871220]],[&quot;^1A&quot;,[298,&quot;^?&quot;,&quot;~u6129d91c-d458-4983-8f0f-0976dd0938ae&quot;,536871220]],[&quot;^1A&quot;,[299,&quot;^1C&quot;,&quot;Semi_Supervised_Learning&quot;,536871220]],[&quot;^1A&quot;,[299,&quot;^S&quot;,[],536871220]],[&quot;^1A&quot;,[299,&quot;^1D&quot;,[&quot;^1E&quot;,[[&quot;^?&quot;,&quot;~u6129d91c-d2dd-4bb5-a8ce-3f10e57b5eb6&quot;]]],536871220]],[&quot;^1A&quot;,[299,&quot;^[&quot;,&quot;Semi-Supervised Learning&quot;,536871220]],[&quot;^1A&quot;,[299,&quot;^W&quot;,&quot;^1F&quot;,536871220]],[&quot;^1A&quot;,[299,&quot;^K&quot;,296,536871220]],[&quot;^1A&quot;,[299,&quot;^X&quot;,1,536871220]],[&quot;^1A&quot;,[299,&quot;^U&quot;,[&quot;^ &quot;,&quot;^1G&quot;,[],&quot;^1H&quot;,[],&quot;^1I&quot;,187,&quot;^1J&quot;,214],536871220]],[&quot;^1A&quot;,[299,&quot;^17&quot;,40,536871220]],[&quot;^1A&quot;,[299,&quot;^13&quot;,40,536871220]],[&quot;^1A&quot;,[299,&quot;^12&quot;,40,536871220]],[&quot;^1A&quot;,[299,&quot;^Z&quot;,[[&quot;Plain&quot;,&quot;Semi-Supervised Learning&quot;]],536871220]],[&quot;^1A&quot;,[299,&quot;^1B&quot;,true,536871220]],[&quot;^1A&quot;,[299,&quot;^?&quot;,&quot;~u6129d91c-ed2e-4e2f-be43-d32c5161cea3&quot;,536871220]],[&quot;^1A&quot;,[300,&quot;^1C&quot;,&quot;&quot;,536873562]],[&quot;^1A&quot;,[300,&quot;^S&quot;,[],536873562]],[&quot;^1A&quot;,[300,&quot;^1D&quot;,[&quot;^1E&quot;,[]],536871220]],[&quot;^1A&quot;,[300,&quot;^[&quot;,&quot;[[Semi-Supervised Learning of Visual Features by Non-Parametrically Predicting View Assignments with Support Samples]]&quot;,536873562]],[&quot;^1A&quot;,[300,&quot;^W&quot;,&quot;^1F&quot;,536871220]],[&quot;^1A&quot;,[300,&quot;^K&quot;,299,536871220]],[&quot;^1A&quot;,[300,&quot;^X&quot;,1,536873562]],[&quot;^1A&quot;,[300,&quot;^U&quot;,[&quot;^ &quot;,&quot;^1G&quot;,[],&quot;^1H&quot;,[],&quot;^1I&quot;,214,&quot;^1J&quot;,216],536871220]],[&quot;^1A&quot;,[300,&quot;^17&quot;,40,536871220]],[&quot;^1A&quot;,[300,&quot;^13&quot;,299,536871220]],[&quot;^1A&quot;,[300,&quot;^12&quot;,40,536873562]],[&quot;^1A&quot;,[300,&quot;^12&quot;,280,536873562]],[&quot;^1A&quot;,[300,&quot;^D&quot;,[&quot;^ &quot;],536873562]],[&quot;^1A&quot;,[300,&quot;^L&quot;,280,536873562]],[&quot;^1A&quot;,[300,&quot;^Z&quot;,[[&quot;Link&quot;,[&quot;^ &quot;,&quot;^1K&quot;,[&quot;Page_ref&quot;,&quot;Semi-Supervised Learning of Visual Features by Non-Parametrically Predicting View Assignments with Support Samples&quot;],&quot;^1N&quot;,[[&quot;Plain&quot;,&quot;&quot;]],&quot;^1O&quot;,&quot;[[Semi-Supervised Learning of Visual Features by Non-Parametrically Predicting View Assignments with Support Samples]]&quot;,&quot;^1P&quot;,&quot;&quot;]]],536873562]],[&quot;^1A&quot;,[300,&quot;^1B&quot;,true,536871220]],[&quot;^1A&quot;,[300,&quot;^?&quot;,&quot;~u6129d91c-d2dd-4bb5-a8ce-3f10e57b5eb6&quot;,536871220]],[&quot;^1A&quot;,[304,&quot;^1C&quot;,&quot;TLDR&quot;,536871257]],[&quot;^1A&quot;,[304,&quot;^S&quot;,[],536871663]],[&quot;^1A&quot;,[304,&quot;^[&quot;,&quot;TLDR\\nheading:: true&quot;,536871265]],[&quot;^1A&quot;,[304,&quot;^W&quot;,&quot;^1F&quot;,536871251]],[&quot;^1A&quot;,[304,&quot;^E&quot;,false,536871251]],[&quot;^1A&quot;,[304,&quot;^K&quot;,281,536871663]],[&quot;^1A&quot;,[304,&quot;^X&quot;,1,536871663]],[&quot;^1A&quot;,[304,&quot;^17&quot;,280,536871251]],[&quot;^1A&quot;,[304,&quot;^13&quot;,280,536871251]],[&quot;^1A&quot;,[304,&quot;^12&quot;,280,536871663]],[&quot;^1A&quot;,[304,&quot;^D&quot;,[&quot;^ &quot;,&quot;^21&quot;,true],536871663]],[&quot;^1A&quot;,[304,&quot;^Z&quot;,[[&quot;Plain&quot;,&quot;TLDR&quot;]],536871663]],[&quot;^1A&quot;,[304,&quot;^1B&quot;,true,536871251]],[&quot;^1A&quot;,[304,&quot;^?&quot;,&quot;~u6129d96f-22dd-4c79-bbdf-187f306d23e2&quot;,536871251]],[&quot;^1A&quot;,[305,&quot;^1C&quot;,&quot;During_training___labelled_data_is_only_used_to_generate_pseudo_labels_for_unlabelled_data-2e-_It_is_not_used_for_computing_a_supervised_loss-2e-&quot;,536871374]],[&quot;^1A&quot;,[305,&quot;^S&quot;,[],536872412]],[&quot;^1A&quot;,[305,&quot;^[&quot;,&quot;During training - labelled data is **only** used to generate pseudo labels for unlabelled data. It is not used for computing a supervised loss.&quot;,536871378]],[&quot;^1A&quot;,[305,&quot;^W&quot;,&quot;^1F&quot;,536871260]],[&quot;^1A&quot;,[305,&quot;^E&quot;,false,536871260]],[&quot;^1A&quot;,[305,&quot;^K&quot;,316,536871615]],[&quot;^1A&quot;,[305,&quot;^X&quot;,1,536872412]],[&quot;^1A&quot;,[305,&quot;^17&quot;,280,536871260]],[&quot;^1A&quot;,[305,&quot;^13&quot;,280,536871260]],[&quot;^1A&quot;,[305,&quot;^12&quot;,280,536872412]],[&quot;^1A&quot;,[305,&quot;^D&quot;,[&quot;^ &quot;],536872412]],[&quot;^1A&quot;,[305,&quot;^Z&quot;,[[&quot;Plain&quot;,&quot;During training - labelled data is &quot;],[&quot;Emphasis&quot;,[[&quot;Bold&quot;],[[&quot;Plain&quot;,&quot;only&quot;]]]],[&quot;Plain&quot;,&quot; used to generate pseudo labels for unlabelled data. It is not used for computing a supervised loss.&quot;]],536872412]],[&quot;^1A&quot;,[305,&quot;^1B&quot;,true,536871260]],[&quot;^1A&quot;,[305,&quot;^?&quot;,&quot;~u6129d9b7-ae2f-4fbb-acca-61530ba9f5f4&quot;,536871260]],[&quot;^1A&quot;,[306,&quot;^1C&quot;,&quot;Training&quot;,536871279]],[&quot;^1A&quot;,[306,&quot;^S&quot;,[],536872351]],[&quot;^1A&quot;,[306,&quot;^[&quot;,&quot;Training\\nheading:: true&quot;,536871288]],[&quot;^1A&quot;,[306,&quot;^W&quot;,&quot;^1F&quot;,536871270]],[&quot;^1A&quot;,[306,&quot;^E&quot;,false,536871270]],[&quot;^1A&quot;,[306,&quot;^K&quot;,334,536872351]],[&quot;^1A&quot;,[306,&quot;^X&quot;,1,536872351]],[&quot;^1A&quot;,[306,&quot;^17&quot;,280,536871270]],[&quot;^1A&quot;,[306,&quot;^13&quot;,280,536871270]],[&quot;^1A&quot;,[306,&quot;^12&quot;,280,536872351]],[&quot;^1A&quot;,[306,&quot;^D&quot;,[&quot;^ &quot;,&quot;^21&quot;,true],536872351]],[&quot;^1A&quot;,[306,&quot;^P&quot;,[&quot;^1@&quot;,[&quot;^21&quot;]],536871960]],[&quot;^1A&quot;,[306,&quot;^Z&quot;,[[&quot;Plain&quot;,&quot;Training&quot;]],536872351]],[&quot;^1A&quot;,[306,&quot;^1B&quot;,true,536871270]],[&quot;^1A&quot;,[306,&quot;^?&quot;,&quot;~u6129dbb0-5259-4f87-81e0-48cca77666e2&quot;,536871270]],[&quot;^1A&quot;,[308,&quot;^1C&quot;,&quot;Use__with_momentum_-3d-_0-2e-9-2c-_weight_decay_10e_6-2c-_cosine_similarity_temperature_-3d-_0-2e-1-2c-_batch_size_-3d-_4096-2e-_Linearly_warm_up_LR_from_0-2e-3_to_6-2e-4_during_initial_10_epochs_in_pre_training-2c-_then_decay_using_a_cosine_schedule-2e-_Use__during_pre_training-2c-_and_exclude_the_bias_and_batch_norm_parameters_from_weight_decay_and_LARS_adaptation-2e-&quot;,536871708]],[&quot;^1A&quot;,[308,&quot;^S&quot;,[],536873147]],[&quot;^1A&quot;,[308,&quot;^[&quot;,&quot;Use [[LARS optimizer]] with momentum = 0.9, weight decay 10e-6, cosine-similarity temperature = 0.1, batch size = 4096. Linearly warm-up LR from 0.3 to 6.4 during initial 10 epochs in pre-training, then decay using a cosine schedule. Use [[batch normalization]] during pre-training, and exclude the bias and batch-norm parameters from weight decay and LARS adaptation.&quot;,536871708]],[&quot;^1A&quot;,[308,&quot;^W&quot;,&quot;^1F&quot;,536871384]],[&quot;^1A&quot;,[308,&quot;^E&quot;,false,536871384]],[&quot;^1A&quot;,[308,&quot;^K&quot;,348,536873147]],[&quot;^1A&quot;,[308,&quot;^X&quot;,1,536873147]],[&quot;^1A&quot;,[308,&quot;^17&quot;,280,536871384]],[&quot;^1A&quot;,[308,&quot;^13&quot;,280,536871384]],[&quot;^1A&quot;,[308,&quot;^12&quot;,280,536873147]],[&quot;^1A&quot;,[308,&quot;^12&quot;,312,536873147]],[&quot;^1A&quot;,[308,&quot;^12&quot;,313,536873147]],[&quot;^1A&quot;,[308,&quot;^D&quot;,[&quot;^ &quot;],536873147]],[&quot;^1A&quot;,[308,&quot;^L&quot;,312,536873147]],[&quot;^1A&quot;,[308,&quot;^L&quot;,313,536873147]],[&quot;^1A&quot;,[308,&quot;^Z&quot;,[[&quot;Plain&quot;,&quot;Use &quot;],[&quot;Link&quot;,[&quot;^ &quot;,&quot;^1K&quot;,[&quot;Page_ref&quot;,&quot;LARS optimizer&quot;],&quot;^1N&quot;,[[&quot;Plain&quot;,&quot;&quot;]],&quot;^1O&quot;,&quot;[[LARS optimizer]]&quot;,&quot;^1P&quot;,&quot;&quot;]],[&quot;Plain&quot;,&quot; with momentum = 0.9, weight decay 10e-6, cosine-similarity temperature = 0.1, batch size = 4096. Linearly warm-up LR from 0.3 to 6.4 during initial 10 epochs in pre-training, then decay using a cosine schedule. Use &quot;],[&quot;Link&quot;,[&quot;^ &quot;,&quot;^1K&quot;,[&quot;Page_ref&quot;,&quot;batch normalization&quot;],&quot;^1N&quot;,[[&quot;Plain&quot;,&quot;&quot;]],&quot;^1O&quot;,&quot;[[batch normalization]]&quot;,&quot;^1P&quot;,&quot;&quot;]],[&quot;Plain&quot;,&quot; during pre-training, and exclude the bias and batch-norm parameters from weight decay and LARS adaptation.&quot;]],536873147]],[&quot;^1A&quot;,[308,&quot;^1B&quot;,true,536871384]],[&quot;^1A&quot;,[308,&quot;^?&quot;,&quot;~u6129ddf8-2fa7-488b-9f2c-63a2f95a32ef&quot;,536871384]],[&quot;^1A&quot;,[309,&quot;^E&quot;,false,536871395]],[&quot;^1A&quot;,[309,&quot;^19&quot;,&quot;lars optimiser&quot;,536871395]],[&quot;^1A&quot;,[309,&quot;^1=&quot;,&quot;LARS optimiser&quot;,536871395]],[&quot;^1A&quot;,[309,&quot;^?&quot;,&quot;~u6129de2c-d225-442c-b5dd-17ddbd1b1125&quot;,536871395]],[&quot;^1A&quot;,[310,&quot;^1C&quot;,&quot;The_images_from_unlabelled_and_labelled_set_may_overlap-2e-&quot;,536872811]],[&quot;^1A&quot;,[310,&quot;^S&quot;,[],536872811]],[&quot;^1A&quot;,[310,&quot;^[&quot;,&quot;The images from unlabelled and labelled set may overlap.&quot;,536872811]],[&quot;^1A&quot;,[310,&quot;^W&quot;,&quot;^1F&quot;,536871534]],[&quot;^1A&quot;,[310,&quot;^E&quot;,false,536871534]],[&quot;^1A&quot;,[310,&quot;^K&quot;,321,536871715]],[&quot;^1A&quot;,[310,&quot;^X&quot;,1,536872811]],[&quot;^1A&quot;,[310,&quot;^17&quot;,280,536871534]],[&quot;^1A&quot;,[310,&quot;^13&quot;,280,536871534]],[&quot;^1A&quot;,[310,&quot;^12&quot;,280,536872811]],[&quot;^1A&quot;,[310,&quot;^D&quot;,[&quot;^ &quot;],536872811]],[&quot;^1A&quot;,[310,&quot;^Z&quot;,[[&quot;Plain&quot;,&quot;The images from unlabelled and labelled set may overlap.&quot;]],536872811]],[&quot;^1A&quot;,[310,&quot;^1B&quot;,true,536871534]],[&quot;^1A&quot;,[310,&quot;^?&quot;,&quot;~u6129de91-2dcc-4dcd-b3d8-c1d9b89d0262&quot;,536871534]],[&quot;^1A&quot;,[311,&quot;^E&quot;,false,536871543]],[&quot;^1A&quot;,[311,&quot;^19&quot;,&quot;batch normalisation&quot;,536871543]],[&quot;^1A&quot;,[311,&quot;^1=&quot;,&quot;batch normalisation&quot;,536871543]],[&quot;^1A&quot;,[311,&quot;^?&quot;,&quot;~u6129deba-d94a-4ea0-b2bf-b7f220e3e3b7&quot;,536871543]],[&quot;^1A&quot;,[312,&quot;^E&quot;,false,536871555]],[&quot;^1A&quot;,[312,&quot;^19&quot;,&quot;lars optimizer&quot;,536871555]],[&quot;^1A&quot;,[312,&quot;^1=&quot;,&quot;LARS optimizer&quot;,536871555]],[&quot;^1A&quot;,[312,&quot;^?&quot;,&quot;~u6129dec3-ee0f-49e6-a8ab-fbc66d5552f8&quot;,536871555]],[&quot;^1A&quot;,[313,&quot;^E&quot;,false,536871559]],[&quot;^1A&quot;,[313,&quot;^19&quot;,&quot;batch normalization&quot;,536871559]],[&quot;^1A&quot;,[313,&quot;^1=&quot;,&quot;batch normalization&quot;,536871559]],[&quot;^1A&quot;,[313,&quot;^?&quot;,&quot;~u6129deca-e8cb-4d0a-8f66-b71e66976a9c&quot;,536871559]],[&quot;^1A&quot;,[314,&quot;^1C&quot;,&quot;&quot;,536871595]],[&quot;^1A&quot;,[314,&quot;^S&quot;,[],536871595]],[&quot;^1A&quot;,[314,&quot;^[&quot;,&quot;&quot;,536871595]],[&quot;^1A&quot;,[314,&quot;^W&quot;,&quot;^1F&quot;,536871595]],[&quot;^1A&quot;,[314,&quot;^E&quot;,false,536871595]],[&quot;^1A&quot;,[314,&quot;^K&quot;,313,536871595]],[&quot;^1A&quot;,[314,&quot;^X&quot;,1,536871595]],[&quot;^1A&quot;,[314,&quot;^17&quot;,313,536871595]],[&quot;^1A&quot;,[314,&quot;^13&quot;,313,536871595]],[&quot;^1A&quot;,[314,&quot;^D&quot;,[&quot;^ &quot;],536871595]],[&quot;^1A&quot;,[314,&quot;^Z&quot;,[],536871595]],[&quot;^1A&quot;,[314,&quot;^1B&quot;,true,536871595]],[&quot;^1A&quot;,[314,&quot;^?&quot;,&quot;~u6129def3-21c8-48b1-9c66-dd2492cd09bc&quot;,536871595]],[&quot;^1A&quot;,[315,&quot;^1C&quot;,&quot;&quot;,536871598]],[&quot;^1A&quot;,[315,&quot;^S&quot;,[],536871598]],[&quot;^1A&quot;,[315,&quot;^[&quot;,&quot;&quot;,536871598]],[&quot;^1A&quot;,[315,&quot;^W&quot;,&quot;^1F&quot;,536871598]],[&quot;^1A&quot;,[315,&quot;^E&quot;,false,536871598]],[&quot;^1A&quot;,[315,&quot;^K&quot;,312,536871598]],[&quot;^1A&quot;,[315,&quot;^X&quot;,1,536871598]],[&quot;^1A&quot;,[315,&quot;^17&quot;,312,536871598]],[&quot;^1A&quot;,[315,&quot;^13&quot;,312,536871598]],[&quot;^1A&quot;,[315,&quot;^D&quot;,[&quot;^ &quot;],536871598]],[&quot;^1A&quot;,[315,&quot;^Z&quot;,[],536871598]],[&quot;^1A&quot;,[315,&quot;^1B&quot;,true,536871598]],[&quot;^1A&quot;,[315,&quot;^?&quot;,&quot;~u6129def8-522d-4fa5-824d-63a8e234fa18&quot;,536871598]],[&quot;^1A&quot;,[316,&quot;^1C&quot;,&quot;Computationally_cheap_and_faster_semi_supervised_learning_for_image_classification-2e-_Faster_training_(2x_to_12x_reduction_in_training_time_compared_with_similar_work)_is_reported_and_attributed_to_the_unique_way_of_generating_pseudo_labels_non_parametrically_from_labelled_images-2e-&quot;,536871928]],[&quot;^1A&quot;,[316,&quot;^S&quot;,[],536871928]],[&quot;^1A&quot;,[316,&quot;^[&quot;,&quot;Computationally cheap and faster semi-supervised learning for image classification. Faster training (2x to 12x reduction in training time compared with similar work) is reported and attributed to the unique way of generating pseudo labels non-parametrically from labelled images.&quot;,536871928]],[&quot;^1A&quot;,[316,&quot;^W&quot;,&quot;^1F&quot;,536871615]],[&quot;^1A&quot;,[316,&quot;^E&quot;,false,536871615]],[&quot;^1A&quot;,[316,&quot;^K&quot;,304,536871615]],[&quot;^1A&quot;,[316,&quot;^X&quot;,1,536871928]],[&quot;^1A&quot;,[316,&quot;^17&quot;,280,536871615]],[&quot;^1A&quot;,[316,&quot;^13&quot;,280,536871615]],[&quot;^1A&quot;,[316,&quot;^12&quot;,280,536871928]],[&quot;^1A&quot;,[316,&quot;^D&quot;,[&quot;^ &quot;],536871928]],[&quot;^1A&quot;,[316,&quot;^Z&quot;,[[&quot;Plain&quot;,&quot;Computationally cheap and faster semi-supervised learning for image classification. Faster training (2x to 12x reduction in training time compared with similar work) is reported and attributed to the unique way of generating pseudo labels non-parametrically from labelled images.&quot;]],536871928]],[&quot;^1A&quot;,[316,&quot;^1B&quot;,true,536871615]],[&quot;^1A&quot;,[316,&quot;^?&quot;,&quot;~u6129e111-9398-481a-8814-1060333acf69&quot;,536871615]],[&quot;^1A&quot;,[317,&quot;^E&quot;,false,536871657]],[&quot;^1A&quot;,[317,&quot;^19&quot;,&quot;arxiv:2104.13963 [cs&quot;,536871657]],[&quot;^1A&quot;,[317,&quot;^1=&quot;,&quot;arXiv:2104.13963 [cs&quot;,536871657]],[&quot;^1A&quot;,[317,&quot;^?&quot;,&quot;~u6129e15f-da7c-4a81-9ca8-fe4cbccb1c50&quot;,536871657]],[&quot;^1A&quot;,[319,&quot;^E&quot;,false,536871675]],[&quot;^1A&quot;,[319,&quot;^19&quot;,&quot;paws&quot;,536871675]],[&quot;^1A&quot;,[319,&quot;^1=&quot;,&quot;PAWS&quot;,536871675]],[&quot;^1A&quot;,[319,&quot;^?&quot;,&quot;~u6129e174-59d5-4018-aed5-b1780f63fec9&quot;,536871675]],[&quot;^1A&quot;,[320,&quot;^1C&quot;,&quot;Default_training_is_done_on_64_GPUs-2e-&quot;,536871709]],[&quot;^1A&quot;,[320,&quot;^S&quot;,[],536871714]],[&quot;^1A&quot;,[320,&quot;^[&quot;,&quot;Default training is done on 64 GPUs.&quot;,536871709]],[&quot;^1A&quot;,[320,&quot;^W&quot;,&quot;^1F&quot;,536871709]],[&quot;^1A&quot;,[320,&quot;^E&quot;,false,536871709]],[&quot;^1A&quot;,[320,&quot;^K&quot;,308,536871709]],[&quot;^1A&quot;,[320,&quot;^X&quot;,1,536871714]],[&quot;^1A&quot;,[320,&quot;^17&quot;,280,536871709]],[&quot;^1A&quot;,[320,&quot;^13&quot;,280,536871709]],[&quot;^1A&quot;,[320,&quot;^12&quot;,280,536871714]],[&quot;^1A&quot;,[320,&quot;^D&quot;,[&quot;^ &quot;],536871714]],[&quot;^1A&quot;,[320,&quot;^Z&quot;,[[&quot;Plain&quot;,&quot;Default training is done on 64 GPUs.&quot;]],536871714]],[&quot;^1A&quot;,[320,&quot;^1B&quot;,true,536871709]],[&quot;^1A&quot;,[320,&quot;^?&quot;,&quot;~u6129e621-0474-4898-ae0e-d76d7094cefb&quot;,536871709]],[&quot;^1A&quot;,[321,&quot;^1C&quot;,&quot;A_support_set_is_constructed_from_labelled_images-2e-_Consists_of_6720_images___960_classes_(out_of_1000_ImageNet_classes-2c-_sampled_randomly)_and_7_images_per_class-2e-_Under_Ablation_Study-2c-_authors_mention_that_increasing_the_size_of_support_set_improves_performance___sampling_more_classes_and_fewer_samples_per_class_better_than_contrary_-e2--86--92-_diversity_of_image_samples_more_important_that_quantity_of_samples-2e-&quot;,536871866]],[&quot;^1A&quot;,[321,&quot;^S&quot;,[],536871866]],[&quot;^1A&quot;,[321,&quot;^[&quot;,&quot;A support set is constructed from labelled images. Consists of 6720 images - 960 classes (out of 1000 ImageNet classes, sampled randomly) and 7 images per class. Under Ablation Study, authors mention that increasing the size of support set improves performance - sampling more classes and fewer samples per class better than contrary → _diversity of image samples more important that quantity of samples_.&quot;,536871866]],[&quot;^1A&quot;,[321,&quot;^W&quot;,&quot;^1F&quot;,536871715]],[&quot;^1A&quot;,[321,&quot;^E&quot;,false,536871715]],[&quot;^1A&quot;,[321,&quot;^K&quot;,320,536871715]],[&quot;^1A&quot;,[321,&quot;^X&quot;,1,536871866]],[&quot;^1A&quot;,[321,&quot;^17&quot;,280,536871715]],[&quot;^1A&quot;,[321,&quot;^13&quot;,280,536871715]],[&quot;^1A&quot;,[321,&quot;^12&quot;,280,536871866]],[&quot;^1A&quot;,[321,&quot;^D&quot;,[&quot;^ &quot;],536871866]],[&quot;^1A&quot;,[321,&quot;^Z&quot;,[[&quot;Plain&quot;,&quot;A support set is constructed from labelled images. Consists of 6720 images - 960 classes (out of 1000 ImageNet classes, sampled randomly) and 7 images per class. Under Ablation Study, authors mention that increasing the size of support set improves performance - sampling more classes and fewer samples per class better than contrary → &quot;],[&quot;Emphasis&quot;,[[&quot;Italic&quot;],[[&quot;Plain&quot;,&quot;diversity of image samples more important that quantity of samples&quot;]]]],[&quot;Plain&quot;,&quot;.&quot;]],536871866]],[&quot;^1A&quot;,[321,&quot;^1B&quot;,true,536871715]],[&quot;^1A&quot;,[321,&quot;^?&quot;,&quot;~u6129e625-729c-4833-9fb4-2cb9b9eda22f&quot;,536871715]],[&quot;^1A&quot;,[322,&quot;^1C&quot;,&quot;Results&quot;,536871938]],[&quot;^1A&quot;,[322,&quot;^S&quot;,[],536871940]],[&quot;^1A&quot;,[322,&quot;^[&quot;,&quot;Results\\nheading:: true&quot;,536871956]],[&quot;^1A&quot;,[322,&quot;^W&quot;,&quot;^1F&quot;,536871933]],[&quot;^1A&quot;,[322,&quot;^E&quot;,false,536871933]],[&quot;^1A&quot;,[322,&quot;^K&quot;,310,536871933]],[&quot;^1A&quot;,[322,&quot;^X&quot;,1,536871940]],[&quot;^1A&quot;,[322,&quot;^17&quot;,280,536871933]],[&quot;^1A&quot;,[322,&quot;^13&quot;,280,536871933]],[&quot;^1A&quot;,[322,&quot;^12&quot;,280,536871940]],[&quot;^1A&quot;,[322,&quot;^D&quot;,[&quot;^ &quot;,&quot;^21&quot;,true],536871956]],[&quot;^1A&quot;,[322,&quot;^Z&quot;,[[&quot;Plain&quot;,&quot;Results&quot;]],536871940]],[&quot;^1A&quot;,[322,&quot;^1B&quot;,true,536871933]],[&quot;^1A&quot;,[322,&quot;^?&quot;,&quot;~u6129e7ea-4189-49c0-a969-993164128171&quot;,536871933]],[&quot;^1A&quot;,[323,&quot;^1C&quot;,&quot;image-2e-png&quot;,536871946]],[&quot;^1A&quot;,[323,&quot;^S&quot;,[],536871950]],[&quot;^1A&quot;,[323,&quot;^[&quot;,&quot;![image.png](../assets/image_1630136305243_0.png) &quot;,536871950]],[&quot;^1A&quot;,[323,&quot;^W&quot;,&quot;^1F&quot;,536871941]],[&quot;^1A&quot;,[323,&quot;^E&quot;,false,536871941]],[&quot;^1A&quot;,[323,&quot;^K&quot;,322,536871941]],[&quot;^1A&quot;,[323,&quot;^X&quot;,1,536871950]],[&quot;^1A&quot;,[323,&quot;^17&quot;,280,536871941]],[&quot;^1A&quot;,[323,&quot;^13&quot;,280,536871941]],[&quot;^1A&quot;,[323,&quot;^12&quot;,280,536871950]],[&quot;^1A&quot;,[323,&quot;^D&quot;,[&quot;^ &quot;],536871950]],[&quot;^1A&quot;,[323,&quot;^Z&quot;,[[&quot;Link&quot;,[&quot;^ &quot;,&quot;^1K&quot;,[&quot;Search&quot;,&quot;../assets/image_1630136305243_0.png&quot;],&quot;^1N&quot;,[[&quot;Plain&quot;,&quot;image.png&quot;]],&quot;^1O&quot;,&quot;![image.png](../assets/image_1630136305243_0.png)&quot;,&quot;^1P&quot;,&quot;&quot;]],[&quot;Plain&quot;,&quot; &quot;]],536871950]],[&quot;^1A&quot;,[323,&quot;^1B&quot;,true,536871941]],[&quot;^1A&quot;,[323,&quot;^?&quot;,&quot;~u6129e7ee-0887-453b-af74-227b9a95c939&quot;,536871941]],[&quot;^1A&quot;,[324,&quot;^1C&quot;,&quot;&quot;,536871951]],[&quot;^1A&quot;,[324,&quot;^S&quot;,[],536871951]],[&quot;^1A&quot;,[324,&quot;^[&quot;,&quot;&quot;,536871951]],[&quot;^1A&quot;,[324,&quot;^W&quot;,&quot;^1F&quot;,536871951]],[&quot;^1A&quot;,[324,&quot;^E&quot;,false,536871951]],[&quot;^1A&quot;,[324,&quot;^K&quot;,323,536871951]],[&quot;^1A&quot;,[324,&quot;^X&quot;,1,536871951]],[&quot;^1A&quot;,[324,&quot;^17&quot;,280,536871951]],[&quot;^1A&quot;,[324,&quot;^13&quot;,280,536871951]],[&quot;^1A&quot;,[324,&quot;^12&quot;,280,536871951]],[&quot;^1A&quot;,[324,&quot;^D&quot;,[&quot;^ &quot;],536871951]],[&quot;^1A&quot;,[324,&quot;^Z&quot;,[],536871951]],[&quot;^1A&quot;,[324,&quot;^1B&quot;,true,536871951]],[&quot;^1A&quot;,[324,&quot;^?&quot;,&quot;~u6129e7f4-3da3-43a0-aaf9-1ec17ff9f139&quot;,536871951]],[&quot;^1A&quot;,[325,&quot;^1C&quot;,&quot;Unique&quot;,536871974]],[&quot;^1A&quot;,[325,&quot;^S&quot;,[],536872431]],[&quot;^1A&quot;,[325,&quot;^[&quot;,&quot;Unique\\nheading:: true&quot;,536872012]],[&quot;^1A&quot;,[325,&quot;^W&quot;,&quot;^1F&quot;,536871962]],[&quot;^1A&quot;,[325,&quot;^E&quot;,false,536871962]],[&quot;^1A&quot;,[325,&quot;^K&quot;,339,536872431]],[&quot;^1A&quot;,[325,&quot;^X&quot;,1,536872431]],[&quot;^1A&quot;,[325,&quot;^17&quot;,280,536871962]],[&quot;^1A&quot;,[325,&quot;^13&quot;,280,536871962]],[&quot;^1A&quot;,[325,&quot;^12&quot;,280,536872431]],[&quot;^1A&quot;,[325,&quot;^D&quot;,[&quot;^ &quot;,&quot;^21&quot;,true],536872431]],[&quot;^1A&quot;,[325,&quot;^Z&quot;,[[&quot;Plain&quot;,&quot;Unique&quot;]],536872431]],[&quot;^1A&quot;,[325,&quot;^1B&quot;,true,536871962]],[&quot;^1A&quot;,[325,&quot;^?&quot;,&quot;~u6129e943-8aad-43d6-b263-0168cc1dfaae&quot;,536871962]],[&quot;^1A&quot;,[327,&quot;^1C&quot;,&quot;Approach_is_compared_with_Assimilation_and_Accommodation_learning-2e-&quot;,536872008]],[&quot;^1A&quot;,[327,&quot;^S&quot;,[],536872016]],[&quot;^1A&quot;,[327,&quot;^[&quot;,&quot;Approach is compared with Assimilation and Accommodation learning.&quot;,536872008]],[&quot;^1A&quot;,[327,&quot;^W&quot;,&quot;^1F&quot;,536871975]],[&quot;^1A&quot;,[327,&quot;^E&quot;,false,536871975]],[&quot;^1A&quot;,[327,&quot;^K&quot;,325,536871975]],[&quot;^1A&quot;,[327,&quot;^X&quot;,1,536872016]],[&quot;^1A&quot;,[327,&quot;^17&quot;,280,536871975]],[&quot;^1A&quot;,[327,&quot;^13&quot;,280,536871975]],[&quot;^1A&quot;,[327,&quot;^12&quot;,280,536872016]],[&quot;^1A&quot;,[327,&quot;^D&quot;,[&quot;^ &quot;],536872016]],[&quot;^1A&quot;,[327,&quot;^Z&quot;,[[&quot;Plain&quot;,&quot;Approach is compared with Assimilation and Accommodation learning.&quot;]],536872016]],[&quot;^1A&quot;,[327,&quot;^1B&quot;,true,536871975]],[&quot;^1A&quot;,[327,&quot;^?&quot;,&quot;~u6129e948-0c92-4ca1-ae3b-65e661dd04c6&quot;,536871975]],[&quot;^1A&quot;,[328,&quot;^1C&quot;,&quot;Backpropagation_wrt_images_views_of_an_unlabelled_image___assimilation-2e-_It_ensures_that_new_observations_are_consistent_with_current_schemata_(the_support_representations)-2e-&quot;,536872096]],[&quot;^1A&quot;,[328,&quot;^S&quot;,[],536872284]],[&quot;^1A&quot;,[328,&quot;^[&quot;,&quot;Backpropagation wrt images views of an unlabelled image - assimilation. It ensures that new observations are consistent with current schemata (the support representations).&quot;,536872096]],[&quot;^1A&quot;,[328,&quot;^W&quot;,&quot;^1F&quot;,536872017]],[&quot;^1A&quot;,[328,&quot;^E&quot;,false,536872017]],[&quot;^1A&quot;,[328,&quot;^K&quot;,327,536872017]],[&quot;^1A&quot;,[328,&quot;^X&quot;,1,536872284]],[&quot;^1A&quot;,[328,&quot;^17&quot;,280,536872017]],[&quot;^1A&quot;,[328,&quot;^13&quot;,327,536872284]],[&quot;^1A&quot;,[328,&quot;^12&quot;,280,536872284]],[&quot;^1A&quot;,[328,&quot;^D&quot;,[&quot;^ &quot;],536872284]],[&quot;^1A&quot;,[328,&quot;^Z&quot;,[[&quot;Plain&quot;,&quot;Backpropagation wrt images views of an unlabelled image - assimilation. It ensures that new observations are consistent with current schemata (the support representations).&quot;]],536872284]],[&quot;^1A&quot;,[328,&quot;^1B&quot;,true,536872017]],[&quot;^1A&quot;,[328,&quot;^?&quot;,&quot;~u6129e971-d3a7-4a56-b764-b1cc059aa174&quot;,536872017]],[&quot;^1A&quot;,[329,&quot;^1C&quot;,&quot;Backpropagation_wrt_support_samples___accommodation-2e-_It_ensures_that_current_schemata_effectively_describes_the_new_observations-2e-&quot;,536872142]],[&quot;^1A&quot;,[329,&quot;^S&quot;,[],536872293]],[&quot;^1A&quot;,[329,&quot;^[&quot;,&quot;Backpropagation wrt support samples - accommodation. It ensures that current schemata effectively describes the new observations.&quot;,536872142]],[&quot;^1A&quot;,[329,&quot;^W&quot;,&quot;^1F&quot;,536872097]],[&quot;^1A&quot;,[329,&quot;^E&quot;,false,536872097]],[&quot;^1A&quot;,[329,&quot;^K&quot;,328,536872288]],[&quot;^1A&quot;,[329,&quot;^X&quot;,1,536872293]],[&quot;^1A&quot;,[329,&quot;^17&quot;,280,536872097]],[&quot;^1A&quot;,[329,&quot;^13&quot;,327,536872288]],[&quot;^1A&quot;,[329,&quot;^12&quot;,280,536872293]],[&quot;^1A&quot;,[329,&quot;^D&quot;,[&quot;^ &quot;],536872293]],[&quot;^1A&quot;,[329,&quot;^Z&quot;,[[&quot;Plain&quot;,&quot;Backpropagation wrt support samples - accommodation. It ensures that current schemata effectively describes the new observations.&quot;]],536872293]],[&quot;^1A&quot;,[329,&quot;^1B&quot;,true,536872097]],[&quot;^1A&quot;,[329,&quot;^?&quot;,&quot;~u6129e9bc-fe58-43a4-9c17-3d92db0da997&quot;,536872097]],[&quot;^1A&quot;,[331,&quot;^1C&quot;,&quot;image-2e-png&quot;,536872162]],[&quot;^1A&quot;,[331,&quot;^S&quot;,[],536872816]],[&quot;^1A&quot;,[331,&quot;^[&quot;,&quot;![image.png](../assets/image_1630137094547_0.png)&quot;,536872162]],[&quot;^1A&quot;,[331,&quot;^W&quot;,&quot;^1F&quot;,536872158]],[&quot;^1A&quot;,[331,&quot;^E&quot;,false,536872158]],[&quot;^1A&quot;,[331,&quot;^K&quot;,306,536872158]],[&quot;^1A&quot;,[331,&quot;^X&quot;,1,536872816]],[&quot;^1A&quot;,[331,&quot;^17&quot;,280,536872158]],[&quot;^1A&quot;,[331,&quot;^13&quot;,280,536872158]],[&quot;^1A&quot;,[331,&quot;^12&quot;,280,536872816]],[&quot;^1A&quot;,[331,&quot;^D&quot;,[&quot;^ &quot;],536872816]],[&quot;^1A&quot;,[331,&quot;^Z&quot;,[[&quot;Link&quot;,[&quot;^ &quot;,&quot;^1K&quot;,[&quot;Search&quot;,&quot;../assets/image_1630137094547_0.png&quot;],&quot;^1N&quot;,[[&quot;Plain&quot;,&quot;image.png&quot;]],&quot;^1O&quot;,&quot;![image.png](../assets/image_1630137094547_0.png)&quot;,&quot;^1P&quot;,&quot;&quot;]]],536872816]],[&quot;^1A&quot;,[331,&quot;^1B&quot;,true,536872158]],[&quot;^1A&quot;,[331,&quot;^?&quot;,&quot;~u6129eb05-4853-4937-86e6-ebeea4e7aaa5&quot;,536872158]],[&quot;^1A&quot;,[332,&quot;^1C&quot;,&quot;Encoder____trunk_of_a__network-2e-&quot;,536872228]],[&quot;^1A&quot;,[332,&quot;^S&quot;,[],536872817]],[&quot;^1A&quot;,[332,&quot;^[&quot;,&quot;Encoder $$f_{\\\\theta}$$ - trunk of a [[Resnet]] network.&quot;,536872228]],[&quot;^1A&quot;,[332,&quot;^W&quot;,&quot;^1F&quot;,536872168]],[&quot;^1A&quot;,[332,&quot;^E&quot;,false,536872168]],[&quot;^1A&quot;,[332,&quot;^K&quot;,347,536872817]],[&quot;^1A&quot;,[332,&quot;^X&quot;,1,536872817]],[&quot;^1A&quot;,[332,&quot;^17&quot;,280,536872168]],[&quot;^1A&quot;,[332,&quot;^13&quot;,280,536872168]],[&quot;^1A&quot;,[332,&quot;^12&quot;,280,536872817]],[&quot;^1A&quot;,[332,&quot;^12&quot;,333,536872817]],[&quot;^1A&quot;,[332,&quot;^D&quot;,[&quot;^ &quot;],536872817]],[&quot;^1A&quot;,[332,&quot;^L&quot;,333,536872817]],[&quot;^1A&quot;,[332,&quot;^Z&quot;,[[&quot;Plain&quot;,&quot;Encoder &quot;],[&quot;Latex_Fragment&quot;,[&quot;Displayed&quot;,&quot;f_{\\\\theta}&quot;]],[&quot;Plain&quot;,&quot; - trunk of a &quot;],[&quot;Link&quot;,[&quot;^ &quot;,&quot;^1K&quot;,[&quot;Page_ref&quot;,&quot;Resnet&quot;],&quot;^1N&quot;,[[&quot;Plain&quot;,&quot;&quot;]],&quot;^1O&quot;,&quot;[[Resnet]]&quot;,&quot;^1P&quot;,&quot;&quot;]],[&quot;Plain&quot;,&quot; network.&quot;]],536872817]],[&quot;^1A&quot;,[332,&quot;^1B&quot;,true,536872168]],[&quot;^1A&quot;,[332,&quot;^?&quot;,&quot;~u6129eca1-e6ef-4a7b-ba32-d17f9fb548e9&quot;,536872168]],[&quot;^1A&quot;,[333,&quot;^E&quot;,false,536872220]],[&quot;^1A&quot;,[333,&quot;^19&quot;,&quot;resnet&quot;,536872220]],[&quot;^1A&quot;,[333,&quot;^1=&quot;,&quot;Resnet&quot;,536872220]],[&quot;^1A&quot;,[333,&quot;^?&quot;,&quot;~u6129ecc9-6823-4a24-8ba7-62d0edec284d&quot;,536872220]],[&quot;^1A&quot;,[334,&quot;^1C&quot;,&quot;Authors_have_given_a_theoretical_proof_that_using_prediction_label_sharpening_is_enough_to_prevent_representation_collapse___case_where_all_learned_representations_are_mapped_to_a_single_vector-2e-&quot;,536872394]],[&quot;^1A&quot;,[334,&quot;^S&quot;,[],536872398]],[&quot;^1A&quot;,[334,&quot;^[&quot;,&quot;Authors have given a theoretical proof that using prediction label sharpening is enough to prevent **representation collapse** - case where all learned representations are mapped to a single vector.&quot;,536872398]],[&quot;^1A&quot;,[334,&quot;^W&quot;,&quot;^1F&quot;,536872294]],[&quot;^1A&quot;,[334,&quot;^E&quot;,false,536872294]],[&quot;^1A&quot;,[334,&quot;^K&quot;,327,536872297]],[&quot;^1A&quot;,[334,&quot;^X&quot;,1,536872398]],[&quot;^1A&quot;,[334,&quot;^17&quot;,280,536872294]],[&quot;^1A&quot;,[334,&quot;^13&quot;,280,536872297]],[&quot;^1A&quot;,[334,&quot;^12&quot;,280,536872398]],[&quot;^1A&quot;,[334,&quot;^D&quot;,[&quot;^ &quot;],536872398]],[&quot;^1A&quot;,[334,&quot;^Z&quot;,[[&quot;Plain&quot;,&quot;Authors have given a theoretical proof that using prediction label sharpening is enough to prevent &quot;],[&quot;Emphasis&quot;,[[&quot;Bold&quot;],[[&quot;Plain&quot;,&quot;representation collapse&quot;]]]],[&quot;Plain&quot;,&quot; - case where all learned representations are mapped to a single vector.&quot;]],536872398]],[&quot;^1A&quot;,[334,&quot;^1B&quot;,true,536872294]],[&quot;^1A&quot;,[334,&quot;^?&quot;,&quot;~u6129f067-b3b5-417c-bee1-0064f9931144&quot;,536872294]],[&quot;^1A&quot;,[335,&quot;^1C&quot;,&quot;image-2e-png&quot;,536872355]],[&quot;^1A&quot;,[335,&quot;^S&quot;,[],536872402]],[&quot;^1A&quot;,[335,&quot;^[&quot;,&quot;![image.png](../assets/image_1630138542620_0.png)&quot;,536872402]],[&quot;^1A&quot;,[335,&quot;^W&quot;,&quot;^1F&quot;,536872348]],[&quot;^1A&quot;,[335,&quot;^E&quot;,false,536872348]],[&quot;^1A&quot;,[335,&quot;^K&quot;,334,536872348]],[&quot;^1A&quot;,[335,&quot;^X&quot;,1,536872402]],[&quot;^1A&quot;,[335,&quot;^17&quot;,280,536872348]],[&quot;^1A&quot;,[335,&quot;^13&quot;,334,536872351]],[&quot;^1A&quot;,[335,&quot;^12&quot;,280,536872402]],[&quot;^1A&quot;,[335,&quot;^D&quot;,[&quot;^ &quot;],536872402]],[&quot;^1A&quot;,[335,&quot;^Z&quot;,[[&quot;Link&quot;,[&quot;^ &quot;,&quot;^1K&quot;,[&quot;Search&quot;,&quot;../assets/image_1630138542620_0.png&quot;],&quot;^1N&quot;,[[&quot;Plain&quot;,&quot;image.png&quot;]],&quot;^1O&quot;,&quot;![image.png](../assets/image_1630138542620_0.png)&quot;,&quot;^1P&quot;,&quot;&quot;]]],536872402]],[&quot;^1A&quot;,[335,&quot;^1B&quot;,true,536872348]],[&quot;^1A&quot;,[335,&quot;^?&quot;,&quot;~u6129f0ac-c336-4205-a751-d1c124ee65f1&quot;,536872348]],[&quot;^1A&quot;,[338,&quot;^1C&quot;,&quot;Blog_post___https-3a--2f--2f-ai-2e-facebook-2e-com-2f-blog-2f-dino_paws_computer_vision_with_self_supervised_transformers_and_10x_more_efficient_training&quot;,536872426]],[&quot;^1A&quot;,[338,&quot;^S&quot;,[],536872430]],[&quot;^1A&quot;,[338,&quot;^[&quot;,&quot;Blog post - https://ai.facebook.com/blog/dino-paws-computer-vision-with-self-supervised-transformers-and-10x-more-efficient-training&quot;,536872426]],[&quot;^1A&quot;,[338,&quot;^W&quot;,&quot;^1F&quot;,536872413]],[&quot;^1A&quot;,[338,&quot;^E&quot;,false,536872413]],[&quot;^1A&quot;,[338,&quot;^K&quot;,305,536872413]],[&quot;^1A&quot;,[338,&quot;^X&quot;,1,536872430]],[&quot;^1A&quot;,[338,&quot;^17&quot;,280,536872413]],[&quot;^1A&quot;,[338,&quot;^13&quot;,280,536872413]],[&quot;^1A&quot;,[338,&quot;^12&quot;,280,536872430]],[&quot;^1A&quot;,[338,&quot;^D&quot;,[&quot;^ &quot;],536872430]],[&quot;^1A&quot;,[338,&quot;^Z&quot;,[[&quot;Plain&quot;,&quot;Blog post - &quot;],[&quot;Link&quot;,[&quot;^ &quot;,&quot;^1K&quot;,[&quot;Complex&quot;,[&quot;^ &quot;,&quot;^1L&quot;,&quot;https&quot;,&quot;^1M&quot;,&quot;ai.facebook.com/blog/dino-paws-computer-vision-with-self-supervised-transformers-and-10x-more-efficient-training&quot;]],&quot;^1N&quot;,[[&quot;Plain&quot;,&quot;https://ai.facebook.com/blog/dino-paws-computer-vision-with-self-supervised-transformers-and-10x-more-efficient-training&quot;]],&quot;^1O&quot;,&quot;https://ai.facebook.com/blog/dino-paws-computer-vision-with-self-supervised-transformers-and-10x-more-efficient-training&quot;,&quot;^1P&quot;,&quot;&quot;]]],536872430]],[&quot;^1A&quot;,[338,&quot;^1B&quot;,true,536872413]],[&quot;^1A&quot;,[338,&quot;^?&quot;,&quot;~u6129f86c-0682-4110-987d-9e712b91609e&quot;,536872413]],[&quot;^1A&quot;,[339,&quot;^1C&quot;,&quot;Code___https-3a--2f--2f-github-2e-com-2f-facebookresearch-2f-suncet&quot;,536872442]],[&quot;^1A&quot;,[339,&quot;^S&quot;,[],536872453]],[&quot;^1A&quot;,[339,&quot;^[&quot;,&quot;Code - https://github.com/facebookresearch/suncet #paperwithcode&quot;,536872453]],[&quot;^1A&quot;,[339,&quot;^W&quot;,&quot;^1F&quot;,536872431]],[&quot;^1A&quot;,[339,&quot;^E&quot;,false,536872431]],[&quot;^1A&quot;,[339,&quot;^K&quot;,338,536872431]],[&quot;^1A&quot;,[339,&quot;^X&quot;,1,536872453]],[&quot;^1A&quot;,[339,&quot;^17&quot;,280,536872431]],[&quot;^1A&quot;,[339,&quot;^13&quot;,280,536872431]],[&quot;^1A&quot;,[339,&quot;^12&quot;,280,536872453]],[&quot;^1A&quot;,[339,&quot;^12&quot;,342,536872453]],[&quot;^1A&quot;,[339,&quot;^D&quot;,[&quot;^ &quot;],536872453]],[&quot;^1A&quot;,[339,&quot;^L&quot;,342,536872453]],[&quot;^1A&quot;,[339,&quot;^Z&quot;,[[&quot;Plain&quot;,&quot;Code - &quot;],[&quot;Link&quot;,[&quot;^ &quot;,&quot;^1K&quot;,[&quot;Complex&quot;,[&quot;^ &quot;,&quot;^1L&quot;,&quot;https&quot;,&quot;^1M&quot;,&quot;github.com/facebookresearch/suncet&quot;]],&quot;^1N&quot;,[[&quot;Plain&quot;,&quot;https://github.com/facebookresearch/suncet&quot;]],&quot;^1O&quot;,&quot;https://github.com/facebookresearch/suncet&quot;,&quot;^1P&quot;,&quot;&quot;]],[&quot;Plain&quot;,&quot; &quot;],[&quot;Tag&quot;,[[&quot;Plain&quot;,&quot;paperwithcode&quot;]]]],536872453]],[&quot;^1A&quot;,[339,&quot;^1B&quot;,true,536872431]],[&quot;^1A&quot;,[339,&quot;^?&quot;,&quot;~u6129f872-f14b-47df-943b-79bd697250f2&quot;,536872431]],[&quot;^1A&quot;,[340,&quot;^E&quot;,false,536872446]],[&quot;^1A&quot;,[340,&quot;^19&quot;,&quot;paperswithcode&quot;,536872446]],[&quot;^1A&quot;,[340,&quot;^1=&quot;,&quot;paperswithcode&quot;,536872446]],[&quot;^1A&quot;,[340,&quot;^?&quot;,&quot;~u6129f8b3-4d78-46b1-b9c2-5b7fec6610a5&quot;,536872446]],[&quot;^1A&quot;,[341,&quot;^1C&quot;,&quot;&quot;,536872450]],[&quot;^1A&quot;,[341,&quot;^S&quot;,[],536872450]],[&quot;^1A&quot;,[341,&quot;^[&quot;,&quot;&quot;,536872450]],[&quot;^1A&quot;,[341,&quot;^W&quot;,&quot;^1F&quot;,536872450]],[&quot;^1A&quot;,[341,&quot;^E&quot;,false,536872450]],[&quot;^1A&quot;,[341,&quot;^K&quot;,340,536872450]],[&quot;^1A&quot;,[341,&quot;^X&quot;,1,536872450]],[&quot;^1A&quot;,[341,&quot;^17&quot;,340,536872450]],[&quot;^1A&quot;,[341,&quot;^13&quot;,340,536872450]],[&quot;^1A&quot;,[341,&quot;^D&quot;,[&quot;^ &quot;],536872450]],[&quot;^1A&quot;,[341,&quot;^Z&quot;,[],536872450]],[&quot;^1A&quot;,[341,&quot;^1B&quot;,true,536872450]],[&quot;^1A&quot;,[341,&quot;^?&quot;,&quot;~u6129f8cc-246c-4112-b6af-1c84f916abcf&quot;,536872450]],[&quot;^1A&quot;,[342,&quot;^E&quot;,false,536872453]],[&quot;^1A&quot;,[342,&quot;^19&quot;,&quot;paperwithcode&quot;,536872453]],[&quot;^1A&quot;,[342,&quot;^1=&quot;,&quot;paperwithcode&quot;,536872453]],[&quot;^1A&quot;,[342,&quot;^?&quot;,&quot;~u6129f8d8-615a-4d74-be18-cd9c69094af1&quot;,536872453]],[&quot;^1A&quot;,[343,&quot;^1C&quot;,&quot;image-2e-png&quot;,536872463]],[&quot;^1A&quot;,[343,&quot;^S&quot;,[],536872795]],[&quot;^1A&quot;,[343,&quot;^[&quot;,&quot;![image.png](../assets/image_1630140911953_0.png)&quot;,536872785]],[&quot;^1A&quot;,[343,&quot;^W&quot;,&quot;^1F&quot;,536872459]],[&quot;^1A&quot;,[343,&quot;^E&quot;,false,536872459]],[&quot;^1A&quot;,[343,&quot;^K&quot;,346,536872787]],[&quot;^1A&quot;,[343,&quot;^X&quot;,1,536872795]],[&quot;^1A&quot;,[343,&quot;^17&quot;,280,536872459]],[&quot;^1A&quot;,[343,&quot;^13&quot;,346,536872795]],[&quot;^1A&quot;,[343,&quot;^12&quot;,280,536872795]],[&quot;^1A&quot;,[343,&quot;^D&quot;,[&quot;^ &quot;],536872795]],[&quot;^1A&quot;,[343,&quot;^Z&quot;,[[&quot;Link&quot;,[&quot;^ &quot;,&quot;^1K&quot;,[&quot;Search&quot;,&quot;../assets/image_1630140911953_0.png&quot;],&quot;^1N&quot;,[[&quot;Plain&quot;,&quot;image.png&quot;]],&quot;^1O&quot;,&quot;![image.png](../assets/image_1630140911953_0.png)&quot;,&quot;^1P&quot;,&quot;&quot;]]],536872795]],[&quot;^1A&quot;,[343,&quot;^1B&quot;,true,536872459]],[&quot;^1A&quot;,[343,&quot;^?&quot;,&quot;~u6129f9ed-4537-4d5b-b936-cb9b77b9bf60&quot;,536872459]],[&quot;^1A&quot;,[344,&quot;^1C&quot;,&quot;here__is_the__representation_from_the_mini_batch_-2c-__is_the_support_set_of_labelled_images-2e-__is_number_of_image_classes-2e-__is_the_one_hot_ground_truth_label_vector_associated_with_the__row_vector__from_-2e-&quot;,536872781]],[&quot;^1A&quot;,[344,&quot;^S&quot;,[],536873117]],[&quot;^1A&quot;,[344,&quot;^[&quot;,&quot;here $$z_{i}$$ is the $$i^{th}$$ representation from the mini-batch $$\\\\bold{z}$$, $$\\\\bold{z}_{S}$$ is the support set of labelled images. $$k$$ is number of image classes. $$y_{j}$$ is the one-hot ground truth label vector associated with the $$j^{th}$$ row vector $$z_{sj}$$ from $$\\\\bold{z}_{S}$$.&quot;,536872781]],[&quot;^1A&quot;,[344,&quot;^W&quot;,&quot;^1F&quot;,536872466]],[&quot;^1A&quot;,[344,&quot;^E&quot;,false,536872466]],[&quot;^1A&quot;,[344,&quot;^K&quot;,343,536872466]],[&quot;^1A&quot;,[344,&quot;^X&quot;,1,536873117]],[&quot;^1A&quot;,[344,&quot;^17&quot;,280,536872466]],[&quot;^1A&quot;,[344,&quot;^13&quot;,346,536872799]],[&quot;^1A&quot;,[344,&quot;^12&quot;,280,536873117]],[&quot;^1A&quot;,[344,&quot;^D&quot;,[&quot;^ &quot;],536873117]],[&quot;^1A&quot;,[344,&quot;^Z&quot;,[[&quot;Plain&quot;,&quot;here &quot;],[&quot;Latex_Fragment&quot;,[&quot;Displayed&quot;,&quot;z_{i}&quot;]],[&quot;Plain&quot;,&quot; is the &quot;],[&quot;Latex_Fragment&quot;,[&quot;Displayed&quot;,&quot;i^{th}&quot;]],[&quot;Plain&quot;,&quot; representation from the mini-batch &quot;],[&quot;Latex_Fragment&quot;,[&quot;Displayed&quot;,&quot;\\\\bold{z}&quot;]],[&quot;Plain&quot;,&quot;, &quot;],[&quot;Latex_Fragment&quot;,[&quot;Displayed&quot;,&quot;\\\\bold{z}_{S}&quot;]],[&quot;Plain&quot;,&quot; is the support set of labelled images. &quot;],[&quot;Latex_Fragment&quot;,[&quot;Displayed&quot;,&quot;k&quot;]],[&quot;Plain&quot;,&quot; is number of image classes. &quot;],[&quot;Latex_Fragment&quot;,[&quot;Displayed&quot;,&quot;y_{j}&quot;]],[&quot;Plain&quot;,&quot; is the one-hot ground truth label vector associated with the &quot;],[&quot;Latex_Fragment&quot;,[&quot;Displayed&quot;,&quot;j^{th}&quot;]],[&quot;Plain&quot;,&quot; row vector &quot;],[&quot;Latex_Fragment&quot;,[&quot;Displayed&quot;,&quot;z_{sj}&quot;]],[&quot;Plain&quot;,&quot; from &quot;],[&quot;Latex_Fragment&quot;,[&quot;Displayed&quot;,&quot;\\\\bold{z}_{S}&quot;]],[&quot;Plain&quot;,&quot;.&quot;]],536873117]],[&quot;^1A&quot;,[344,&quot;^1B&quot;,true,536872466]],[&quot;^1A&quot;,[344,&quot;^?&quot;,&quot;~u6129f9f0-d772-4c3a-bd0d-905038d03547&quot;,536872466]],[&quot;^1A&quot;,[346,&quot;^1C&quot;,&quot;A_differentiable-2c-_distance_similarity_based_classifier-2c-_-2c-_is_used_to_generate_soft_pseudo_labels_for_unlabelled_images_using_labelled_images-2e-&quot;,536872791]],[&quot;^1A&quot;,[346,&quot;^S&quot;,[],536872791]],[&quot;^1A&quot;,[346,&quot;^[&quot;,&quot;A differentiable, distance similarity based classifier, $$\\\\pi_{d}$$, is used to generate soft pseudo labels for unlabelled images using labelled images.&quot;,536872791]],[&quot;^1A&quot;,[346,&quot;^W&quot;,&quot;^1F&quot;,536872787]],[&quot;^1A&quot;,[346,&quot;^E&quot;,false,536872787]],[&quot;^1A&quot;,[346,&quot;^K&quot;,332,536872787]],[&quot;^1A&quot;,[346,&quot;^X&quot;,1,536872791]],[&quot;^1A&quot;,[346,&quot;^17&quot;,280,536872787]],[&quot;^1A&quot;,[346,&quot;^13&quot;,280,536872787]],[&quot;^1A&quot;,[346,&quot;^12&quot;,280,536872791]],[&quot;^1A&quot;,[346,&quot;^D&quot;,[&quot;^ &quot;],536872791]],[&quot;^1A&quot;,[346,&quot;^Z&quot;,[[&quot;Plain&quot;,&quot;A differentiable, distance similarity based classifier, &quot;],[&quot;Latex_Fragment&quot;,[&quot;Displayed&quot;,&quot;\\\\pi_{d}&quot;]],[&quot;Plain&quot;,&quot;, is used to generate soft pseudo labels for unlabelled images using labelled images.&quot;]],536872791]],[&quot;^1A&quot;,[346,&quot;^1B&quot;,true,536872787]],[&quot;^1A&quot;,[346,&quot;^?&quot;,&quot;~u6129fb24-af38-42b8-b255-57658d0158f8&quot;,536872787]],[&quot;^1A&quot;,[347,&quot;^1C&quot;,&quot;Terminology_(section_3-2e-1_in_paper)___given_an_image-2c-_generate_two_views_after_applying_data_augmentation_strategies_(described_in_paper)___(i)_an_anchor_view_-2c-_and_(ii)_associated_positive_view_-2e-_A_labelled_image__and_its_corresponding_one_hot_encoded_class_vector__is_used_to_generate_pseudo_labels_using_the_distance_similarity_function-2e-&quot;,536873113]],[&quot;^1A&quot;,[347,&quot;^S&quot;,[],536873113]],[&quot;^1A&quot;,[347,&quot;^[&quot;,&quot;Terminology (section 3.1 in paper) - given an image, generate two views after applying data augmentation strategies (described in paper) - (i) an anchor view $$\\\\hat{\\\\bold{x}}_{i}$$, and (ii) associated positive view $$\\\\hat{\\\\bold{x}}_{i}^{+}$$. A labelled image $$\\\\hat{\\\\bold{x}}_{s}$$ and its corresponding one-hot encoded class vector $$y_{s}$$ is used to generate pseudo labels using the distance similarity function.&quot;,536873113]],[&quot;^1A&quot;,[347,&quot;^W&quot;,&quot;^1F&quot;,536872817]],[&quot;^1A&quot;,[347,&quot;^E&quot;,false,536872817]],[&quot;^1A&quot;,[347,&quot;^K&quot;,331,536872817]],[&quot;^1A&quot;,[347,&quot;^X&quot;,1,536873113]],[&quot;^1A&quot;,[347,&quot;^17&quot;,280,536872817]],[&quot;^1A&quot;,[347,&quot;^13&quot;,280,536872817]],[&quot;^1A&quot;,[347,&quot;^12&quot;,280,536873113]],[&quot;^1A&quot;,[347,&quot;^D&quot;,[&quot;^ &quot;],536873113]],[&quot;^1A&quot;,[347,&quot;^Z&quot;,[[&quot;Plain&quot;,&quot;Terminology (section 3.1 in paper) - given an image, generate two views after applying data augmentation strategies (described in paper) - (i) an anchor view &quot;],[&quot;Latex_Fragment&quot;,[&quot;Displayed&quot;,&quot;\\\\hat{\\\\bold{x}}_{i}&quot;]],[&quot;Plain&quot;,&quot;, and (ii) associated positive view &quot;],[&quot;Latex_Fragment&quot;,[&quot;Displayed&quot;,&quot;\\\\hat{\\\\bold{x}}_{i}^{+}&quot;]],[&quot;Plain&quot;,&quot;. A labelled image &quot;],[&quot;Latex_Fragment&quot;,[&quot;Displayed&quot;,&quot;\\\\hat{\\\\bold{x}}_{s}&quot;]],[&quot;Plain&quot;,&quot; and its corresponding one-hot encoded class vector &quot;],[&quot;Latex_Fragment&quot;,[&quot;Displayed&quot;,&quot;y_{s}&quot;]],[&quot;Plain&quot;,&quot; is used to generate pseudo labels using the distance similarity function.&quot;]],536873113]],[&quot;^1A&quot;,[347,&quot;^1B&quot;,true,536872817]],[&quot;^1A&quot;,[347,&quot;^?&quot;,&quot;~u6129fbd4-4fcd-4aab-9248-2913476384a7&quot;,536872817]],[&quot;^1A&quot;,[348,&quot;^1C&quot;,&quot;image-2e-png&quot;,536873139]],[&quot;^1A&quot;,[348,&quot;^S&quot;,[],536873143]],[&quot;^1A&quot;,[348,&quot;^[&quot;,&quot;![image.png](../assets/image_1630141821799_0.png)&quot;,536873139]],[&quot;^1A&quot;,[348,&quot;^W&quot;,&quot;^1F&quot;,536873118]],[&quot;^1A&quot;,[348,&quot;^E&quot;,false,536873118]],[&quot;^1A&quot;,[348,&quot;^K&quot;,346,536873121]],[&quot;^1A&quot;,[348,&quot;^X&quot;,1,536873143]],[&quot;^1A&quot;,[348,&quot;^17&quot;,280,536873118]],[&quot;^1A&quot;,[348,&quot;^13&quot;,280,536873121]],[&quot;^1A&quot;,[348,&quot;^12&quot;,280,536873143]],[&quot;^1A&quot;,[348,&quot;^D&quot;,[&quot;^ &quot;],536873143]],[&quot;^1A&quot;,[348,&quot;^Z&quot;,[[&quot;Link&quot;,[&quot;^ &quot;,&quot;^1K&quot;,[&quot;Search&quot;,&quot;../assets/image_1630141821799_0.png&quot;],&quot;^1N&quot;,[[&quot;Plain&quot;,&quot;image.png&quot;]],&quot;^1O&quot;,&quot;![image.png](../assets/image_1630141821799_0.png)&quot;,&quot;^1P&quot;,&quot;&quot;]]],536873143]],[&quot;^1A&quot;,[348,&quot;^1B&quot;,true,536873118]],[&quot;^1A&quot;,[348,&quot;^?&quot;,&quot;~u6129fd55-cc74-45da-a5d7-3de8fe817b66&quot;,536873118]],[&quot;^1A&quot;,[349,&quot;^1C&quot;,&quot;Final_training_objective-2e-__is_cross_entropy_loss-2e-__seeks_to_maximise_entropy_for_regularization_term_-2c-_which_is_referred_as_mean_entropy_maximization_(ME_MAX)-2e-&quot;,536873323]],[&quot;^1A&quot;,[349,&quot;^S&quot;,[],536873327]],[&quot;^1A&quot;,[349,&quot;^[&quot;,&quot;Final training objective. $$H(.,.)$$ is cross-entropy loss. $$H(\\\\bar{p})$$ seeks to maximise entropy for regularization term $$\\\\bar{p}$$, which is referred as **mean entropy maximization** (ME-MAX).&quot;,536873327]],[&quot;^1A&quot;,[349,&quot;^W&quot;,&quot;^1F&quot;,536873144]],[&quot;^1A&quot;,[349,&quot;^E&quot;,false,536873144]],[&quot;^1A&quot;,[349,&quot;^K&quot;,348,536873144]],[&quot;^1A&quot;,[349,&quot;^X&quot;,1,536873327]],[&quot;^1A&quot;,[349,&quot;^17&quot;,280,536873144]],[&quot;^1A&quot;,[349,&quot;^13&quot;,348,536873147]],[&quot;^1A&quot;,[349,&quot;^12&quot;,280,536873327]],[&quot;^1A&quot;,[349,&quot;^D&quot;,[&quot;^ &quot;],536873327]],[&quot;^1A&quot;,[349,&quot;^Z&quot;,[[&quot;Plain&quot;,&quot;Final training objective. &quot;],[&quot;Latex_Fragment&quot;,[&quot;Displayed&quot;,&quot;H(.,.)&quot;]],[&quot;Plain&quot;,&quot; is cross-entropy loss. &quot;],[&quot;Latex_Fragment&quot;,[&quot;Displayed&quot;,&quot;H(\\\\bar{p})&quot;]],[&quot;Plain&quot;,&quot; seeks to maximise entropy for regularization term &quot;],[&quot;Latex_Fragment&quot;,[&quot;Displayed&quot;,&quot;\\\\bar{p}&quot;]],[&quot;Plain&quot;,&quot;, which is referred as &quot;],[&quot;Emphasis&quot;,[[&quot;Bold&quot;],[[&quot;Plain&quot;,&quot;mean entropy maximization&quot;]]]],[&quot;Plain&quot;,&quot; (ME-MAX).&quot;]],536873327]],[&quot;^1A&quot;,[349,&quot;^1B&quot;,true,536873144]],[&quot;^1A&quot;,[349,&quot;^?&quot;,&quot;~u6129fd82-3f14-423d-bfab-56686b300b0e&quot;,536873144]],[&quot;^1A&quot;,[350,&quot;^1C&quot;,&quot;By_maximising_the_entropy-2c-_individual_predictions_are_encouraged_to_be_confident-2c-_the_average_prediction_is_encouraged_to_be_close_to_uniform_distribution___equal_probability_for_all_classes-2e-&quot;,536873411]],[&quot;^1A&quot;,[350,&quot;^S&quot;,[],536873415]],[&quot;^1A&quot;,[350,&quot;^[&quot;,&quot;By maximising the entropy, individual predictions are encouraged to be confident, the average prediction is encouraged to be close to uniform distribution - equal probability for all classes.&quot;,536873411]],[&quot;^1A&quot;,[350,&quot;^W&quot;,&quot;^1F&quot;,536873264]],[&quot;^1A&quot;,[350,&quot;^E&quot;,false,536873264]],[&quot;^1A&quot;,[350,&quot;^K&quot;,349,536873264]],[&quot;^1A&quot;,[350,&quot;^X&quot;,1,536873415]],[&quot;^1A&quot;,[350,&quot;^17&quot;,280,536873264]],[&quot;^1A&quot;,[350,&quot;^13&quot;,348,536873264]],[&quot;^1A&quot;,[350,&quot;^12&quot;,280,536873415]],[&quot;^1A&quot;,[350,&quot;^D&quot;,[&quot;^ &quot;],536873415]],[&quot;^1A&quot;,[350,&quot;^Z&quot;,[[&quot;Plain&quot;,&quot;By maximising the entropy, individual predictions are encouraged to be confident, the average prediction is encouraged to be close to uniform distribution - equal probability for all classes.&quot;]],536873415]],[&quot;^1A&quot;,[350,&quot;^1B&quot;,true,536873264]],[&quot;^1A&quot;,[350,&quot;^?&quot;,&quot;~u6129fded-ec01-4eb6-86ad-1f7cf4e55ddd&quot;,536873264]],[&quot;^1A&quot;,[351,&quot;^1C&quot;,&quot;Note-3a-_This_also_ties_to__in_the_theoretical_guarantee_against_representation_collapse_(section_4_in_the_paper)_where_class_balanced_sampling_is_assumed-2e-_Each_mini_batch_of_labeled_support_sample_contains_an_equal_number_of_instances_from_each_of_the_sampled_classes-2e-&quot;,536873557]],[&quot;^1A&quot;,[351,&quot;^S&quot;,[],536873557]],[&quot;^1A&quot;,[351,&quot;^[&quot;,&quot;Note: This also ties to `Assumption 1` in the theoretical guarantee against representation collapse (section 4 in the paper) where class balanced sampling is assumed. Each mini-batch of labeled support sample contains an equal number of instances from each of the sampled classes.&quot;,536873557]],[&quot;^1A&quot;,[351,&quot;^W&quot;,&quot;^1F&quot;,536873416]],[&quot;^1A&quot;,[351,&quot;^E&quot;,false,536873416]],[&quot;^1A&quot;,[351,&quot;^K&quot;,350,536873416]],[&quot;^1A&quot;,[351,&quot;^X&quot;,1,536873557]],[&quot;^1A&quot;,[351,&quot;^17&quot;,280,536873416]],[&quot;^1A&quot;,[351,&quot;^13&quot;,350,536873419]],[&quot;^1A&quot;,[351,&quot;^12&quot;,280,536873557]],[&quot;^1A&quot;,[351,&quot;^D&quot;,[&quot;^ &quot;],536873557]],[&quot;^1A&quot;,[351,&quot;^Z&quot;,[[&quot;Plain&quot;,&quot;Note: This also ties to &quot;],[&quot;Code&quot;,&quot;Assumption 1&quot;],[&quot;Plain&quot;,&quot; in the theoretical guarantee against representation collapse (section 4 in the paper) where class balanced sampling is assumed. Each mini-batch of labeled support sample contains an equal number of instances from each of the sampled classes.&quot;]],536873557]],[&quot;^1A&quot;,[351,&quot;^1B&quot;,true,536873416]],[&quot;^1A&quot;,[351,&quot;^?&quot;,&quot;~u6129feea-0a74-4cbf-980f-3e36d4635e31&quot;,536873416]]]]]]"</script><script>window.logseq_state="{:ui/theme \"dark\", :ui/cycle-collapse :show-all, :ui/sidebar-collapsed-blocks {}, :ui/show-recent? false, :config {\"local\" {:shortcuts {}, :default-templates {:journals \"\"}, :feature/enable-journals? false, :macros {}, :ui/show-empty-bullets? false, :markdown/version 2, :preferred-workflow :todo, :publishing/all-pages-public? true, :ref/default-open-blocks-level 2, :feature/enable-block-timestamps? false, :commands [], :hidden [], :default-queries {:journals [{:title \"🔨 NOW\", :query [:find (pull ?h [*]) :in $ ?start ?today :where [?h :block/marker ?marker] [(contains? #{\"NOW\" \"DOING\"} ?marker)] [?h :block/page ?p] [?p :block/journal? true] [?p :block/journal-day ?d] [(>= ?d ?start)] [(<= ?d ?today)]], :inputs [:14d :today], :result-transform (fn [result] (sort-by (fn [h] (get h :block/priority \"Z\")) result)), :collapsed? false} {:title \"📅 NEXT\", :query [:find (pull ?h [*]) :in $ ?start ?next :where [?h :block/marker ?marker] [(contains? #{\"NOW\" \"LATER\" \"TODO\"} ?marker)] [?h :block/ref-pages ?p] [?p :block/journal? true] [?p :block/journal-day ?d] [(> ?d ?start)] [(< ?d ?next)]], :inputs [:today :7d-after], :collapsed? false}]}, :editor/logical-outdenting? true, :zotero/settings {:type-id \"7048753\", :attachments-block-text \"[[Attachments]]\", :notes-block-text \"[[Notes]]\", :zotero-data-directory \"\", :include-attachments? false, :include-notes? true, :prefer-citekey? false, :page-insert-prefix \"\"}, :ui/enable-tooltip? true, :graph/settings {:orphan-pages? false, :builtin-pages? false}, :zotero/settings-v2 {\"default\" {:include-attachments? false, :include-notes? true, :prefer-citekey? false, :type-id \"7048753\", :page-insert-prefix \"\", :zotero-linked-attachment-base-directory \"/Users/utkarshchauhan/Google Drive/ResearchPapers\", :notes-block-text \"\"}}, :ui/show-command-doc? true, :default-home {:page \"Contents\"}}}}"</script><script type="text/javascript">// Single Page Apps for GitHub Pages
      // https://github.com/rafgraph/spa-github-pages
      // Copyright (c) 2016 Rafael Pedicini, licensed under the MIT License
      // ----------------------------------------------------------------------
      // This script checks to see if a redirect is present in the query string
      // and converts it back into the correct url and adds it to the
      // browser's history using window.history.replaceState(...),
      // which won't cause the browser to attempt to load the new url.
      // When the single page app is loaded further down in this file,
      // the correct url will be waiting in the browser's history for
      // the single page app to route accordingly.
      (function(l) {
        if (l.search) {
          var q = {};
          l.search.slice(1).split('&').forEach(function(v) {
            var a = v.split('=');
            q[a[0]] = a.slice(1).join('=').replace(/~and~/g, '&');
          });
          if (q.p !== undefined) {
            window.history.replaceState(null, null,
              l.pathname.slice(0, -1) + (q.p || '') +
              (q.q ? ('?' + q.q) : '') +
              l.hash
            );
          }
        }
      }(window.location))</script><script src="static/js/highlight.min.js"></script><script src="static/js/interact.min.js"></script><script src="static/js/main.js"></script></body>